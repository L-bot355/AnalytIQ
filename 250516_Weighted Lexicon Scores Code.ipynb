{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f3516e-c928-4265-a9a5-2d9b48313c49",
   "metadata": {},
   "source": [
    "# Lexicon Score based on BoE Wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2a453-aab6-4f67-b551-bf4da5f2c4e7",
   "metadata": {},
   "source": [
    "### 1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2866bd-6853-41bd-b63c-f03c4e6cb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re                                               # Regular expression operations on strings.\n",
    "from collections import defaultdict                     # Creating dictionaries that return default value for nonexistent keys.\n",
    "from nltk.corpus import wordnet as wn                   # Lexical database for retrieving word relationships & meanings.\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer  # Reducing words to base or root form.\n",
    "import contractions                                     # Expanding/contracting text contractions.\n",
    "from nltk.corpus import stopwords                       # Providing list of common words to exclude from analysis.\n",
    "from nltk import word_tokenize, pos_tag                 # Splitting text into words and tags with part of speech\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer  # Reducing words to base or root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c2a033-3f8c-4ae0-8df6-2601c6cb6493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \n",
       "0  fraser       0  They would no doubt argue that to have two obj...  \n",
       "1  fraser       0  Today I wish to talk about real interest rates...  \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...  \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...  \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file as speeches\n",
    "speeches = pd.read_csv('/Users/kaferrante/Documents/Python/_Course4_Project/all_speeches.csv')\n",
    "\n",
    "# View the DataFrame\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05240735-961c-455f-950d-5f1d3216d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Weak</th>\n",
       "      <th>Constraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDONING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABANDONMENTS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Negative  Positive  Uncertainty  Litigious  Strong  Weak  \\\n",
       "0       ABANDON         1         0            0          0       0     0   \n",
       "1     ABANDONED         1         0            0          0       0     0   \n",
       "2    ABANDONING         1         0            0          0       0     0   \n",
       "3   ABANDONMENT         1         0            0          0       0     0   \n",
       "4  ABANDONMENTS         1         0            0          0       0     0   \n",
       "\n",
       "   Constraining  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file of BoE sentiment labelled wordlist\n",
    "sentiment_lexicon = pd.read_excel('/Users/kaferrante/Documents/Python/_Course4_Project/sentiment_labelled_wordlist.xlsx')\n",
    "\n",
    "# View the DataFrame\n",
    "sentiment_lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46003af1-907a-459b-bc46-eab1b9c24c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDONING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABANDONMENTS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  negative  positive  uncertainty  litigious  strong  weak  \\\n",
       "0       ABANDON         1         0            0          0       0     0   \n",
       "1     ABANDONED         1         0            0          0       0     0   \n",
       "2    ABANDONING         1         0            0          0       0     0   \n",
       "3   ABANDONMENT         1         0            0          0       0     0   \n",
       "4  ABANDONMENTS         1         0            0          0       0     0   \n",
       "\n",
       "   constraining  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "sentiment_lexicon = sentiment_lexicon.rename(columns={\n",
    "    'Negative': 'negative',\n",
    "    'Positive': 'positive',\n",
    "    'Uncertainty': 'uncertainty',\n",
    "    'Litigious': 'litigious',\n",
    "    'Strong': 'strong',\n",
    "    'Weak': 'weak',\n",
    "    'Constraining': 'constraining',\n",
    "})\n",
    "\n",
    "# View the DataFrame\n",
    "sentiment_lexicon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c807e1-c67d-45db-9f6b-8f01879e1700",
   "metadata": {},
   "source": [
    "### 2. Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c986e4-9b77-47da-a847-e5dbeb952e92",
   "metadata": {},
   "source": [
    "**Text cleaned** by\n",
    "- Removing unwanted characters\n",
    "- Removing any special characters and punctuation\n",
    "- Converting text to lower case\n",
    "- Removing stopwords\n",
    "- tokenisation: Split the cleaned text into individual words, so that text can be analysed at word level.\n",
    "- Lemmatisation: Reduce words to its base or dictionary form (the lemma)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91fc66-bd31-4675-86f2-410695a730ae",
   "metadata": {},
   "source": [
    "**Text cleaning functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae3fcc5-dc54-4b3b-af10-288d73115130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = contractions.fix(text)  # Expand contractions i.e I'm not good goes to I am not good\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub('#', '', text)         # Remove hashtags\n",
    "    text = re.sub(r'\\W', ' ', text)      # Remove special characters\n",
    "    text = text.lower()                  # Convert to lowercase\n",
    "    #Below is to create a set of stop words from the NLTK library's predefined list but not is excluded.\n",
    "    stop_words = set(stopwords.words('english')) - {'not'} \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66b7669-293d-496d-8728-b9ec44b4cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tag map for POS tagging.\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "# Lemmatise the tokens with correct POS tags.\n",
    "lemma_function = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatisation function.\n",
    "def lemmatize_tokens(tokens):\n",
    "    #For each word in the token list, it lemmatizes the word with the correct part-of-speech\n",
    "    lemmatized_tokens = [lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens)]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f57f0-f79c-4192-9498-5fc11f5294f6",
   "metadata": {},
   "source": [
    "**Apply text cleaning functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f54f23a-0877-40ab-9321-c3b4be36a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function\n",
    "speeches['text_cleaned'] = speeches['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd6d0fe-1df9-450c-8580-6dc0c8a1bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenisation function\n",
    "speeches['text_tokenised'] = speeches['text_cleaned'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ccb2849-843f-4730-b5cd-7379110fe370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the lemmatisation function\n",
    "speeches['text_lemmatised'] = speeches['text_tokenised'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68f06e09-0b44-40ac-87b0-787e76a64461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of words into a string\n",
    "speeches['text_lemmatised_str'] = speeches['text_lemmatised'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdf53afd-6d46-4cd7-8acb-c60b2508e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of words in original text\n",
    "speeches['word_count_text'] = speeches['text'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ea391a-814d-46a1-80cd-ae3c26ba7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of words in lemmatised text\n",
    "speeches['word_count_text_cleaned'] = speeches['text_lemmatised_str'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5644902-6515-41b7-affc-310dc43ed604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>text_lemmatised_str</th>\n",
       "      <th>word_count_text</th>\n",
       "      <th>word_count_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>would doubt argue two objective like try cake ...</td>\n",
       "      <td>3627</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>today wish talk real interest rate mainly hist...</td>\n",
       "      <td>3054</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>welcome opportunity talk prospect bank austral...</td>\n",
       "      <td>3399</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>3841</td>\n",
       "      <td>2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>long time fan sander delight participate tribu...</td>\n",
       "      <td>4152</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...   \n",
       "1  [today, wish, talk, real, interest, rate, main...   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sander, delight, participate...   \n",
       "\n",
       "                                 text_lemmatised_str  word_count_text  \\\n",
       "0  would doubt argue two objective like try cake ...             3627   \n",
       "1  today wish talk real interest rate mainly hist...             3054   \n",
       "2  welcome opportunity talk prospect bank austral...             3399   \n",
       "3  pleasure opportunity address influential gathe...             3841   \n",
       "4  long time fan sander delight participate tribu...             4152   \n",
       "\n",
       "   word_count_text_cleaned  \n",
       "0                     1919  \n",
       "1                     1754  \n",
       "2                     1867  \n",
       "3                     2123  \n",
       "4                     2150  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the Dataframe\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f4fb7-bef5-4f29-8ee0-3c4757f5b069",
   "metadata": {},
   "source": [
    "### 3. Calculating simple sentiment score with BoE Wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e670b-4ec9-455b-beb2-1be3eabbe738",
   "metadata": {},
   "source": [
    "**Sentiment score** is calculated as follows:\n",
    "- positive and negative words in each speech are counted\n",
    "- sentiment score = psotive word count - negative word count /  wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c69bde77-ce1f-4737-bb2f-acc0195551cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the lexicon\n",
    "sentiment_lexicon = sentiment_lexicon.copy()\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "     'negative',\n",
    "     'positive',\n",
    "     'uncertainty',\n",
    "     'litigious',\n",
    "     'strong',\n",
    "     'weak',\n",
    "     'constraining',\n",
    " ]\n",
    "\n",
    "# Create dictionary of categories, containing words that belong to that category based on your sentiment lexicon.\n",
    "word_sets = {\n",
    "    cat: set(sentiment_lexicon.loc[sentiment_lexicon[cat] == 1, 'Word'].str.lower())\n",
    "    for cat in categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afd92354-e145-4783-88bf-a1884f1c73a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_text</th>\n",
       "      <th>word_count_text_cleaned</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>...</td>\n",
       "      <td>3627</td>\n",
       "      <td>1919</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>...</td>\n",
       "      <td>3054</td>\n",
       "      <td>1754</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>...</td>\n",
       "      <td>3399</td>\n",
       "      <td>1867</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>3841</td>\n",
       "      <td>2123</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>...</td>\n",
       "      <td>4152</td>\n",
       "      <td>2150</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  ... word_count_text  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...  ...            3627   \n",
       "1  [today, wish, talk, real, interest, rate, main...  ...            3054   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...  ...            3399   \n",
       "3  [pleasure, opportunity, address, influential, ...  ...            3841   \n",
       "4  [long, time, fan, sander, delight, participate...  ...            4152   \n",
       "\n",
       "   word_count_text_cleaned  negative  positive  uncertainty  litigious  \\\n",
       "0                     1919        84        58           32          5   \n",
       "1                     1754        53        28           35          2   \n",
       "2                     1867        43        67           33          8   \n",
       "3                     2123        62        56           43          6   \n",
       "4                     2150        72        62           42          6   \n",
       "\n",
       "   strong  weak  constraining  word_count_sentiment  \n",
       "0      10    15            13                   217  \n",
       "1       3    16            12                   149  \n",
       "2      11    16            13                   191  \n",
       "3       7    20             8                   202  \n",
       "4      12    27            13                   234  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to apply the lexicon to the tokens\n",
    "def lexicon_counts(tokens):\n",
    "    return pd.Series({\n",
    "        cat: sum(t in word_sets[cat] for t in tokens)\n",
    "        for cat in categories\n",
    "    })\n",
    "\n",
    "# Apply the lexicon_counts function to 'text_lemmatised' column\n",
    "category_counts = speeches['text_lemmatised'].apply(lexicon_counts)\n",
    "\n",
    "# Concatenate category counts to the original DataFrame\n",
    "speeches = pd.concat([speeches, category_counts], axis=1)\n",
    "\n",
    "# Calculate total sentiment words across all categories for each speech\n",
    "speeches['word_count_sentiment'] = category_counts.sum(axis=1)\n",
    "\n",
    "# View the DataFrame\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52fefa00-5c98-43bb-bbbb-b385ae23707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sentiment score by subtracting the negative score from the positive score\n",
    "# abd dividing by the total number of words in the lemmatised text\n",
    "speeches['sentiment_lexicon_simple'] = (speeches['positive'] - speeches['negative'])/ speeches['word_count_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03151a76-b87b-401e-b294-16fd5cd9c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_text_cleaned</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>...</td>\n",
       "      <td>1919</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.119816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>...</td>\n",
       "      <td>1754</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.167785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>...</td>\n",
       "      <td>1867</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>191</td>\n",
       "      <td>0.125654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2123</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>-0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>...</td>\n",
       "      <td>2150</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "      <td>-0.042735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  ...  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...  ...   \n",
       "1  [today, wish, talk, real, interest, rate, main...  ...   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...  ...   \n",
       "3  [pleasure, opportunity, address, influential, ...  ...   \n",
       "4  [long, time, fan, sander, delight, participate...  ...   \n",
       "\n",
       "  word_count_text_cleaned  negative  positive  uncertainty  litigious  strong  \\\n",
       "0                    1919        84        58           32          5      10   \n",
       "1                    1754        53        28           35          2       3   \n",
       "2                    1867        43        67           33          8      11   \n",
       "3                    2123        62        56           43          6       7   \n",
       "4                    2150        72        62           42          6      12   \n",
       "\n",
       "   weak  constraining  word_count_sentiment  sentiment_lexicon_simple  \n",
       "0    15            13                   217                 -0.119816  \n",
       "1    16            12                   149                 -0.167785  \n",
       "2    16            13                   191                  0.125654  \n",
       "3    20             8                   202                 -0.029703  \n",
       "4    27            13                   234                 -0.042735  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframe\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce340f2-5450-4add-91ba-2ec90fbbc4a9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800ab5f-ff87-4eba-b454-6927b2a930ca",
   "metadata": {},
   "source": [
    "### 4. Calculate weighted sentiment score with BoE Wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686466b-ae7b-4d75-87b5-c8ca2cc459e1",
   "metadata": {},
   "source": [
    "**Sentiment score** is calculated as follows:\n",
    "- words in all categories in each speech are counted (positive, negative, uncertainty, litigious, strong, weak, constraining)\n",
    "- weights are applied to each category to show how important the influence on the sentiment is\n",
    "- sentiment score = category counts * category weights / wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2efd5-181a-4b29-aedb-8e0b4753f8d5",
   "metadata": {},
   "source": [
    "**Category weights** based on importance:\n",
    "- Negative -1       Standard negative words\n",
    "- Positive +1.5     Standard positive words - compensate for negatively skewed wordlist\n",
    "- Uncertainty 0.2   Words expressing doubt or ambiguity, less impactful than outright negative or positive words\n",
    "- Litigious -0.2    Words related to lawsuits or legal issues, potentially negative or impactful depending on context\n",
    "- Strong +1.5       Words with high intensity or impact, thus given more weight\n",
    "- Weak +0.5         Words with less impact, so given lesser weight than 'Strong' words\n",
    "- Constraining -0.5 Words implying restriction or limitations, generally negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b04c34a-7f87-42f0-b86f-fddfd393ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights to the categories\n",
    "category_weights = {\n",
    "    'negative': -1,\n",
    "    'positive': 1.5,\n",
    "    'uncertainty': 0.2,\n",
    "    'litigious': -0.2,\n",
    "    'strong': 1.5,\n",
    "    'weak': 0.5,\n",
    "    'constraining': -0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fda6b52-e81a-4c96-9f56-fdefb35ff780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.119816</td>\n",
       "      <td>0.112442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>191</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.421466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>-0.029703</td>\n",
       "      <td>0.227228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>0.227350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  ... negative  positive  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...  ...       84        58   \n",
       "1  [today, wish, talk, real, interest, rate, main...  ...       53        28   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...  ...       43        67   \n",
       "3  [pleasure, opportunity, address, influential, ...  ...       62        56   \n",
       "4  [long, time, fan, sander, delight, participate...  ...       72        62   \n",
       "\n",
       "   uncertainty  litigious  strong  weak  constraining  word_count_sentiment  \\\n",
       "0           32          5      10    15            13                   217   \n",
       "1           35          2       3    16            12                   149   \n",
       "2           33          8      11    16            13                   191   \n",
       "3           43          6       7    20             8                   202   \n",
       "4           42          6      12    27            13                   234   \n",
       "\n",
       "   sentiment_lexicon_simple  sentiment_lexicon_weighted  \n",
       "0                 -0.119816                    0.112442  \n",
       "1                 -0.167785                    0.014094  \n",
       "2                  0.125654                    0.421466  \n",
       "3                 -0.029703                    0.227228  \n",
       "4                 -0.042735                    0.227350  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to apply the lexicon to the text\n",
    "def lexicon_score_weighted(tokens):\n",
    "    score = 0\n",
    "    for cat in categories:\n",
    "        count = sum(t in word_sets[cat] for t in tokens)\n",
    "        score += count * category_weights[cat]\n",
    "    return score\n",
    "\n",
    "# Compute counts and store as a new column\n",
    "speeches['sentiment_lexicon_weighted'] = speeches['text_lemmatised'].apply(lexicon_score_weighted) \\\n",
    "                                                    / speeches['word_count_sentiment']\n",
    "\n",
    "# View the DataFrame\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a40391-8fc6-4562-acca-80f6d004b983",
   "metadata": {},
   "source": [
    "### 5. Export the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf47c147-fa1c-447b-8f7c-0a031b265abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to CSV\n",
    "speeches.to_csv('speeches_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c492469-73d6-4519-9b78-5710b37e4283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>['would', 'doubt', 'argue', 'two', 'objectives...</td>\n",
       "      <td>['would', 'doubt', 'argue', 'two', 'objective'...</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.119816</td>\n",
       "      <td>0.112442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>['today', 'wish', 'talk', 'real', 'interest', ...</td>\n",
       "      <td>['today', 'wish', 'talk', 'real', 'interest', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>['welcome', 'opportunity', 'talk', 'prospects'...</td>\n",
       "      <td>['welcome', 'opportunity', 'talk', 'prospect',...</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>191</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.421466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>['pleasure', 'opportunity', 'address', 'influe...</td>\n",
       "      <td>['pleasure', 'opportunity', 'address', 'influe...</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>-0.029703</td>\n",
       "      <td>0.227228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>['long', 'time', 'fan', 'sanders', 'delighted'...</td>\n",
       "      <td>['long', 'time', 'fan', 'sander', 'delight', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>0.227350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  ['would', 'doubt', 'argue', 'two', 'objectives...   \n",
       "1  ['today', 'wish', 'talk', 'real', 'interest', ...   \n",
       "2  ['welcome', 'opportunity', 'talk', 'prospects'...   \n",
       "3  ['pleasure', 'opportunity', 'address', 'influe...   \n",
       "4  ['long', 'time', 'fan', 'sanders', 'delighted'...   \n",
       "\n",
       "                                     text_lemmatised  ... negative  positive  \\\n",
       "0  ['would', 'doubt', 'argue', 'two', 'objective'...  ...       84        58   \n",
       "1  ['today', 'wish', 'talk', 'real', 'interest', ...  ...       53        28   \n",
       "2  ['welcome', 'opportunity', 'talk', 'prospect',...  ...       43        67   \n",
       "3  ['pleasure', 'opportunity', 'address', 'influe...  ...       62        56   \n",
       "4  ['long', 'time', 'fan', 'sander', 'delight', '...  ...       72        62   \n",
       "\n",
       "   uncertainty  litigious  strong  weak  constraining  word_count_sentiment  \\\n",
       "0           32          5      10    15            13                   217   \n",
       "1           35          2       3    16            12                   149   \n",
       "2           33          8      11    16            13                   191   \n",
       "3           43          6       7    20             8                   202   \n",
       "4           42          6      12    27            13                   234   \n",
       "\n",
       "   sentiment_lexicon_simple  sentiment_lexicon_weighted  \n",
       "0                 -0.119816                    0.112442  \n",
       "1                 -0.167785                    0.014094  \n",
       "2                  0.125654                    0.421466  \n",
       "3                 -0.029703                    0.227228  \n",
       "4                 -0.042735                    0.227350  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file as speeches\n",
    "speeches_test = pd.read_csv('/Users/kaferrante/Documents/Python/_Course4_Project/speeches_sentiment.csv')\n",
    "\n",
    "# View the DataFrame\n",
    "speeches_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fa52c69-4251-4765-81ab-14aeb20471eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7721 entries, 0 to 7720\n",
      "Data columns (total 23 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   reference                   7721 non-null   object \n",
      " 1   country                     7721 non-null   object \n",
      " 2   date                        7721 non-null   object \n",
      " 3   title                       7721 non-null   object \n",
      " 4   author                      7721 non-null   object \n",
      " 5   is_gov                      7721 non-null   int64  \n",
      " 6   text                        7721 non-null   object \n",
      " 7   text_cleaned                7721 non-null   object \n",
      " 8   text_tokenised              7721 non-null   object \n",
      " 9   text_lemmatised             7721 non-null   object \n",
      " 10  text_lemmatised_str         7721 non-null   object \n",
      " 11  word_count_text             7721 non-null   int64  \n",
      " 12  word_count_text_cleaned     7721 non-null   int64  \n",
      " 13  negative                    7721 non-null   int64  \n",
      " 14  positive                    7721 non-null   int64  \n",
      " 15  uncertainty                 7721 non-null   int64  \n",
      " 16  litigious                   7721 non-null   int64  \n",
      " 17  strong                      7721 non-null   int64  \n",
      " 18  weak                        7721 non-null   int64  \n",
      " 19  constraining                7721 non-null   int64  \n",
      " 20  word_count_sentiment        7721 non-null   int64  \n",
      " 21  sentiment_lexicon_simple    7720 non-null   float64\n",
      " 22  sentiment_lexicon_weighted  7720 non-null   float64\n",
      "dtypes: float64(2), int64(11), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "speeches_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2bea5-f22a-46bd-a9c5-21ed50f3a88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
