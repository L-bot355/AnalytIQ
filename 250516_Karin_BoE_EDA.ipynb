{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de1e30b-c1ca-4623-8b5b-66d6f09a0d79",
   "metadata": {},
   "source": [
    "# Bank of England Sentiment Analysis\n",
    "## Employer Project\n",
    "### Team 8 AnalytIQ, June 2nd, 2025\n",
    "**Team Members**: Lalitha Vemuri, Christina Tsoulfa, Reka Bodo, Yann Hirsig, Louis Pang, Dr. Karin Agius Ferrante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc09fa-f863-4b6a-8d83-8e8935064bb8",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. Approach\n",
    "2. Load the Data\n",
    "4. Exploratory Sentiment Analysis & Natural Language Processing (NLP)\n",
    "5. Exploratory Analysis for Correlation with Economic Indicators\n",
    "8. Insights & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a093e-a3cc-420f-96ae-f55c272bd61e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7223da-fd61-42d4-98c5-ca16e195acf7",
   "metadata": {},
   "source": [
    "## 1. Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b79b3-9bdb-411d-b25f-ec6c55526527",
   "metadata": {},
   "source": [
    "The **Bank of England (BoE)**, the UK’s central bank and one of the world’s leading financial institutions, plays a pivotal role in maintaining economic and financial stability, and supporting the UK government’s economic policies. One of its key communication channels with the public and markets is through formal speeches delivered by its representatives. These speeches aim to offer guidance, manage expectations, and provide clarity in times of uncertainty.\n",
    "\n",
    "However, the effectiveness and impact of these speeches on economic indicators and market behaviour are not fully understood. \n",
    "\n",
    "This project seeks to explore whether the sentiment and timing of BoE speeches hold analytical or predictive value, when compared with economic performance and key events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29c6dd-8ae8-47da-96ec-94601d52a130",
   "metadata": {},
   "source": [
    "### Main Business Questions\n",
    "**Has the tone or sentiment of the BoE’s speeches evolved over time? If so, how?**<br>\n",
    "**How do sentiments align with events like interest rate changes, policy reports, or major economic releases?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318b1e3-a0dd-418c-a116-36bc7c7780ad",
   "metadata": {},
   "source": [
    "**Sub-questions**\n",
    "\n",
    "1.\tAre there measurable correlations between speech sentiment and UK economic indicators such as inflation, GDP, employment rates and bond yields?\n",
    "2. Does the change in sentiment change economic indicators or is the speech sentiment reactive to economic indicators?\n",
    "3. Can speech sentiment trends be used to predict market reactions or economic outcomes?\n",
    "4. What broader insights can be drawn to support data-informed communication strategies?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78340774-7c96-428a-a66f-c3dcc087be3e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958697d8-8039-440d-9169-ec5f798b14c9",
   "metadata": {},
   "source": [
    "## 2. Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c3f7a-739c-4d97-a2c1-065610f230dd",
   "metadata": {},
   "source": [
    "### 2.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defc712-fa64-4482-bafd-9023f4114927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries.\n",
    "# !pip install nltk\n",
    "# !pip install vaderSentiment\n",
    "# !pip install textblob\n",
    "# !pip install pandas openpyxl\n",
    "# !pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd6da6-73ce-4489-b7f3-6f84966ad913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('words')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0158b855-53c2-4032-92b7-8eacd78bcbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np                             # Numerical operations and array handling.\n",
    "import pandas as pd                            # Data manipulation and analysis.\n",
    "import contractions                            # Expanding/contracting text contractions.\n",
    "import re                                      # Regular expression operations on strings.\n",
    "import os                                      # Interacting with the operating system and file handling.\n",
    "import matplotlib.pyplot as plt                # Create visualisations.\n",
    "from matplotlib.colors import rgb2hex          # Colour conversion in plots.\n",
    "import seaborn as sns                          # Enhanced statistical data visualisations.\n",
    "import math                                    # Mathematical functions and constants.\n",
    "from IPython.display import display, Markdown  # Rich output in Jupyter.\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import  Counter\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose   # Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad1c8f7-532b-49bd-87fd-53b8f450f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text and Sentiment Analysis \n",
    "from wordcloud import WordCloud                                       # Generating visual word frequency clouds from text.\n",
    "import nltk                                                           # Natural language processing tasks.\n",
    "from nltk import word_tokenize, pos_tag                               # Splitting text into words and tags with part of speech\n",
    "from nltk import defaultdict                                          # Providing default values for nonexistent keys.\n",
    "from nltk.probability import FreqDist                                 # Calculating frequency distribution of tokens.\n",
    "from nltk.corpus import stopwords                                     # Providing list of common words to exclude from analysis.\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet as wn                                 # Lexical database for retrieving word relationships & meanings.\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer                # Reducing words to base or root form.\n",
    "from nltk.probability import FreqDist\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer  # Assessing sentiment intensity in text.\n",
    "from textblob import TextBlob                                         # API for text processing tasks including sentiment analysis.\n",
    "import contractions                                                   # Expanding/contracting text contractions.\n",
    "import re                                                             # Regular expression operations on strings.\n",
    "import ast                                                            # If column contains string representations of lists\n",
    "from collections import defaultdict  # Creating dictionaries that return default value for nonexistent keys.\n",
    "from collections import Counter  # Importing Counter for counting hashable objects and efficiently tallying occurrences in an iterable.\n",
    "from transformers import AutoTokenizer                                # FinBERT Model\n",
    "from transformers import AutoModelForSequenceClassification           # FinBERT Model\n",
    "import torch                                                          # FinBERT Model\n",
    "import torch.nn.functional as F                                       # FinBERT Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49bc0fbf-ccf3-4bb6-af0e-a540151ebd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import warnings\n",
    "import warnings\n",
    "# Settings for the notebook.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf5c9f0-0482-4185-a651-02a7f83b98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure style for seaborn.\n",
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f73649-b44e-4791-b9c9-6e13dbf2f4f8",
   "metadata": {},
   "source": [
    "### 2.2. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac578f-e501-4df1-a182-d5cc11b94b82",
   "metadata": {},
   "source": [
    "**2.2.a. Charts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63cab6da-db6e-445b-8910-89e2b6b7abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_label(label):\n",
    "    # If label is a Series, return its name.\n",
    "    if isinstance(label, pd.Series):\n",
    "        return label.name.replace('_', ' ').title() if label.name else ' '\n",
    "    elif isinstance(label, str):\n",
    "        return label.replace('_', ' ').title()\n",
    "    return ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b15f0044-0695-41c8-aa28-0fa75c91a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scatterplot.\n",
    "def generate_scatterplot(df, x_axis, y_axis, title, hue, save_path=None):\n",
    "\n",
    "    # Set figure size & style for seaborn.\n",
    "    sns.set_theme(style='darkgrid')\n",
    "    sns.set(rc={'figure.figsize':(8, 6)})\n",
    "\n",
    "    # Plot the scatterplot.\n",
    "    sns.scatterplot(data=df, x=x_axis, y=y_axis, hue=hue, color='#0e1b2c')\n",
    "\n",
    "    # Customize the plot.\n",
    "    plt.title(title, fontsize=12, fontweight='bold')\n",
    "    plt.xlabel(clean_label(x_axis), fontsize=10)\n",
    "    plt.ylabel(clean_label(y_axis), fontsize=10)\n",
    "\n",
    "    # Add legend ONLY if hue is not None.\n",
    "    if hue is not None:\n",
    "        plt.legend(title='Legend', fontsize=10, bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "    \n",
    "    # Save the plot, if save_path is provided.\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=500, bbox_inches='tight')\n",
    "\n",
    "    # Display the chart.\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc3e2b0-0ce4-4885-91e6-365802ff7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to plot a lineplot.\n",
    "def generate_lineplot(df, x_axis, y_axis, title, ylim=None, save_path=None, \\\n",
    "                      rotate_xticks=False):\n",
    "    \n",
    "    # Set figure size & style for seaborn.\n",
    "    sns.set_theme(style='darkgrid')\n",
    "    sns.set(rc={'figure.figsize':(14, 8)})\n",
    "    \n",
    "    # Ensure time column is in datetime format.\n",
    "    df[x_axis] = pd.to_datetime(df[x_axis])\n",
    "    \n",
    "    # Sort DataFrame by the time column.\n",
    "    df.sort_values(by=x_axis, inplace=True)\n",
    "    \n",
    "    # Plot the lineplot.\n",
    "    sns.lineplot(data=df, x=x_axis, y=y_axis, label=clean_label(y_axis))\n",
    "    \n",
    "    # Customize the plot.\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(clean_label(x_axis), fontsize=14)\n",
    "    plt.ylabel(clean_label(y_axis), fontsize=14)\n",
    "    plt.legend(title='Legend', fontsize=12, bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "    plt.tick_params(axis='both', labelsize=12)\n",
    "    \n",
    "    # Rotate x-tick labels by 45 degrees, if specified.\n",
    "    if rotate_xticks:\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    # Set y-axis limits, if provided.\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    # Save the plot, if save_path is provided.\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=500, bbox_inches='tight')\n",
    "    \n",
    "    # Display the chart.\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409922dc-0c41-4ec5-9c45-a2bb32fe39c9",
   "metadata": {},
   "source": [
    "**2.2.b. NLP analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21cb5313-5a46-4bd9-b663-575ae941506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = contractions.fix(text)  # Expand contractions i.e I'm not good goes to I am not good\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub('#', '', text)         # Remove hashtags\n",
    "    text = re.sub(r'\\W', ' ', text)      # Remove special characters\n",
    "    text = text.lower()                  # Convert to lowercase\n",
    "    #Below is to create a set of stop words from the NLTK library's predefined list but not is excluded.\n",
    "    stop_words = set(stopwords.words('english')) - {'not'} \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5a3ee7-2211-4500-90d0-5209d48a5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tag map for POS tagging.\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "# Lemmatise the tokens with correct POS tags.\n",
    "lemma_function = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatisation function.\n",
    "def lemmatize_tokens(tokens):\n",
    "    #For each word in the token list, it lemmatizes the word with the correct part-of-speech\n",
    "    lemmatized_tokens = [lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens)]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1234ed84-70c2-4557-b84e-134de231f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER Sentiment Intensity Analyzer.\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define the function to compute and return sentiment scores.\n",
    "def analyse_sentiment(text):\n",
    "    return analyzer.polarity_scores(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b55c65-06da-4b24-84f1-96672561902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to label sentiments.\n",
    "def get_sentiment_label(compound):\n",
    "    if compound >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3ab9ecb-6fce-4ecb-9a8d-a667131b2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract a polarity score using TextBlob.\n",
    "def generate_polarity(comment):\n",
    "    return TextBlob(comment).sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efe29c3c-6d53-4c13-91b3-6ca22e8b5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract a subjectivity score using TextBlob.\n",
    "def generate_subjectivity(comment):\n",
    "    return TextBlob(comment).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fb950-265f-4c85-8b92-a0a66ecc86be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b744bfb3-b165-4ee6-8795-d3573893dccf",
   "metadata": {},
   "source": [
    "### 2.3. Import and review the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e6896-dc88-49a0-9e3b-4c69055c92e7",
   "metadata": {},
   "source": [
    "**2.3.a. Import Bank of England Speeches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48001caf-56c3-4957-b59a-e0e49d630639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \n",
       "0  fraser       0  They would no doubt argue that to have two obj...  \n",
       "1  fraser       0  Today I wish to talk about real interest rates...  \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...  \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...  \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file as speeches.\n",
    "speeches_original = pd.read_csv('/Users/kaferrante/Documents/Python/_Course4_Project/all_speeches.csv')\n",
    "\n",
    "# View the data.\n",
    "speeches_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72524c5a-f934-4fe6-88d0-e732470c4d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7721 entries, 0 to 7720\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   reference  7721 non-null   object\n",
      " 1   country    7721 non-null   object\n",
      " 2   date       7721 non-null   object\n",
      " 3   title      7721 non-null   object\n",
      " 4   author     7721 non-null   object\n",
      " 5   is_gov     7721 non-null   int64 \n",
      " 6   text       7721 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 422.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore data set.\n",
    "speeches_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0945d52d-f0c6-486b-b357-d3a148fbc039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference    0\n",
       "country      0\n",
       "date         0\n",
       "title        0\n",
       "author       0\n",
       "is_gov       0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "speeches_original.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4046629c-c157-469e-bc54-59c7c4767195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates.\n",
    "speeches_original.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd6a8c6d-0fb0-4a31-9f6f-ee0d0136530f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_gov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7721.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.347235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            is_gov\n",
       "count  7721.000000\n",
       "mean      0.347235\n",
       "std       0.476122\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review basic descriptive statistics.\n",
    "speeches_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0b6a8fa-11b3-47cc-92bd-ee442d0b1722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'canada', 'euro area', 'japan', 'sweden',\n",
       "       'switzerland', 'united kingdom', 'united states'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the countries.\n",
    "speeches_original['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52bce450-6cf2-4395-a037-264fab652a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraser', 'macfarlane', 'lowe', 'stevens', 'no_info', 'ac',\n",
       "       'thiessen', 'bonin', 'dodge', 'jenkins', 'kennedy', 'macklem',\n",
       "       'duguay', 'longworth', 'carney', 'murray', 'lane', 'wolf',\n",
       "       'boivin', 'cote', 'poloz', 'schembri', 'johnson', 'wilkins',\n",
       "       'chilcott', 'mendes', 'patterson', 'murchison', 'leduc', 'dinis',\n",
       "       'beaudry', 'gravelle', 'kozicki', 'rogers', 'morrow', 'lamfalussy',\n",
       "       'duisenberg', 'vienna', 'london', 'tokyo', 'kong', 'bank',\n",
       "       'schioppa', 'hamalainen', 'main', 'noyer', 'committee', 'solans',\n",
       "       'francisco', 'istanbul', 'issing', 'hoogduin', 'bankwashington',\n",
       "       'efma', 'brussels', 'forum', 'workshop', 'quiros', 'papademos',\n",
       "       'gugerell', 'trichet', 'network', 'delivered', 'paramo',\n",
       "       'strasbourg', 'rome', 'berlin', 'smaghi', 'sevilla', 'madrid',\n",
       "       'stark', 'singapore', 'summit', 'washington', 'aires',\n",
       "       'bratislava', 'ecb', 'constancio', 'posen', 'praet', 'draghi',\n",
       "       'coeure', 'asmussen', 'mersch', 'lautenschlager', 'marcel', ']',\n",
       "       'guindos', 'lagarde', 'schnabel', 'panetta', 'elderson',\n",
       "       'matsushita', 'governor', 'taketomi', 'hayami', 'fujiwara',\n",
       "       'yamaguchi', 'ueda', 'nakahara', 'shinotsuka', 'suda', 'fukui',\n",
       "       'muto', 'noda', 'mizuno', 'iwata', 'nakamura', 'kamezaki',\n",
       "       'shirakawa', 'horii', 'miyao', 'nishimura', 'morimoto', 'shirai',\n",
       "       'ishida', 'sato', 'kiuchi', 'kuroda', 'nakaso', 'harada',\n",
       "       'kuwabara', 'funo', 'amamiya', 'masai', 'sakurai', 'suzuki',\n",
       "       'kataoka', 'wakatabe', 'ikeda', 'japan', 'adachi', 'uchida',\n",
       "       'noguchi', 'nakagawa', 'backstrom', 'NO_INFO', 'heikensten',\n",
       "       'ingves', 'crises', 'hessius', 'capital', 'eu', 'nyberg',\n",
       "       'bergstrom', 'environment', 'srejber', 'emu', 'policy', 'persson',\n",
       "       'rosenberg', 'banking', 'responsibility', 'conference', 'oberg',\n",
       "       'forward', 'parak', 'svensson', 'ekholm', 'targeting', 'crisis',\n",
       "       'jansson', 'jochnick', 'skingsley', 'floden', 'ohlsson',\n",
       "       'skinglsey', 'iii', 'breman', 'meyer', 'fuglister', 'gehrig',\n",
       "       'haeberli', 'sporndli', 'roth', 'rich', 'blattner', 'kugler',\n",
       "       'hildebrand', 'raggenbass', 'tornare', 'kohli', 'ammann', 'jordan',\n",
       "       'baltensperger', 'james', 'danthine', 'zurbrugg', 'studer',\n",
       "       'maechler', 'moser', 'pfrunder', 'wiedmer', 'steiner', 'schlegel',\n",
       "       'george', 'king', 'budd', 'vickers', 'buiter', 'julius',\n",
       "       'clementi', 'brealey', 'wadhwani', 'goodhart', 'clark', 'allen',\n",
       "       'plenderleith', 'nickell', 'smout', 'allsopp', 'barker', 'bean',\n",
       "       'jackson', 'fisher', 'bell', 'large', 'young', 'tucker', 'lomax',\n",
       "       'lambert', 'walton', 'gieve', 'blanchflower', 'bond', 'jenkinson',\n",
       "       'sentance', 'besley', 'cbi', 'sentence', 'haldane', 'dale',\n",
       "       'miles', 'bailey', 'cleland', 'weale', 'aikman', 'salmon', 'kohn',\n",
       "       'broadbent', 'cohrs', 'gracie', 'hauser', 'mccafferty', 'adams',\n",
       "       'taylor', 'industry', 'braddick', 'cunliffe', 'furse', 'sharp',\n",
       "       'bulley', 'forbes', 'rule', 'shafik', 'stewart', 'woods',\n",
       "       'brazier', 'saporta', 'moulder', 'vlieghe', 'mills', 'breeden',\n",
       "       'brandon', 'saunders', 'proudman', 'hogg', 'brown', 'gerken',\n",
       "       'john', 'ramsden', 'tenreyro', 'place', 'kashyap', 'nelson',\n",
       "       'churm', 'haskel', 'strange', 'sweeney', 'bake', 'knowles',\n",
       "       'paterson', 'stheeman', 'mutton', 'ramsay', 'rosen', 'hall',\n",
       "       'truran', 'pill', 'mann', 'sheppard', 'mackinnon', 'claus',\n",
       "       'benjamin', 'bowe', 'greenspan', 'phillips', 'kelley', 'rivlin',\n",
       "       'gramlich', 'ferguson', 'olson', 'bies', 'bernanke', 'sack',\n",
       "       'reinhart', 'kroszner', 'warsh', 'mishkin', 'duke', 'tarullo',\n",
       "       'madigan', 'yellen', 'raskin', 'stein', 'powell', 'fischer',\n",
       "       'brainard', 'quarles', 'clarida', 'bowman', 'waller', 'barr',\n",
       "       'jefferson', 'cook'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the author.\n",
    "speeches_original['author'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490fbe7-e981-4d7e-a82f-c062f5451c0a",
   "metadata": {},
   "source": [
    "**2.3.b. Import Lexicon Sentiment based on BoE Wordlist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9797b2c-984a-43c9-864b-1ccd2b52a046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>['would', 'doubt', 'argue', 'two', 'objectives...</td>\n",
       "      <td>['would', 'doubt', 'argue', 'two', 'objective'...</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.119816</td>\n",
       "      <td>0.112442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>['today', 'wish', 'talk', 'real', 'interest', ...</td>\n",
       "      <td>['today', 'wish', 'talk', 'real', 'interest', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>['welcome', 'opportunity', 'talk', 'prospects'...</td>\n",
       "      <td>['welcome', 'opportunity', 'talk', 'prospect',...</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>191</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.421466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>['pleasure', 'opportunity', 'address', 'influe...</td>\n",
       "      <td>['pleasure', 'opportunity', 'address', 'influe...</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>-0.029703</td>\n",
       "      <td>0.227228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>['long', 'time', 'fan', 'sanders', 'delighted'...</td>\n",
       "      <td>['long', 'time', 'fan', 'sander', 'delight', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>0.227350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  ['would', 'doubt', 'argue', 'two', 'objectives...   \n",
       "1  ['today', 'wish', 'talk', 'real', 'interest', ...   \n",
       "2  ['welcome', 'opportunity', 'talk', 'prospects'...   \n",
       "3  ['pleasure', 'opportunity', 'address', 'influe...   \n",
       "4  ['long', 'time', 'fan', 'sanders', 'delighted'...   \n",
       "\n",
       "                                     text_lemmatised  ... negative  positive  \\\n",
       "0  ['would', 'doubt', 'argue', 'two', 'objective'...  ...       84        58   \n",
       "1  ['today', 'wish', 'talk', 'real', 'interest', ...  ...       53        28   \n",
       "2  ['welcome', 'opportunity', 'talk', 'prospect',...  ...       43        67   \n",
       "3  ['pleasure', 'opportunity', 'address', 'influe...  ...       62        56   \n",
       "4  ['long', 'time', 'fan', 'sander', 'delight', '...  ...       72        62   \n",
       "\n",
       "   uncertainty  litigious  strong  weak  constraining  word_count_sentiment  \\\n",
       "0           32          5      10    15            13                   217   \n",
       "1           35          2       3    16            12                   149   \n",
       "2           33          8      11    16            13                   191   \n",
       "3           43          6       7    20             8                   202   \n",
       "4           42          6      12    27            13                   234   \n",
       "\n",
       "   sentiment_lexicon_simple  sentiment_lexicon_weighted  \n",
       "0                 -0.119816                    0.112442  \n",
       "1                 -0.167785                    0.014094  \n",
       "2                  0.125654                    0.421466  \n",
       "3                 -0.029703                    0.227228  \n",
       "4                 -0.042735                    0.227350  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file of BoE sentiment labelled wordlist.\n",
    "speeches = pd.read_csv('/Users/kaferrante/Documents/Python/_Course4_Project/speeches_sentiment.csv')\n",
    "\n",
    "# View the data.\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bcf30e9-ae9b-4fea-b565-ad5167942926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7721 entries, 0 to 7720\n",
      "Data columns (total 23 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   reference                   7721 non-null   object \n",
      " 1   country                     7721 non-null   object \n",
      " 2   date                        7721 non-null   object \n",
      " 3   title                       7721 non-null   object \n",
      " 4   author                      7721 non-null   object \n",
      " 5   is_gov                      7721 non-null   int64  \n",
      " 6   text                        7721 non-null   object \n",
      " 7   text_cleaned                7721 non-null   object \n",
      " 8   text_tokenised              7721 non-null   object \n",
      " 9   text_lemmatised             7721 non-null   object \n",
      " 10  text_lemmatised_str         7721 non-null   object \n",
      " 11  word_count_text             7721 non-null   int64  \n",
      " 12  word_count_text_cleaned     7721 non-null   int64  \n",
      " 13  negative                    7721 non-null   int64  \n",
      " 14  positive                    7721 non-null   int64  \n",
      " 15  uncertainty                 7721 non-null   int64  \n",
      " 16  litigious                   7721 non-null   int64  \n",
      " 17  strong                      7721 non-null   int64  \n",
      " 18  weak                        7721 non-null   int64  \n",
      " 19  constraining                7721 non-null   int64  \n",
      " 20  word_count_sentiment        7721 non-null   int64  \n",
      " 21  sentiment_lexicon_simple    7721 non-null   float64\n",
      " 22  sentiment_lexicon_weighted  7721 non-null   float64\n",
      "dtypes: float64(2), int64(11), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Explore data set.\n",
    "speeches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c36846e8-ccf1-406c-98d9-1962a7d9908a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference                     0\n",
       "country                       0\n",
       "date                          0\n",
       "title                         0\n",
       "author                        0\n",
       "is_gov                        0\n",
       "text                          0\n",
       "text_cleaned                  0\n",
       "text_tokenised                0\n",
       "text_lemmatised               0\n",
       "text_lemmatised_str           0\n",
       "word_count_text               0\n",
       "word_count_text_cleaned       0\n",
       "negative                      0\n",
       "positive                      0\n",
       "uncertainty                   0\n",
       "litigious                     0\n",
       "strong                        0\n",
       "weak                          0\n",
       "constraining                  0\n",
       "word_count_sentiment          0\n",
       "sentiment_lexicon_simple      0\n",
       "sentiment_lexicon_weighted    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "speeches.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0ab24e4-2aee-4160-9fc2-09aad4b4d902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates.\n",
    "speeches.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "835caca0-969d-45a8-bf4e-1de6371c9181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_gov</th>\n",
       "      <th>word_count_text</th>\n",
       "      <th>word_count_text_cleaned</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "      <td>7721.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.347235</td>\n",
       "      <td>3113.002072</td>\n",
       "      <td>1776.809222</td>\n",
       "      <td>68.278073</td>\n",
       "      <td>55.249968</td>\n",
       "      <td>45.351768</td>\n",
       "      <td>11.074343</td>\n",
       "      <td>5.342831</td>\n",
       "      <td>18.962958</td>\n",
       "      <td>11.482709</td>\n",
       "      <td>215.742650</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>0.201127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476122</td>\n",
       "      <td>2047.797030</td>\n",
       "      <td>1174.241676</td>\n",
       "      <td>55.675494</td>\n",
       "      <td>37.151788</td>\n",
       "      <td>43.173626</td>\n",
       "      <td>15.827917</td>\n",
       "      <td>4.827564</td>\n",
       "      <td>18.883414</td>\n",
       "      <td>12.094693</td>\n",
       "      <td>154.677042</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.233665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>-0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1081.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>-0.146341</td>\n",
       "      <td>0.039130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>1656.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>-0.039823</td>\n",
       "      <td>0.178968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3879.000000</td>\n",
       "      <td>2219.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0.082902</td>\n",
       "      <td>0.341406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37522.000000</td>\n",
       "      <td>23119.000000</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>3206.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            is_gov  word_count_text  word_count_text_cleaned     negative  \\\n",
       "count  7721.000000      7721.000000              7721.000000  7721.000000   \n",
       "mean      0.347235      3113.002072              1776.809222    68.278073   \n",
       "std       0.476122      2047.797030              1174.241676    55.675494   \n",
       "min       0.000000        16.000000                18.000000     0.000000   \n",
       "25%       0.000000      1906.000000              1081.000000    31.000000   \n",
       "50%       0.000000      2904.000000              1656.000000    57.000000   \n",
       "75%       1.000000      3879.000000              2219.000000    91.000000   \n",
       "max       1.000000     37522.000000             23119.000000  1251.000000   \n",
       "\n",
       "          positive  uncertainty    litigious       strong         weak  \\\n",
       "count  7721.000000  7721.000000  7721.000000  7721.000000  7721.000000   \n",
       "mean     55.249968    45.351768    11.074343     5.342831    18.962958   \n",
       "std      37.151788    43.173626    15.827917     4.827564    18.883414   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      31.000000    19.000000     3.000000     2.000000     8.000000   \n",
       "50%      49.000000    35.000000     6.000000     4.000000    15.000000   \n",
       "75%      71.000000    60.000000    14.000000     7.000000    25.000000   \n",
       "max    1042.000000   893.000000   351.000000    70.000000   422.000000   \n",
       "\n",
       "       constraining  word_count_sentiment  sentiment_lexicon_simple  \\\n",
       "count   7721.000000           7721.000000               7721.000000   \n",
       "mean      11.482709            215.742650                 -0.023590   \n",
       "std       12.094693            154.677042                  0.179100   \n",
       "min        0.000000              0.000000                 -0.782609   \n",
       "25%        5.000000            120.000000                 -0.146341   \n",
       "50%        9.000000            195.000000                 -0.039823   \n",
       "75%       15.000000            277.000000                  0.082902   \n",
       "max      262.000000           3206.000000                  1.000000   \n",
       "\n",
       "       sentiment_lexicon_weighted  \n",
       "count                 7721.000000  \n",
       "mean                     0.201127  \n",
       "std                      0.233665  \n",
       "min                     -0.833333  \n",
       "25%                      0.039130  \n",
       "50%                      0.178968  \n",
       "75%                      0.341406  \n",
       "max                      1.500000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review basic descriptive statistics.\n",
    "speeches.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9cd47d0-6d2e-4a9e-80e6-b5e0e64c04bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference                     7721\n",
       "country                          8\n",
       "date                          4410\n",
       "title                         6218\n",
       "author                         325\n",
       "is_gov                           2\n",
       "text                          7692\n",
       "text_cleaned                  7691\n",
       "text_tokenised                7691\n",
       "text_lemmatised               7691\n",
       "text_lemmatised_str           7691\n",
       "word_count_text               4183\n",
       "word_count_text_cleaned       3074\n",
       "negative                       293\n",
       "positive                       225\n",
       "uncertainty                    245\n",
       "litigious                      120\n",
       "strong                          42\n",
       "weak                           126\n",
       "constraining                    98\n",
       "word_count_sentiment           681\n",
       "sentiment_lexicon_simple      5426\n",
       "sentiment_lexicon_weighted    7276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values.\n",
    "speeches.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffbffa96-9bf0-4e53-8330-541086a12e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a normalized version of the 'text' column\n",
    "speeches['text_norm'] = speeches['text'].str.strip().str.lower()\n",
    "\n",
    "# Find duplicate 'text_norm' entries\n",
    "duplicate_mask = speeches['text_norm'].duplicated(keep=False)\n",
    "\n",
    "# Extract all duplicates based on normalized text\n",
    "duplicates = speeches[duplicate_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dda92072-c139-41eb-9f0f-40d9df005e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>positive</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>litigious</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "      <th>text_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>r101026a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2010-10-26</td>\n",
       "      <td>Opening Statement before the House of Commons ...</td>\n",
       "      <td>carney</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Good afternoon,...</td>\n",
       "      <td>governor bank canada good afternoon mr chairma...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>governor of the bank of canada good afternoon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>r101027a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>Opening Statement before the Standing Senate C...</td>\n",
       "      <td>carney</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Good afternoon,...</td>\n",
       "      <td>governor bank canada good afternoon mr chairma...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>governor of the bank of canada good afternoon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>r120424a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2012-04-24</td>\n",
       "      <td>Opening Statement before the House of Commons ...</td>\n",
       "      <td>carney</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Good afternoon....</td>\n",
       "      <td>governor bank canada good afternoon tiff pleas...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>governor of the bank of canada good afternoon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>r120425a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>Opening Statement before the Senate Standing C...</td>\n",
       "      <td>carney</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Good afternoon....</td>\n",
       "      <td>governor bank canada good afternoon tiff pleas...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>governor of the bank of canada good afternoon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>r121030a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2012-10-30</td>\n",
       "      <td>Opening Statement before the House of Commons ...</td>\n",
       "      <td>carney</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Good afternoon....</td>\n",
       "      <td>governor bank canada good afternoon tiff pleas...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.286765</td>\n",
       "      <td>governor of the bank of canada good afternoon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>r121031a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>Opening Statement before the Standing Senate C...</td>\n",
       "      <td>carney</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Good afternoon....</td>\n",
       "      <td>governor bank canada good afternoon tiff pleas...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'good', 'aftern...</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.286765</td>\n",
       "      <td>governor of the bank of canada good afternoon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>r140429a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>Opening Statement before the House of Commons ...</td>\n",
       "      <td>poloz</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Thank you for t...</td>\n",
       "      <td>governor bank canada thank opportunity tiff to...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'thank', 'oppor...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'thank', 'oppor...</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.393976</td>\n",
       "      <td>governor of the bank of canada thank you for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>r140430a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>Opening Statement before the Senate Standing C...</td>\n",
       "      <td>poloz</td>\n",
       "      <td>1</td>\n",
       "      <td>Governor of the Bank of Canada Thank you for t...</td>\n",
       "      <td>governor bank canada thank opportunity tiff to...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'thank', 'oppor...</td>\n",
       "      <td>['governor', 'bank', 'canada', 'thank', 'oppor...</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.393976</td>\n",
       "      <td>governor of the bank of canada thank you for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>r020121a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2002-01-21</td>\n",
       "      <td>Securities and banking: bridges and walls</td>\n",
       "      <td>no_info</td>\n",
       "      <td>0</td>\n",
       "      <td>I once again find myself speaking at the Londo...</td>\n",
       "      <td>find speaking london school economics mileston...</td>\n",
       "      <td>['find', 'speaking', 'london', 'school', 'econ...</td>\n",
       "      <td>['find', 'speaking', 'london', 'school', 'econ...</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>557</td>\n",
       "      <td>-0.062837</td>\n",
       "      <td>0.105745</td>\n",
       "      <td>i once again find myself speaking at the londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>r020221a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2002-02-21</td>\n",
       "      <td>Securities and banking: bridges and walls</td>\n",
       "      <td>schioppa</td>\n",
       "      <td>0</td>\n",
       "      <td>I once again find myself speaking at the Londo...</td>\n",
       "      <td>find speaking london school economics mileston...</td>\n",
       "      <td>['find', 'speaking', 'london', 'school', 'econ...</td>\n",
       "      <td>['find', 'speaking', 'london', 'school', 'econ...</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>557</td>\n",
       "      <td>-0.062837</td>\n",
       "      <td>0.105745</td>\n",
       "      <td>i once again find myself speaking at the londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>r180507a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>Economic developments in the euro area</td>\n",
       "      <td>praet</td>\n",
       "      <td>0</td>\n",
       "      <td>After several quarters of higher than expected...</td>\n",
       "      <td>several quarters higher expected growth latest...</td>\n",
       "      <td>['several', 'quarters', 'higher', 'expected', ...</td>\n",
       "      <td>['several', 'quarter', 'higher', 'expected', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>after several quarters of higher than expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>r180514c_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>Economic developments in the euro area</td>\n",
       "      <td>praet</td>\n",
       "      <td>0</td>\n",
       "      <td>After several quarters of higher than expected...</td>\n",
       "      <td>several quarters higher expected growth latest...</td>\n",
       "      <td>['several', 'quarters', 'higher', 'expected', ...</td>\n",
       "      <td>['several', 'quarter', 'higher', 'expected', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>after several quarters of higher than expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>r981210a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>1998-12-10</td>\n",
       "      <td>Statement by Masaru Hayami, Governor of the Ba...</td>\n",
       "      <td>hayami</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you very much for giving us this opportu...</td>\n",
       "      <td>thank much giving us opportunity explain monet...</td>\n",
       "      <td>['thank', 'much', 'giving', 'us', 'opportunity...</td>\n",
       "      <td>['thank', 'much', 'give', 'u', 'opportunity', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>thank you very much for giving us this opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>r981211a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>1998-12-11</td>\n",
       "      <td>Statement by Masaru Hayami, Governor of the Ba...</td>\n",
       "      <td>hayami</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you very much for giving us this opportu...</td>\n",
       "      <td>thank much giving us opportunity explain monet...</td>\n",
       "      <td>['thank', 'much', 'giving', 'us', 'opportunity...</td>\n",
       "      <td>['thank', 'much', 'give', 'u', 'opportunity', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>thank you very much for giving us this opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>r071101a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2007-11-01</td>\n",
       "      <td>NO_INFO</td>\n",
       "      <td>no_info</td>\n",
       "      <td>0</td>\n",
       "      <td>The Bank of Japan submitted its for the second...</td>\n",
       "      <td>bank japan submitted second half fiscal 2006 d...</td>\n",
       "      <td>['bank', 'japan', 'submitted', 'second', 'half...</td>\n",
       "      <td>['bank', 'japan', 'submit', 'second', 'half', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>the bank of japan submitted its for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>r071102a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2007-11-02</td>\n",
       "      <td>NO_INFO</td>\n",
       "      <td>no_info</td>\n",
       "      <td>0</td>\n",
       "      <td>The Bank of Japan submitted its for the second...</td>\n",
       "      <td>bank japan submitted second half fiscal 2006 d...</td>\n",
       "      <td>['bank', 'japan', 'submitted', 'second', 'half...</td>\n",
       "      <td>['bank', 'japan', 'submit', 'second', 'half', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>the bank of japan submitted its for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>r100413a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2010-04-13</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>shirakawa</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Masaaki Shirakawa, Governor of th...</td>\n",
       "      <td>statement masaaki shirakawa governor bank japa...</td>\n",
       "      <td>['statement', 'masaaki', 'shirakawa', 'governo...</td>\n",
       "      <td>['statement', 'masaaki', 'shirakawa', 'governo...</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>statement by masaaki shirakawa, governor of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>r100420a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2010-04-20</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>shirakawa</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Masaaki Shirakawa, Governor of th...</td>\n",
       "      <td>statement masaaki shirakawa governor bank japa...</td>\n",
       "      <td>['statement', 'masaaki', 'shirakawa', 'governo...</td>\n",
       "      <td>['statement', 'masaaki', 'shirakawa', 'governo...</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>statement by masaaki shirakawa, governor of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>r150610a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2015-06-10</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>r150616a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>r161102a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.630233</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>r161122a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.630233</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>r181206a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.767568</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>r181207a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.767568</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>r191119a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>r191129a_BOJ</td>\n",
       "      <td>japan</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>The Bank's Semiannual Report on Currency and M...</td>\n",
       "      <td>kuroda</td>\n",
       "      <td>1</td>\n",
       "      <td>Statement by Haruhiko Kuroda, Governor of the ...</td>\n",
       "      <td>statement haruhiko kuroda governor bank japan ...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>['statement', 'haruhiko', 'kuroda', 'governor'...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>statement by haruhiko kuroda, governor of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>r061024a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2006-10-24</td>\n",
       "      <td>Globalisation and Inflation</td>\n",
       "      <td>bean</td>\n",
       "      <td>0</td>\n",
       "      <td>Madonna\", given the 90 million hits that her n...</td>\n",
       "      <td>madonna given 90 million hits name brings term...</td>\n",
       "      <td>['madonna', 'given', '90', 'million', 'hits', ...</td>\n",
       "      <td>['madonna', 'give', '90', 'million', 'hit', 'n...</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.283158</td>\n",
       "      <td>madonna\", given the 90 million hits that her n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>r150226a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2015-02-26</td>\n",
       "      <td>Goodbye ambiguity, hello clarity: the Bank of ...</td>\n",
       "      <td>shafik</td>\n",
       "      <td>0</td>\n",
       "      <td>Bank of England's relationship with financial ...</td>\n",
       "      <td>bank england relationship financial markets pa...</td>\n",
       "      <td>['bank', 'england', 'relationship', 'financial...</td>\n",
       "      <td>['bank', 'england', 'relationship', 'financial...</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>171</td>\n",
       "      <td>-0.040936</td>\n",
       "      <td>0.225731</td>\n",
       "      <td>bank of england's relationship with financial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>r190517a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>Citizens in service, not people in power</td>\n",
       "      <td>brazier</td>\n",
       "      <td>0</td>\n",
       "      <td>Dimitri Demekas and Paul Tucker for helpful di...</td>\n",
       "      <td>dimitri demekas paul tucker helpful discussion...</td>\n",
       "      <td>['dimitri', 'demekas', 'paul', 'tucker', 'help...</td>\n",
       "      <td>['dimitri', 'demekas', 'paul', 'tucker', 'help...</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>246</td>\n",
       "      <td>-0.203252</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>dimitri demekas and paul tucker for helpful di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>r200903a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>Reinventing the wheel (with more automation)</td>\n",
       "      <td>bailey</td>\n",
       "      <td>1</td>\n",
       "      <td>The Covid-19 pandemic is having a severely dis...</td>\n",
       "      <td>covid 19 pandemic severely disruptive economic...</td>\n",
       "      <td>['covid', '19', 'pandemic', 'severely', 'disru...</td>\n",
       "      <td>['covid', '19', 'pandemic', 'severely', 'disru...</td>\n",
       "      <td>...</td>\n",
       "      <td>289</td>\n",
       "      <td>829</td>\n",
       "      <td>190</td>\n",
       "      <td>25</td>\n",
       "      <td>422</td>\n",
       "      <td>200</td>\n",
       "      <td>3206</td>\n",
       "      <td>-0.300062</td>\n",
       "      <td>-0.168808</td>\n",
       "      <td>the covid-19 pandemic is having a severely dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>r200909a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Paving the way forward: managing climate risk ...</td>\n",
       "      <td>sweeney</td>\n",
       "      <td>0</td>\n",
       "      <td>The Covid-19 pandemic is having a severely dis...</td>\n",
       "      <td>covid 19 pandemic severely disruptive economic...</td>\n",
       "      <td>['covid', '19', 'pandemic', 'severely', 'disru...</td>\n",
       "      <td>['covid', '19', 'pandemic', 'severely', 'disru...</td>\n",
       "      <td>...</td>\n",
       "      <td>289</td>\n",
       "      <td>829</td>\n",
       "      <td>190</td>\n",
       "      <td>25</td>\n",
       "      <td>422</td>\n",
       "      <td>200</td>\n",
       "      <td>3206</td>\n",
       "      <td>-0.300062</td>\n",
       "      <td>-0.168808</td>\n",
       "      <td>the covid-19 pandemic is having a severely dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>r210421a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>Opening remarks: meeting varied people</td>\n",
       "      <td>rosen</td>\n",
       "      <td>0</td>\n",
       "      <td>Bank of England's relationship with financial ...</td>\n",
       "      <td>bank england relationship financial markets pa...</td>\n",
       "      <td>['bank', 'england', 'relationship', 'financial...</td>\n",
       "      <td>['bank', 'england', 'relationship', 'financial...</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>171</td>\n",
       "      <td>-0.040936</td>\n",
       "      <td>0.225731</td>\n",
       "      <td>bank of england's relationship with financial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>r210429b_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>Developments in the PRA’s supervision of annui...</td>\n",
       "      <td>gerken</td>\n",
       "      <td>0</td>\n",
       "      <td>Asset eligibility Liability eligibility Calcul...</td>\n",
       "      <td>asset eligibility liability eligibility calcul...</td>\n",
       "      <td>['asset', 'eligibility', 'liability', 'eligibi...</td>\n",
       "      <td>['asset', 'eligibility', 'liability', 'eligibi...</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>277</td>\n",
       "      <td>104</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>121</td>\n",
       "      <td>926</td>\n",
       "      <td>-0.090713</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>asset eligibility liability eligibility calcul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>r210601a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>Tackling climate for real: the role of central...</td>\n",
       "      <td>bailey</td>\n",
       "      <td>1</td>\n",
       "      <td>We all tend to reach for the payment methods t...</td>\n",
       "      <td>tend reach payment methods accustomed using fo...</td>\n",
       "      <td>['tend', 'reach', 'payment', 'methods', 'accus...</td>\n",
       "      <td>['tend', 'reach', 'payment', 'method', 'accust...</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.631915</td>\n",
       "      <td>we all tend to reach for the payment methods t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>r210617a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>Central Bank Digital Currency: An update on th...</td>\n",
       "      <td>mutton</td>\n",
       "      <td>0</td>\n",
       "      <td>We all tend to reach for the payment methods t...</td>\n",
       "      <td>tend reach payment methods accustomed using fo...</td>\n",
       "      <td>['tend', 'reach', 'payment', 'methods', 'accus...</td>\n",
       "      <td>['tend', 'reach', 'payment', 'method', 'accust...</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.631915</td>\n",
       "      <td>we all tend to reach for the payment methods t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>r211020a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>Driving different decisions today: putting cli...</td>\n",
       "      <td>breeden</td>\n",
       "      <td>0</td>\n",
       "      <td>The hurdles to the delivery of effective scena...</td>\n",
       "      <td>hurdles delivery effective scenario analysis h...</td>\n",
       "      <td>['hurdles', 'delivery', 'effective', 'scenario...</td>\n",
       "      <td>['hurdle', 'delivery', 'effective', 'scenario'...</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>230</td>\n",
       "      <td>-0.069565</td>\n",
       "      <td>0.128696</td>\n",
       "      <td>the hurdles to the delivery of effective scena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>r211103a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Laying the Foundations for a Net Zero Financia...</td>\n",
       "      <td>bailey</td>\n",
       "      <td>1</td>\n",
       "      <td>The hurdles to the delivery of effective scena...</td>\n",
       "      <td>hurdles delivery effective scenario analysis h...</td>\n",
       "      <td>['hurdles', 'delivery', 'effective', 'scenario...</td>\n",
       "      <td>['hurdle', 'delivery', 'effective', 'scenario'...</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>230</td>\n",
       "      <td>-0.069565</td>\n",
       "      <td>0.128696</td>\n",
       "      <td>the hurdles to the delivery of effective scena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>r211203a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>The outlook for inflation and monetary policy</td>\n",
       "      <td>saunders</td>\n",
       "      <td>0</td>\n",
       "      <td>Madonna\", given the 90 million hits that her n...</td>\n",
       "      <td>madonna given 90 million hits name brings term...</td>\n",
       "      <td>['madonna', 'given', '90', 'million', 'hits', ...</td>\n",
       "      <td>['madonna', 'give', '90', 'million', 'hit', 'n...</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.283158</td>\n",
       "      <td>madonna\", given the 90 million hits that her n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>r220428a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>Macropru</td>\n",
       "      <td>breeden</td>\n",
       "      <td>0</td>\n",
       "      <td>Dimitri Demekas and Paul Tucker for helpful di...</td>\n",
       "      <td>dimitri demekas paul tucker helpful discussion...</td>\n",
       "      <td>['dimitri', 'demekas', 'paul', 'tucker', 'help...</td>\n",
       "      <td>['dimitri', 'demekas', 'paul', 'tucker', 'help...</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>246</td>\n",
       "      <td>-0.203252</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>dimitri demekas and paul tucker for helpful di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td>r220526a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>Four Rs: Creating the conditions for long-term...</td>\n",
       "      <td>gerken</td>\n",
       "      <td>0</td>\n",
       "      <td>Asset eligibility Liability eligibility Calcul...</td>\n",
       "      <td>asset eligibility liability eligibility calcul...</td>\n",
       "      <td>['asset', 'eligibility', 'liability', 'eligibi...</td>\n",
       "      <td>['asset', 'eligibility', 'liability', 'eligibi...</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>277</td>\n",
       "      <td>104</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>121</td>\n",
       "      <td>926</td>\n",
       "      <td>-0.090713</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>asset eligibility liability eligibility calcul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>r040103a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-01-03</td>\n",
       "      <td>Presented at the Meetings of the American Econ...</td>\n",
       "      <td>reinhart</td>\n",
       "      <td>0</td>\n",
       "      <td>Can monetary policy committees, accustomed to ...</td>\n",
       "      <td>monetary policy committees accustomed describi...</td>\n",
       "      <td>['monetary', 'policy', 'committees', 'accustom...</td>\n",
       "      <td>['monetary', 'policy', 'committee', 'accustom'...</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>222</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.120270</td>\n",
       "      <td>can monetary policy committees, accustomed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>r040114a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-01-14</td>\n",
       "      <td>Presented at the Meetings of the American Econ...</td>\n",
       "      <td>reinhart</td>\n",
       "      <td>0</td>\n",
       "      <td>Can monetary policy committees, accustomed to ...</td>\n",
       "      <td>monetary policy committees accustomed describi...</td>\n",
       "      <td>['monetary', 'policy', 'committees', 'accustom...</td>\n",
       "      <td>['monetary', 'policy', 'committee', 'accustom'...</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>222</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.120270</td>\n",
       "      <td>can monetary policy committees, accustomed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>r040225b_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-02-25</td>\n",
       "      <td>Presented at the Los Angeles Chapter of the Na...</td>\n",
       "      <td>gramlich</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to speak today. Whil...</td>\n",
       "      <td>thank inviting speak today know would welcome ...</td>\n",
       "      <td>['thank', 'inviting', 'speak', 'today', 'know'...</td>\n",
       "      <td>['thank', 'invite', 'speak', 'today', 'know', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>352</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>-0.094886</td>\n",
       "      <td>thank you for inviting me to speak today. whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>r040226a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-02-26</td>\n",
       "      <td>Presented at the Institute for International E...</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the appropriate domain of a currency a...</td>\n",
       "      <td>appropriate domain currency area might seem fi...</td>\n",
       "      <td>['appropriate', 'domain', 'currency', 'area', ...</td>\n",
       "      <td>['appropriate', 'domain', 'currency', 'area', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>314</td>\n",
       "      <td>0.213376</td>\n",
       "      <td>0.506688</td>\n",
       "      <td>what is the appropriate domain of a currency a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>r040331a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-03-31</td>\n",
       "      <td>Presented at the Los Angeles Chapter of the Na...</td>\n",
       "      <td>gramlich</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to speak today. Whil...</td>\n",
       "      <td>thank inviting speak today know would welcome ...</td>\n",
       "      <td>['thank', 'inviting', 'speak', 'today', 'know'...</td>\n",
       "      <td>['thank', 'invite', 'speak', 'today', 'know', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>352</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>-0.094886</td>\n",
       "      <td>thank you for inviting me to speak today. whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>r040514a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-05-14</td>\n",
       "      <td>Presented at the Los Angeles Chapter of the Na...</td>\n",
       "      <td>gramlich</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to speak today. Whil...</td>\n",
       "      <td>thank inviting speak today know would welcome ...</td>\n",
       "      <td>['thank', 'inviting', 'speak', 'today', 'know'...</td>\n",
       "      <td>['thank', 'invite', 'speak', 'today', 'know', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>352</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>-0.094886</td>\n",
       "      <td>thank you for inviting me to speak today. whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>r040621a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2004-06-21</td>\n",
       "      <td>Presented at the Institute for International E...</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the appropriate domain of a currency a...</td>\n",
       "      <td>appropriate domain currency area might seem fi...</td>\n",
       "      <td>['appropriate', 'domain', 'currency', 'area', ...</td>\n",
       "      <td>['appropriate', 'domain', 'currency', 'area', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>314</td>\n",
       "      <td>0.213376</td>\n",
       "      <td>0.506688</td>\n",
       "      <td>what is the appropriate domain of a currency a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>r050112a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2005-01-12</td>\n",
       "      <td>Presented at the Real Estate Roundtable, Washi...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to address the assoc...</td>\n",
       "      <td>thank inviting address associates stanford ins...</td>\n",
       "      <td>['thank', 'inviting', 'address', 'associates',...</td>\n",
       "      <td>['thank', 'invite', 'address', 'associate', 's...</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>449</td>\n",
       "      <td>-0.260579</td>\n",
       "      <td>-0.058129</td>\n",
       "      <td>thank you for inviting me to address the assoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>r050119a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>Presented at the University of Arkansas at Lit...</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>Almost certainly, the most important economic ...</td>\n",
       "      <td>almost certainly important economic developmen...</td>\n",
       "      <td>['almost', 'certainly', 'important', 'economic...</td>\n",
       "      <td>['almost', 'certainly', 'important', 'economic...</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>421</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.422803</td>\n",
       "      <td>almost certainly, the most important economic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>r050127a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2005-01-27</td>\n",
       "      <td>Presented at the Real Estate Roundtable, Washi...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to address the assoc...</td>\n",
       "      <td>thank inviting address associates stanford ins...</td>\n",
       "      <td>['thank', 'inviting', 'address', 'associates',...</td>\n",
       "      <td>['thank', 'invite', 'address', 'associate', 's...</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>449</td>\n",
       "      <td>-0.260579</td>\n",
       "      <td>-0.058129</td>\n",
       "      <td>thank you for inviting me to address the assoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>r050224a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2005-02-24</td>\n",
       "      <td>Presented at the University of Arkansas at Lit...</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>Almost certainly, the most important economic ...</td>\n",
       "      <td>almost certainly important economic developmen...</td>\n",
       "      <td>['almost', 'certainly', 'important', 'economic...</td>\n",
       "      <td>['almost', 'certainly', 'important', 'economic...</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>421</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.422803</td>\n",
       "      <td>almost certainly, the most important economic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>r051012b_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2005-10-12</td>\n",
       "      <td>Regulatory Issues</td>\n",
       "      <td>bies</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to speak to you toda...</td>\n",
       "      <td>thank inviting speak today remarks focus near ...</td>\n",
       "      <td>['thank', 'inviting', 'speak', 'today', 'remar...</td>\n",
       "      <td>['thank', 'invite', 'speak', 'today', 'remark'...</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>220</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.101364</td>\n",
       "      <td>thank you for inviting me to speak to you toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>r051013a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2005-10-13</td>\n",
       "      <td>Governor Mark W. Olson presented identical rem...</td>\n",
       "      <td>olson</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for inviting me to speak to you toda...</td>\n",
       "      <td>thank inviting speak today remarks focus near ...</td>\n",
       "      <td>['thank', 'inviting', 'speak', 'today', 'remar...</td>\n",
       "      <td>['thank', 'invite', 'speak', 'today', 'remark'...</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>220</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.101364</td>\n",
       "      <td>thank you for inviting me to speak to you toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6824</th>\n",
       "      <td>r060615a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2006-06-15</td>\n",
       "      <td>Why Are Yield Curves So Flat and Long Rates So...</td>\n",
       "      <td>kroszner</td>\n",
       "      <td>0</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>federal reserve central bank united states pro...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>210</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.364762</td>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6826</th>\n",
       "      <td>r060616b_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2006-06-16</td>\n",
       "      <td>Why Are Yield Curves So Flat and Long Rates So...</td>\n",
       "      <td>kroszner</td>\n",
       "      <td>0</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>federal reserve central bank united states pro...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>210</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.364762</td>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>r070426a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2007-04-26</td>\n",
       "      <td>Globalization and Financial Development</td>\n",
       "      <td>mishkin</td>\n",
       "      <td>0</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>federal reserve central bank united states pro...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>413</td>\n",
       "      <td>0.089588</td>\n",
       "      <td>0.338257</td>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>r070623a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2007-06-23</td>\n",
       "      <td>Globalization and Financial Development</td>\n",
       "      <td>mishkin</td>\n",
       "      <td>0</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>federal reserve central bank united states pro...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>['federal', 'reserve', 'central', 'bank', 'uni...</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>413</td>\n",
       "      <td>0.089588</td>\n",
       "      <td>0.338257</td>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference         country        date  \\\n",
       "564    r101026a_BOC          canada  2010-10-26   \n",
       "565    r101027a_BOC          canada  2010-10-27   \n",
       "610    r120424a_BOC          canada  2012-04-24   \n",
       "611    r120425a_BOC          canada  2012-04-25   \n",
       "624    r121030a_BOC          canada  2012-10-30   \n",
       "625    r121031a_BOC          canada  2012-10-31   \n",
       "668    r140429a_BOC          canada  2014-04-29   \n",
       "669    r140430a_BOC          canada  2014-04-30   \n",
       "1182   r020121a_ECB       euro area  2002-01-21   \n",
       "1186   r020221a_ECB       euro area  2002-02-21   \n",
       "2824   r180507a_ECB       euro area  2018-05-07   \n",
       "2829   r180514c_ECB       euro area  2018-05-14   \n",
       "3266   r981210a_BOJ           japan  1998-12-10   \n",
       "3267   r981211a_BOJ           japan  1998-12-11   \n",
       "3422   r071101a_BOJ           japan  2007-11-01   \n",
       "3423   r071102a_BOJ           japan  2007-11-02   \n",
       "3506   r100413a_BOJ           japan  2010-04-13   \n",
       "3507   r100420a_BOJ           japan  2010-04-20   \n",
       "3744   r150610a_BOJ           japan  2015-06-10   \n",
       "3746   r150616a_BOJ           japan  2015-06-16   \n",
       "3803   r161102a_BOJ           japan  2016-11-02   \n",
       "3808   r161122a_BOJ           japan  2016-11-22   \n",
       "3886   r181206a_BOJ           japan  2018-12-06   \n",
       "3887   r181207a_BOJ           japan  2018-12-07   \n",
       "3922   r191119a_BOJ           japan  2019-11-19   \n",
       "3926   r191129a_BOJ           japan  2019-11-29   \n",
       "5203   r061024a_BOE  united kingdom  2006-10-24   \n",
       "5658   r150226a_BOE  united kingdom  2015-02-26   \n",
       "5952   r190517a_BOE  united kingdom  2019-05-17   \n",
       "6035   r200903a_BOE  united kingdom  2020-09-03   \n",
       "6038   r200909a_BOE  united kingdom  2020-09-09   \n",
       "6081   r210421a_BOE  united kingdom  2021-04-21   \n",
       "6082   r210429b_BOE  united kingdom  2021-04-29   \n",
       "6095   r210601a_BOE  united kingdom  2021-06-01   \n",
       "6099   r210617a_BOE  united kingdom  2021-06-17   \n",
       "6115   r211020a_BOE  united kingdom  2021-10-20   \n",
       "6116   r211103a_BOE  united kingdom  2021-11-03   \n",
       "6120   r211203a_BOE  united kingdom  2021-12-03   \n",
       "6135   r220428a_BOE  united kingdom  2022-04-28   \n",
       "6142   r220526a_BOE  united kingdom  2022-05-26   \n",
       "6598  r040103a_FOMC   united states  2004-01-03   \n",
       "6603  r040114a_FOMC   united states  2004-01-14   \n",
       "6611  r040225b_FOMC   united states  2004-02-25   \n",
       "6612  r040226a_FOMC   united states  2004-02-26   \n",
       "6626  r040331a_FOMC   united states  2004-03-31   \n",
       "6645  r040514a_FOMC   united states  2004-05-14   \n",
       "6658  r040621a_FOMC   united states  2004-06-21   \n",
       "6697  r050112a_FOMC   united states  2005-01-12   \n",
       "6699  r050119a_FOMC   united states  2005-01-19   \n",
       "6700  r050127a_FOMC   united states  2005-01-27   \n",
       "6705  r050224a_FOMC   united states  2005-02-24   \n",
       "6758  r051012b_FOMC   united states  2005-10-12   \n",
       "6761  r051013a_FOMC   united states  2005-10-13   \n",
       "6824  r060615a_FOMC   united states  2006-06-15   \n",
       "6826  r060616b_FOMC   united states  2006-06-16   \n",
       "6875  r070426a_FOMC   united states  2007-04-26   \n",
       "6891  r070623a_FOMC   united states  2007-06-23   \n",
       "\n",
       "                                                  title     author  is_gov  \\\n",
       "564   Opening Statement before the House of Commons ...     carney       1   \n",
       "565   Opening Statement before the Standing Senate C...     carney       1   \n",
       "610   Opening Statement before the House of Commons ...     carney       1   \n",
       "611   Opening Statement before the Senate Standing C...     carney       1   \n",
       "624   Opening Statement before the House of Commons ...     carney       1   \n",
       "625   Opening Statement before the Standing Senate C...     carney       1   \n",
       "668   Opening Statement before the House of Commons ...      poloz       1   \n",
       "669   Opening Statement before the Senate Standing C...      poloz       1   \n",
       "1182          Securities and banking: bridges and walls    no_info       0   \n",
       "1186          Securities and banking: bridges and walls   schioppa       0   \n",
       "2824             Economic developments in the euro area      praet       0   \n",
       "2829             Economic developments in the euro area      praet       0   \n",
       "3266  Statement by Masaru Hayami, Governor of the Ba...     hayami       0   \n",
       "3267  Statement by Masaru Hayami, Governor of the Ba...     hayami       0   \n",
       "3422                                            NO_INFO    no_info       0   \n",
       "3423                                            NO_INFO    no_info       0   \n",
       "3506  The Bank's Semiannual Report on Currency and M...  shirakawa       1   \n",
       "3507  The Bank's Semiannual Report on Currency and M...  shirakawa       1   \n",
       "3744  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3746  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3803  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3808  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3886  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3887  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3922  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "3926  The Bank's Semiannual Report on Currency and M...     kuroda       1   \n",
       "5203                        Globalisation and Inflation       bean       0   \n",
       "5658  Goodbye ambiguity, hello clarity: the Bank of ...     shafik       0   \n",
       "5952           Citizens in service, not people in power    brazier       0   \n",
       "6035       Reinventing the wheel (with more automation)     bailey       1   \n",
       "6038  Paving the way forward: managing climate risk ...    sweeney       0   \n",
       "6081             Opening remarks: meeting varied people      rosen       0   \n",
       "6082  Developments in the PRA’s supervision of annui...     gerken       0   \n",
       "6095  Tackling climate for real: the role of central...     bailey       1   \n",
       "6099  Central Bank Digital Currency: An update on th...     mutton       0   \n",
       "6115  Driving different decisions today: putting cli...    breeden       0   \n",
       "6116  Laying the Foundations for a Net Zero Financia...     bailey       1   \n",
       "6120      The outlook for inflation and monetary policy   saunders       0   \n",
       "6135                                           Macropru    breeden       0   \n",
       "6142  Four Rs: Creating the conditions for long-term...     gerken       0   \n",
       "6598  Presented at the Meetings of the American Econ...   reinhart       0   \n",
       "6603  Presented at the Meetings of the American Econ...   reinhart       0   \n",
       "6611  Presented at the Los Angeles Chapter of the Na...   gramlich       0   \n",
       "6612  Presented at the Institute for International E...   bernanke       1   \n",
       "6626  Presented at the Los Angeles Chapter of the Na...   gramlich       0   \n",
       "6645  Presented at the Los Angeles Chapter of the Na...   gramlich       0   \n",
       "6658  Presented at the Institute for International E...   bernanke       1   \n",
       "6697  Presented at the Real Estate Roundtable, Washi...   ferguson       0   \n",
       "6699  Presented at the University of Arkansas at Lit...   bernanke       1   \n",
       "6700  Presented at the Real Estate Roundtable, Washi...   ferguson       0   \n",
       "6705  Presented at the University of Arkansas at Lit...   bernanke       1   \n",
       "6758                                  Regulatory Issues       bies       0   \n",
       "6761  Governor Mark W. Olson presented identical rem...      olson       0   \n",
       "6824  Why Are Yield Curves So Flat and Long Rates So...   kroszner       0   \n",
       "6826  Why Are Yield Curves So Flat and Long Rates So...   kroszner       0   \n",
       "6875            Globalization and Financial Development    mishkin       0   \n",
       "6891            Globalization and Financial Development    mishkin       0   \n",
       "\n",
       "                                                   text  \\\n",
       "564   Governor of the Bank of Canada Good afternoon,...   \n",
       "565   Governor of the Bank of Canada Good afternoon,...   \n",
       "610   Governor of the Bank of Canada Good afternoon....   \n",
       "611   Governor of the Bank of Canada Good afternoon....   \n",
       "624   Governor of the Bank of Canada Good afternoon....   \n",
       "625   Governor of the Bank of Canada Good afternoon....   \n",
       "668   Governor of the Bank of Canada Thank you for t...   \n",
       "669   Governor of the Bank of Canada Thank you for t...   \n",
       "1182  I once again find myself speaking at the Londo...   \n",
       "1186  I once again find myself speaking at the Londo...   \n",
       "2824  After several quarters of higher than expected...   \n",
       "2829  After several quarters of higher than expected...   \n",
       "3266  Thank you very much for giving us this opportu...   \n",
       "3267  Thank you very much for giving us this opportu...   \n",
       "3422  The Bank of Japan submitted its for the second...   \n",
       "3423  The Bank of Japan submitted its for the second...   \n",
       "3506  Statement by Masaaki Shirakawa, Governor of th...   \n",
       "3507  Statement by Masaaki Shirakawa, Governor of th...   \n",
       "3744  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3746  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3803  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3808  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3886  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3887  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3922  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "3926  Statement by Haruhiko Kuroda, Governor of the ...   \n",
       "5203  Madonna\", given the 90 million hits that her n...   \n",
       "5658  Bank of England's relationship with financial ...   \n",
       "5952  Dimitri Demekas and Paul Tucker for helpful di...   \n",
       "6035  The Covid-19 pandemic is having a severely dis...   \n",
       "6038  The Covid-19 pandemic is having a severely dis...   \n",
       "6081  Bank of England's relationship with financial ...   \n",
       "6082  Asset eligibility Liability eligibility Calcul...   \n",
       "6095  We all tend to reach for the payment methods t...   \n",
       "6099  We all tend to reach for the payment methods t...   \n",
       "6115  The hurdles to the delivery of effective scena...   \n",
       "6116  The hurdles to the delivery of effective scena...   \n",
       "6120  Madonna\", given the 90 million hits that her n...   \n",
       "6135  Dimitri Demekas and Paul Tucker for helpful di...   \n",
       "6142  Asset eligibility Liability eligibility Calcul...   \n",
       "6598  Can monetary policy committees, accustomed to ...   \n",
       "6603  Can monetary policy committees, accustomed to ...   \n",
       "6611  Thank you for inviting me to speak today. Whil...   \n",
       "6612  What is the appropriate domain of a currency a...   \n",
       "6626  Thank you for inviting me to speak today. Whil...   \n",
       "6645  Thank you for inviting me to speak today. Whil...   \n",
       "6658  What is the appropriate domain of a currency a...   \n",
       "6697  Thank you for inviting me to address the assoc...   \n",
       "6699  Almost certainly, the most important economic ...   \n",
       "6700  Thank you for inviting me to address the assoc...   \n",
       "6705  Almost certainly, the most important economic ...   \n",
       "6758  Thank you for inviting me to speak to you toda...   \n",
       "6761  Thank you for inviting me to speak to you toda...   \n",
       "6824  The Federal Reserve, the central bank of the U...   \n",
       "6826  The Federal Reserve, the central bank of the U...   \n",
       "6875  The Federal Reserve, the central bank of the U...   \n",
       "6891  The Federal Reserve, the central bank of the U...   \n",
       "\n",
       "                                           text_cleaned  \\\n",
       "564   governor bank canada good afternoon mr chairma...   \n",
       "565   governor bank canada good afternoon mr chairma...   \n",
       "610   governor bank canada good afternoon tiff pleas...   \n",
       "611   governor bank canada good afternoon tiff pleas...   \n",
       "624   governor bank canada good afternoon tiff pleas...   \n",
       "625   governor bank canada good afternoon tiff pleas...   \n",
       "668   governor bank canada thank opportunity tiff to...   \n",
       "669   governor bank canada thank opportunity tiff to...   \n",
       "1182  find speaking london school economics mileston...   \n",
       "1186  find speaking london school economics mileston...   \n",
       "2824  several quarters higher expected growth latest...   \n",
       "2829  several quarters higher expected growth latest...   \n",
       "3266  thank much giving us opportunity explain monet...   \n",
       "3267  thank much giving us opportunity explain monet...   \n",
       "3422  bank japan submitted second half fiscal 2006 d...   \n",
       "3423  bank japan submitted second half fiscal 2006 d...   \n",
       "3506  statement masaaki shirakawa governor bank japa...   \n",
       "3507  statement masaaki shirakawa governor bank japa...   \n",
       "3744  statement haruhiko kuroda governor bank japan ...   \n",
       "3746  statement haruhiko kuroda governor bank japan ...   \n",
       "3803  statement haruhiko kuroda governor bank japan ...   \n",
       "3808  statement haruhiko kuroda governor bank japan ...   \n",
       "3886  statement haruhiko kuroda governor bank japan ...   \n",
       "3887  statement haruhiko kuroda governor bank japan ...   \n",
       "3922  statement haruhiko kuroda governor bank japan ...   \n",
       "3926  statement haruhiko kuroda governor bank japan ...   \n",
       "5203  madonna given 90 million hits name brings term...   \n",
       "5658  bank england relationship financial markets pa...   \n",
       "5952  dimitri demekas paul tucker helpful discussion...   \n",
       "6035  covid 19 pandemic severely disruptive economic...   \n",
       "6038  covid 19 pandemic severely disruptive economic...   \n",
       "6081  bank england relationship financial markets pa...   \n",
       "6082  asset eligibility liability eligibility calcul...   \n",
       "6095  tend reach payment methods accustomed using fo...   \n",
       "6099  tend reach payment methods accustomed using fo...   \n",
       "6115  hurdles delivery effective scenario analysis h...   \n",
       "6116  hurdles delivery effective scenario analysis h...   \n",
       "6120  madonna given 90 million hits name brings term...   \n",
       "6135  dimitri demekas paul tucker helpful discussion...   \n",
       "6142  asset eligibility liability eligibility calcul...   \n",
       "6598  monetary policy committees accustomed describi...   \n",
       "6603  monetary policy committees accustomed describi...   \n",
       "6611  thank inviting speak today know would welcome ...   \n",
       "6612  appropriate domain currency area might seem fi...   \n",
       "6626  thank inviting speak today know would welcome ...   \n",
       "6645  thank inviting speak today know would welcome ...   \n",
       "6658  appropriate domain currency area might seem fi...   \n",
       "6697  thank inviting address associates stanford ins...   \n",
       "6699  almost certainly important economic developmen...   \n",
       "6700  thank inviting address associates stanford ins...   \n",
       "6705  almost certainly important economic developmen...   \n",
       "6758  thank inviting speak today remarks focus near ...   \n",
       "6761  thank inviting speak today remarks focus near ...   \n",
       "6824  federal reserve central bank united states pro...   \n",
       "6826  federal reserve central bank united states pro...   \n",
       "6875  federal reserve central bank united states pro...   \n",
       "6891  federal reserve central bank united states pro...   \n",
       "\n",
       "                                         text_tokenised  \\\n",
       "564   ['governor', 'bank', 'canada', 'good', 'aftern...   \n",
       "565   ['governor', 'bank', 'canada', 'good', 'aftern...   \n",
       "610   ['governor', 'bank', 'canada', 'good', 'aftern...   \n",
       "611   ['governor', 'bank', 'canada', 'good', 'aftern...   \n",
       "624   ['governor', 'bank', 'canada', 'good', 'aftern...   \n",
       "625   ['governor', 'bank', 'canada', 'good', 'aftern...   \n",
       "668   ['governor', 'bank', 'canada', 'thank', 'oppor...   \n",
       "669   ['governor', 'bank', 'canada', 'thank', 'oppor...   \n",
       "1182  ['find', 'speaking', 'london', 'school', 'econ...   \n",
       "1186  ['find', 'speaking', 'london', 'school', 'econ...   \n",
       "2824  ['several', 'quarters', 'higher', 'expected', ...   \n",
       "2829  ['several', 'quarters', 'higher', 'expected', ...   \n",
       "3266  ['thank', 'much', 'giving', 'us', 'opportunity...   \n",
       "3267  ['thank', 'much', 'giving', 'us', 'opportunity...   \n",
       "3422  ['bank', 'japan', 'submitted', 'second', 'half...   \n",
       "3423  ['bank', 'japan', 'submitted', 'second', 'half...   \n",
       "3506  ['statement', 'masaaki', 'shirakawa', 'governo...   \n",
       "3507  ['statement', 'masaaki', 'shirakawa', 'governo...   \n",
       "3744  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3746  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3803  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3808  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3886  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3887  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3922  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "3926  ['statement', 'haruhiko', 'kuroda', 'governor'...   \n",
       "5203  ['madonna', 'given', '90', 'million', 'hits', ...   \n",
       "5658  ['bank', 'england', 'relationship', 'financial...   \n",
       "5952  ['dimitri', 'demekas', 'paul', 'tucker', 'help...   \n",
       "6035  ['covid', '19', 'pandemic', 'severely', 'disru...   \n",
       "6038  ['covid', '19', 'pandemic', 'severely', 'disru...   \n",
       "6081  ['bank', 'england', 'relationship', 'financial...   \n",
       "6082  ['asset', 'eligibility', 'liability', 'eligibi...   \n",
       "6095  ['tend', 'reach', 'payment', 'methods', 'accus...   \n",
       "6099  ['tend', 'reach', 'payment', 'methods', 'accus...   \n",
       "6115  ['hurdles', 'delivery', 'effective', 'scenario...   \n",
       "6116  ['hurdles', 'delivery', 'effective', 'scenario...   \n",
       "6120  ['madonna', 'given', '90', 'million', 'hits', ...   \n",
       "6135  ['dimitri', 'demekas', 'paul', 'tucker', 'help...   \n",
       "6142  ['asset', 'eligibility', 'liability', 'eligibi...   \n",
       "6598  ['monetary', 'policy', 'committees', 'accustom...   \n",
       "6603  ['monetary', 'policy', 'committees', 'accustom...   \n",
       "6611  ['thank', 'inviting', 'speak', 'today', 'know'...   \n",
       "6612  ['appropriate', 'domain', 'currency', 'area', ...   \n",
       "6626  ['thank', 'inviting', 'speak', 'today', 'know'...   \n",
       "6645  ['thank', 'inviting', 'speak', 'today', 'know'...   \n",
       "6658  ['appropriate', 'domain', 'currency', 'area', ...   \n",
       "6697  ['thank', 'inviting', 'address', 'associates',...   \n",
       "6699  ['almost', 'certainly', 'important', 'economic...   \n",
       "6700  ['thank', 'inviting', 'address', 'associates',...   \n",
       "6705  ['almost', 'certainly', 'important', 'economic...   \n",
       "6758  ['thank', 'inviting', 'speak', 'today', 'remar...   \n",
       "6761  ['thank', 'inviting', 'speak', 'today', 'remar...   \n",
       "6824  ['federal', 'reserve', 'central', 'bank', 'uni...   \n",
       "6826  ['federal', 'reserve', 'central', 'bank', 'uni...   \n",
       "6875  ['federal', 'reserve', 'central', 'bank', 'uni...   \n",
       "6891  ['federal', 'reserve', 'central', 'bank', 'uni...   \n",
       "\n",
       "                                        text_lemmatised  ... positive  \\\n",
       "564   ['governor', 'bank', 'canada', 'good', 'aftern...  ...       20   \n",
       "565   ['governor', 'bank', 'canada', 'good', 'aftern...  ...       20   \n",
       "610   ['governor', 'bank', 'canada', 'good', 'aftern...  ...       21   \n",
       "611   ['governor', 'bank', 'canada', 'good', 'aftern...  ...       21   \n",
       "624   ['governor', 'bank', 'canada', 'good', 'aftern...  ...       23   \n",
       "625   ['governor', 'bank', 'canada', 'good', 'aftern...  ...       23   \n",
       "668   ['governor', 'bank', 'canada', 'thank', 'oppor...  ...       31   \n",
       "669   ['governor', 'bank', 'canada', 'thank', 'oppor...  ...       31   \n",
       "1182  ['find', 'speaking', 'london', 'school', 'econ...  ...      108   \n",
       "1186  ['find', 'speaking', 'london', 'school', 'econ...  ...      108   \n",
       "2824  ['several', 'quarter', 'higher', 'expected', '...  ...       48   \n",
       "2829  ['several', 'quarter', 'higher', 'expected', '...  ...       48   \n",
       "3266  ['thank', 'much', 'give', 'u', 'opportunity', ...  ...       32   \n",
       "3267  ['thank', 'much', 'give', 'u', 'opportunity', ...  ...       32   \n",
       "3422  ['bank', 'japan', 'submit', 'second', 'half', ...  ...       23   \n",
       "3423  ['bank', 'japan', 'submit', 'second', 'half', ...  ...       23   \n",
       "3506  ['statement', 'masaaki', 'shirakawa', 'governo...  ...       29   \n",
       "3507  ['statement', 'masaaki', 'shirakawa', 'governo...  ...       29   \n",
       "3744  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       13   \n",
       "3746  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       13   \n",
       "3803  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       24   \n",
       "3808  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       24   \n",
       "3886  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       22   \n",
       "3887  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       22   \n",
       "3922  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       13   \n",
       "3926  ['statement', 'haruhiko', 'kuroda', 'governor'...  ...       13   \n",
       "5203  ['madonna', 'give', '90', 'million', 'hit', 'n...  ...       65   \n",
       "5658  ['bank', 'england', 'relationship', 'financial...  ...       51   \n",
       "5952  ['dimitri', 'demekas', 'paul', 'tucker', 'help...  ...       57   \n",
       "6035  ['covid', '19', 'pandemic', 'severely', 'disru...  ...      289   \n",
       "6038  ['covid', '19', 'pandemic', 'severely', 'disru...  ...      289   \n",
       "6081  ['bank', 'england', 'relationship', 'financial...  ...       51   \n",
       "6082  ['asset', 'eligibility', 'liability', 'eligibi...  ...      108   \n",
       "6095  ['tend', 'reach', 'payment', 'method', 'accust...  ...       39   \n",
       "6099  ['tend', 'reach', 'payment', 'method', 'accust...  ...       39   \n",
       "6115  ['hurdle', 'delivery', 'effective', 'scenario'...  ...       28   \n",
       "6116  ['hurdle', 'delivery', 'effective', 'scenario'...  ...       28   \n",
       "6120  ['madonna', 'give', '90', 'million', 'hit', 'n...  ...       65   \n",
       "6135  ['dimitri', 'demekas', 'paul', 'tucker', 'help...  ...       57   \n",
       "6142  ['asset', 'eligibility', 'liability', 'eligibi...  ...      108   \n",
       "6598  ['monetary', 'policy', 'committee', 'accustom'...  ...       36   \n",
       "6603  ['monetary', 'policy', 'committee', 'accustom'...  ...       36   \n",
       "6611  ['thank', 'invite', 'speak', 'today', 'know', ...  ...       57   \n",
       "6612  ['appropriate', 'domain', 'currency', 'area', ...  ...      126   \n",
       "6626  ['thank', 'invite', 'speak', 'today', 'know', ...  ...       57   \n",
       "6645  ['thank', 'invite', 'speak', 'today', 'know', ...  ...       57   \n",
       "6658  ['appropriate', 'domain', 'currency', 'area', ...  ...      126   \n",
       "6697  ['thank', 'invite', 'address', 'associate', 's...  ...       84   \n",
       "6699  ['almost', 'certainly', 'important', 'economic...  ...      158   \n",
       "6700  ['thank', 'invite', 'address', 'associate', 's...  ...       84   \n",
       "6705  ['almost', 'certainly', 'important', 'economic...  ...      158   \n",
       "6758  ['thank', 'invite', 'speak', 'today', 'remark'...  ...       36   \n",
       "6761  ['thank', 'invite', 'speak', 'today', 'remark'...  ...       36   \n",
       "6824  ['federal', 'reserve', 'central', 'bank', 'uni...  ...       77   \n",
       "6826  ['federal', 'reserve', 'central', 'bank', 'uni...  ...       77   \n",
       "6875  ['federal', 'reserve', 'central', 'bank', 'uni...  ...      158   \n",
       "6891  ['federal', 'reserve', 'central', 'bank', 'uni...  ...      158   \n",
       "\n",
       "      uncertainty  litigious  strong  weak  constraining  \\\n",
       "564            19          0       0     3             4   \n",
       "565            19          0       0     3             4   \n",
       "610            20          0       0     8             0   \n",
       "611            20          0       0     8             0   \n",
       "624            16          1       0     6             2   \n",
       "625            16          1       0     6             2   \n",
       "668            21          0       1     6             3   \n",
       "669            21          0       1     6             3   \n",
       "1182          157         70       8    46            25   \n",
       "1186          157         70       8    46            25   \n",
       "2824           27          4       2    13             3   \n",
       "2829           27          4       2    13             3   \n",
       "3266            9         10       1     3             6   \n",
       "3267            9         10       1     3             6   \n",
       "3422            9          0       0     1             0   \n",
       "3423            9          0       0     1             0   \n",
       "3506           12          2       1     3             1   \n",
       "3507           12          2       1     3             1   \n",
       "3744            5          1       0     2             1   \n",
       "3746            5          1       0     2             1   \n",
       "3803            3          0       1     2             2   \n",
       "3808            3          0       1     2             2   \n",
       "3886            7          0       0     1             1   \n",
       "3887            7          0       0     1             1   \n",
       "3922            8          0       0     2             1   \n",
       "3926            8          0       0     2             1   \n",
       "5203           80         14       5    53             8   \n",
       "5658           26          3      10    12            11   \n",
       "5952           22         14      13    17            16   \n",
       "6035          829        190      25   422           200   \n",
       "6038          829        190      25   422           200   \n",
       "6081           26          3      10    12            11   \n",
       "6082          277        104      27    97           121   \n",
       "6095           18          1       4    15             2   \n",
       "6099           18          1       4    15             2   \n",
       "6115          114          6       3    23            12   \n",
       "6116          114          6       3    23            12   \n",
       "6120           80         14       5    53             8   \n",
       "6135           22         14      13    17            16   \n",
       "6142          277        104      27    97           121   \n",
       "6598           60          9       2    39            32   \n",
       "6603           60          9       2    39            32   \n",
       "6611           66         18       5    45             5   \n",
       "6612           64         16       4    36             9   \n",
       "6626           66         18       5    45             5   \n",
       "6645           66         18       5    45             5   \n",
       "6658           64         16       4    36             9   \n",
       "6697           92          5       4    57             6   \n",
       "6699           84         14       8    45             9   \n",
       "6700           92          5       4    57             6   \n",
       "6705           84         14       8    45             9   \n",
       "6758           43         12       7    16            10   \n",
       "6761           43         12       7    16            10   \n",
       "6824           48          0       2    19             6   \n",
       "6826           48          0       2    19             6   \n",
       "6875           37         36      18    18            25   \n",
       "6891           37         36      18    18            25   \n",
       "\n",
       "      word_count_sentiment  sentiment_lexicon_simple  \\\n",
       "564                     61                  0.081967   \n",
       "565                     61                  0.081967   \n",
       "610                     60                  0.166667   \n",
       "611                     60                  0.166667   \n",
       "624                     68                  0.044118   \n",
       "625                     68                  0.044118   \n",
       "668                     83                  0.120482   \n",
       "669                     83                  0.120482   \n",
       "1182                   557                 -0.062837   \n",
       "1186                   557                 -0.062837   \n",
       "2824                   144                  0.006944   \n",
       "2829                   144                  0.006944   \n",
       "3266                   107                 -0.130841   \n",
       "3267                   107                 -0.130841   \n",
       "3422                    42                  0.333333   \n",
       "3423                    42                  0.333333   \n",
       "3506                    72                  0.069444   \n",
       "3507                    72                  0.069444   \n",
       "3744                    25                  0.400000   \n",
       "3746                    25                  0.400000   \n",
       "3803                    43                  0.302326   \n",
       "3808                    43                  0.302326   \n",
       "3886                    37                  0.432432   \n",
       "3887                    37                  0.432432   \n",
       "3922                    38                 -0.026316   \n",
       "3926                    38                 -0.026316   \n",
       "5203                   285                  0.017544   \n",
       "5658                   171                 -0.040936   \n",
       "5952                   246                 -0.203252   \n",
       "6035                  3206                 -0.300062   \n",
       "6038                  3206                 -0.300062   \n",
       "6081                   171                 -0.040936   \n",
       "6082                   926                 -0.090713   \n",
       "6095                    94                  0.255319   \n",
       "6099                    94                  0.255319   \n",
       "6115                   230                 -0.069565   \n",
       "6116                   230                 -0.069565   \n",
       "6120                   285                  0.017544   \n",
       "6135                   246                 -0.203252   \n",
       "6142                   926                 -0.090713   \n",
       "6598                   222                 -0.036036   \n",
       "6603                   222                 -0.036036   \n",
       "6611                   352                 -0.281250   \n",
       "6612                   314                  0.213376   \n",
       "6626                   352                 -0.281250   \n",
       "6645                   352                 -0.281250   \n",
       "6658                   314                  0.213376   \n",
       "6697                   449                 -0.260579   \n",
       "6699                   421                  0.130641   \n",
       "6700                   449                 -0.260579   \n",
       "6705                   421                  0.130641   \n",
       "6758                   220                 -0.272727   \n",
       "6761                   220                 -0.272727   \n",
       "6824                   210                  0.090476   \n",
       "6826                   210                  0.090476   \n",
       "6875                   413                  0.089588   \n",
       "6891                   413                  0.089588   \n",
       "\n",
       "      sentiment_lexicon_weighted  \\\n",
       "564                     0.300000   \n",
       "565                     0.300000   \n",
       "610                     0.475000   \n",
       "611                     0.475000   \n",
       "624                     0.286765   \n",
       "625                     0.286765   \n",
       "668                     0.393976   \n",
       "669                     0.393976   \n",
       "1182                    0.105745   \n",
       "1186                    0.105745   \n",
       "2824                    0.261111   \n",
       "2829                    0.261111   \n",
       "3266                    0.016822   \n",
       "3267                    0.016822   \n",
       "3422                    0.661905   \n",
       "3423                    0.661905   \n",
       "3506                    0.333333   \n",
       "3507                    0.333333   \n",
       "3744                    0.712000   \n",
       "3746                    0.712000   \n",
       "3803                    0.630233   \n",
       "3808                    0.630233   \n",
       "3886                    0.767568   \n",
       "3887                    0.767568   \n",
       "3922                    0.200000   \n",
       "3926                    0.200000   \n",
       "5203                    0.283158   \n",
       "5658                    0.225731   \n",
       "5952                    0.000407   \n",
       "6035                   -0.168808   \n",
       "6038                   -0.168808   \n",
       "6081                    0.225731   \n",
       "6082                    0.035745   \n",
       "6095                    0.631915   \n",
       "6099                    0.631915   \n",
       "6115                    0.128696   \n",
       "6116                    0.128696   \n",
       "6120                    0.283158   \n",
       "6135                    0.000407   \n",
       "6142                    0.035745   \n",
       "6598                    0.120270   \n",
       "6603                    0.120270   \n",
       "6611                   -0.094886   \n",
       "6612                    0.506688   \n",
       "6626                   -0.094886   \n",
       "6645                   -0.094886   \n",
       "6658                    0.506688   \n",
       "6697                   -0.058129   \n",
       "6699                    0.422803   \n",
       "6700                   -0.058129   \n",
       "6705                    0.422803   \n",
       "6758                   -0.101364   \n",
       "6761                   -0.101364   \n",
       "6824                    0.364762   \n",
       "6826                    0.364762   \n",
       "6875                    0.338257   \n",
       "6891                    0.338257   \n",
       "\n",
       "                                              text_norm  \n",
       "564   governor of the bank of canada good afternoon,...  \n",
       "565   governor of the bank of canada good afternoon,...  \n",
       "610   governor of the bank of canada good afternoon....  \n",
       "611   governor of the bank of canada good afternoon....  \n",
       "624   governor of the bank of canada good afternoon....  \n",
       "625   governor of the bank of canada good afternoon....  \n",
       "668   governor of the bank of canada thank you for t...  \n",
       "669   governor of the bank of canada thank you for t...  \n",
       "1182  i once again find myself speaking at the londo...  \n",
       "1186  i once again find myself speaking at the londo...  \n",
       "2824  after several quarters of higher than expected...  \n",
       "2829  after several quarters of higher than expected...  \n",
       "3266  thank you very much for giving us this opportu...  \n",
       "3267  thank you very much for giving us this opportu...  \n",
       "3422  the bank of japan submitted its for the second...  \n",
       "3423  the bank of japan submitted its for the second...  \n",
       "3506  statement by masaaki shirakawa, governor of th...  \n",
       "3507  statement by masaaki shirakawa, governor of th...  \n",
       "3744  statement by haruhiko kuroda, governor of the ...  \n",
       "3746  statement by haruhiko kuroda, governor of the ...  \n",
       "3803  statement by haruhiko kuroda, governor of the ...  \n",
       "3808  statement by haruhiko kuroda, governor of the ...  \n",
       "3886  statement by haruhiko kuroda, governor of the ...  \n",
       "3887  statement by haruhiko kuroda, governor of the ...  \n",
       "3922  statement by haruhiko kuroda, governor of the ...  \n",
       "3926  statement by haruhiko kuroda, governor of the ...  \n",
       "5203  madonna\", given the 90 million hits that her n...  \n",
       "5658  bank of england's relationship with financial ...  \n",
       "5952  dimitri demekas and paul tucker for helpful di...  \n",
       "6035  the covid-19 pandemic is having a severely dis...  \n",
       "6038  the covid-19 pandemic is having a severely dis...  \n",
       "6081  bank of england's relationship with financial ...  \n",
       "6082  asset eligibility liability eligibility calcul...  \n",
       "6095  we all tend to reach for the payment methods t...  \n",
       "6099  we all tend to reach for the payment methods t...  \n",
       "6115  the hurdles to the delivery of effective scena...  \n",
       "6116  the hurdles to the delivery of effective scena...  \n",
       "6120  madonna\", given the 90 million hits that her n...  \n",
       "6135  dimitri demekas and paul tucker for helpful di...  \n",
       "6142  asset eligibility liability eligibility calcul...  \n",
       "6598  can monetary policy committees, accustomed to ...  \n",
       "6603  can monetary policy committees, accustomed to ...  \n",
       "6611  thank you for inviting me to speak today. whil...  \n",
       "6612  what is the appropriate domain of a currency a...  \n",
       "6626  thank you for inviting me to speak today. whil...  \n",
       "6645  thank you for inviting me to speak today. whil...  \n",
       "6658  what is the appropriate domain of a currency a...  \n",
       "6697  thank you for inviting me to address the assoc...  \n",
       "6699  almost certainly, the most important economic ...  \n",
       "6700  thank you for inviting me to address the assoc...  \n",
       "6705  almost certainly, the most important economic ...  \n",
       "6758  thank you for inviting me to speak to you toda...  \n",
       "6761  thank you for inviting me to speak to you toda...  \n",
       "6824  the federal reserve, the central bank of the u...  \n",
       "6826  the federal reserve, the central bank of the u...  \n",
       "6875  the federal reserve, the central bank of the u...  \n",
       "6891  the federal reserve, the central bank of the u...  \n",
       "\n",
       "[57 rows x 24 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 'text' of these duplicates\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329a284-5cf7-4de1-be44-233af29fa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "# duplicates.to_csv('/Users/kaferrante/Documents/Python/_Course4_Project/duplicates_full_rows.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94425ee-1f4d-4f0f-9bb3-aa4d4be29084",
   "metadata": {},
   "source": [
    "**2.3.c. Import BoE Wordlist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "087db4c5-4ecf-4baa-ab2b-89c8282f1033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Weak</th>\n",
       "      <th>Constraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDONING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABANDONMENTS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Negative  Positive  Uncertainty  Litigious  Strong  Weak  \\\n",
       "0       ABANDON         1         0            0          0       0     0   \n",
       "1     ABANDONED         1         0            0          0       0     0   \n",
       "2    ABANDONING         1         0            0          0       0     0   \n",
       "3   ABANDONMENT         1         0            0          0       0     0   \n",
       "4  ABANDONMENTS         1         0            0          0       0     0   \n",
       "\n",
       "   Constraining  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file of BoE sentiment labelled wordlist.\n",
    "sentiment_lexicon = pd.read_excel('/Users/kaferrante/Documents/Python/_Course4_Project/sentiment_labelled_wordlist.xlsx')\n",
    "\n",
    "# View the data.\n",
    "sentiment_lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d73e8dc-61a5-470c-8d5d-fa1e4a193bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3880 entries, 0 to 3879\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Word          3880 non-null   object\n",
      " 1   Negative      3880 non-null   int64 \n",
      " 2   Positive      3880 non-null   int64 \n",
      " 3   Uncertainty   3880 non-null   int64 \n",
      " 4   Litigious     3880 non-null   int64 \n",
      " 5   Strong        3880 non-null   int64 \n",
      " 6   Weak          3880 non-null   int64 \n",
      " 7   Constraining  3880 non-null   int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 242.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore data set.\n",
    "sentiment_lexicon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "535ff1ba-57bc-4283-bffa-107b07e23892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word            0\n",
       "Negative        0\n",
       "Positive        0\n",
       "Uncertainty     0\n",
       "Litigious       0\n",
       "Strong          0\n",
       "Weak            0\n",
       "Constraining    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "sentiment_lexicon.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b21ec14f-bffd-42a9-a987-09e0286a1454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Weak</th>\n",
       "      <th>Constraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3880.000000</td>\n",
       "      <td>3880.000000</td>\n",
       "      <td>3880.000000</td>\n",
       "      <td>3880.000000</td>\n",
       "      <td>3880.000000</td>\n",
       "      <td>3880.000000</td>\n",
       "      <td>3880.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.606959</td>\n",
       "      <td>0.092268</td>\n",
       "      <td>0.076546</td>\n",
       "      <td>0.233247</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.047423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488489</td>\n",
       "      <td>0.289441</td>\n",
       "      <td>0.265905</td>\n",
       "      <td>0.422953</td>\n",
       "      <td>0.069815</td>\n",
       "      <td>0.083139</td>\n",
       "      <td>0.212569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative     Positive  Uncertainty    Litigious       Strong  \\\n",
       "count  3880.000000  3880.000000  3880.000000  3880.000000  3880.000000   \n",
       "mean      0.606959     0.092268     0.076546     0.233247     0.004897   \n",
       "std       0.488489     0.289441     0.265905     0.422953     0.069815   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              Weak  Constraining  \n",
       "count  3880.000000   3880.000000  \n",
       "mean      0.006959      0.047423  \n",
       "std       0.083139      0.212569  \n",
       "min       0.000000      0.000000  \n",
       "25%       0.000000      0.000000  \n",
       "50%       0.000000      0.000000  \n",
       "75%       0.000000      0.000000  \n",
       "max       1.000000      1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review basic descriptive statistics.\n",
    "sentiment_lexicon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d657b00-93ec-4dc3-8447-a355f6bb10e1",
   "metadata": {},
   "source": [
    "**2.3.d. Import UK Economic Indicators (1998-2025)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb1adf69-2464-4bb9-bdc4-5c8afa57d733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "      <th>uk_inflation_rate_CPIH</th>\n",
       "      <th>uk_unemployment_rate</th>\n",
       "      <th>uk_gdp_growth</th>\n",
       "      <th>uk_interest_rate</th>\n",
       "      <th>uk_consumer_confidence</th>\n",
       "      <th>gbp_usd_fx</th>\n",
       "      <th>ftse_250</th>\n",
       "      <th>gilts_short</th>\n",
       "      <th>gilts_medium</th>\n",
       "      <th>gilts_long</th>\n",
       "      <th>uk_credit_growth_no_cc</th>\n",
       "      <th>uk_credit_growth_only_cc</th>\n",
       "      <th>avg_price_all_property_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>4</td>\n",
       "      <td>1998-04</td>\n",
       "      <td>1.815</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.673270</td>\n",
       "      <td>5554.720972</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.71</td>\n",
       "      <td>14.1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>64258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>5</td>\n",
       "      <td>1998-05</td>\n",
       "      <td>2.039</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.636589</td>\n",
       "      <td>5799.256322</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.55</td>\n",
       "      <td>14.4</td>\n",
       "      <td>24.5</td>\n",
       "      <td>64258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>6</td>\n",
       "      <td>1998-06</td>\n",
       "      <td>1.675</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.650718</td>\n",
       "      <td>5739.277233</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.43</td>\n",
       "      <td>13.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>64258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>7</td>\n",
       "      <td>1998-07</td>\n",
       "      <td>1.443</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>1.643657</td>\n",
       "      <td>5595.919582</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.38</td>\n",
       "      <td>14.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>67057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>8</td>\n",
       "      <td>1998-08</td>\n",
       "      <td>1.327</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>1.631950</td>\n",
       "      <td>5173.355054</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.11</td>\n",
       "      <td>14.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>67057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month year_month  uk_inflation_rate_CPIH  uk_unemployment_rate  \\\n",
       "0  1998      4    1998-04                   1.815                   6.3   \n",
       "1  1998      5    1998-05                   2.039                   6.3   \n",
       "2  1998      6    1998-06                   1.675                   6.3   \n",
       "3  1998      7    1998-07                   1.443                   6.3   \n",
       "4  1998      8    1998-08                   1.327                   6.2   \n",
       "\n",
       "   uk_gdp_growth  uk_interest_rate  uk_consumer_confidence  gbp_usd_fx  \\\n",
       "0            0.6              7.25                     1.1    1.673270   \n",
       "1            0.6              7.25                     1.2    1.636589   \n",
       "2            0.6              7.50                    -1.3    1.650718   \n",
       "3            0.3              7.50                    -4.3    1.643657   \n",
       "4            0.3              7.50                    -6.5    1.631950   \n",
       "\n",
       "      ftse_250  gilts_short   gilts_medium   gilts_long   \\\n",
       "0  5554.720972          5.91           5.70         5.71   \n",
       "1  5799.256322          5.82           5.57         5.55   \n",
       "2  5739.277233          6.17           5.64         5.43   \n",
       "3  5595.919582          6.06           5.57         5.38   \n",
       "4  5173.355054          5.52           5.19         5.11   \n",
       "\n",
       "   uk_credit_growth_no_cc  uk_credit_growth_only_cc  \\\n",
       "0                    14.1                      24.7   \n",
       "1                    14.4                      24.5   \n",
       "2                    13.9                      25.5   \n",
       "3                    14.6                      25.6   \n",
       "4                    14.6                      26.1   \n",
       "\n",
       "   avg_price_all_property_types  \n",
       "0                         64258  \n",
       "1                         64258  \n",
       "2                         64258  \n",
       "3                         67057  \n",
       "4                         67057  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file for UK Economic Indicators\n",
    "uk_economic_indicators = pd.read_excel('/Users/kaferrante/Documents/Python/_Course4_Project/Consolidated_Eco_KPI _V3.xlsx')\n",
    "\n",
    "# View the data.\n",
    "uk_economic_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfbefcde-d024-4926-b631-146b943a2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 321 entries, 0 to 320\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   year                          321 non-null    int64  \n",
      " 1   month                         321 non-null    int64  \n",
      " 2   year_month                    321 non-null    object \n",
      " 3   uk_inflation_rate_CPIH        321 non-null    float64\n",
      " 4   uk_unemployment_rate          321 non-null    float64\n",
      " 5   uk_gdp_growth                 321 non-null    float64\n",
      " 6   uk_interest_rate              321 non-null    float64\n",
      " 7   uk_consumer_confidence        321 non-null    float64\n",
      " 8   gbp_usd_fx                    321 non-null    float64\n",
      " 9   ftse_250                      321 non-null    float64\n",
      " 10  gilts_short                   321 non-null    float64\n",
      " 11  gilts_medium                  321 non-null    float64\n",
      " 12  gilts_long                    321 non-null    float64\n",
      " 13  uk_credit_growth_no_cc        321 non-null    float64\n",
      " 14  uk_credit_growth_only_cc      321 non-null    float64\n",
      " 15  avg_price_all_property_types  321 non-null    int64  \n",
      "dtypes: float64(12), int64(3), object(1)\n",
      "memory usage: 40.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore data set.\n",
    "uk_economic_indicators.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "028240fe-f17a-4e6f-aa78-0bb321079941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                            0\n",
       "month                           0\n",
       "year_month                      0\n",
       "uk_inflation_rate_CPIH          0\n",
       "uk_unemployment_rate            0\n",
       "uk_gdp_growth                   0\n",
       "uk_interest_rate                0\n",
       "uk_consumer_confidence          0\n",
       "gbp_usd_fx                      0\n",
       "ftse_250                        0\n",
       "gilts_short                     0\n",
       "gilts_medium                    0\n",
       "gilts_long                      0\n",
       "uk_credit_growth_no_cc          0\n",
       "uk_credit_growth_only_cc        0\n",
       "avg_price_all_property_types    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "uk_economic_indicators.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9616b06a-4549-499e-b6ca-898a8906bf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                              int64\n",
       "month                             int64\n",
       "year_month                       object\n",
       "uk_inflation_rate_CPIH          float64\n",
       "uk_unemployment_rate            float64\n",
       "uk_gdp_growth                   float64\n",
       "uk_interest_rate                float64\n",
       "uk_consumer_confidence          float64\n",
       "gbp_usd_fx                      float64\n",
       "ftse_250                        float64\n",
       "gilts_short                     float64\n",
       "gilts_medium                    float64\n",
       "gilts_long                      float64\n",
       "uk_credit_growth_no_cc          float64\n",
       "uk_credit_growth_only_cc        float64\n",
       "avg_price_all_property_types      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column types.\n",
    "uk_economic_indicators.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89425754-e04f-4ca3-b727-1dc237183d0c",
   "metadata": {},
   "source": [
    "### 2.4. Date Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46483b43-00ca-4a5b-b3e8-06fb52e75baf",
   "metadata": {},
   "source": [
    "**Speeches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67de950c-81c5-4a16-9551-6a72a2531967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1990-11-28\n",
       "1    1991-10-03\n",
       "2    1992-03-14\n",
       "3    1992-05-29\n",
       "4    1992-08-17\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the date format for speeches.\n",
    "speeches.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8614851-88aa-4de6-a4a7-ada06e1a1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format from 'object' to 'datetime64' and display in a new column\n",
    "speeches['date_format'] = speeches['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d106119-f44e-405d-919c-dcd85b98550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for year and month\n",
    "speeches['year_month'] = pd.to_datetime(speeches['date_format']).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91f0c903-7af8-43a7-9bb5-3c74d6b1d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for year only\n",
    "speeches['year'] = pd.to_datetime(speeches.date).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d10de06-19dd-486f-a6ea-6098ad30e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for year_month in date format\n",
    "speeches['year_month_dt'] = speeches['year_month'].dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eabd6019-d4d2-4e84-94d8-a1a524b0fb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>date_format</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>year_month_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>['would', 'doubt', 'argue', 'two', 'objectives...</td>\n",
       "      <td>['would', 'doubt', 'argue', 'two', 'objective'...</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.119816</td>\n",
       "      <td>0.112442</td>\n",
       "      <td>they would no doubt argue that to have two obj...</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>1990-11</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>['today', 'wish', 'talk', 'real', 'interest', ...</td>\n",
       "      <td>['today', 'wish', 'talk', 'real', 'interest', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>today i wish to talk about real interest rates...</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td>1991-10</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>['welcome', 'opportunity', 'talk', 'prospects'...</td>\n",
       "      <td>['welcome', 'opportunity', 'talk', 'prospect',...</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>191</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.421466</td>\n",
       "      <td>i welcome this opportunity to talk about prosp...</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td>1992-03</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>['pleasure', 'opportunity', 'address', 'influe...</td>\n",
       "      <td>['pleasure', 'opportunity', 'address', 'influe...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>-0.029703</td>\n",
       "      <td>0.227228</td>\n",
       "      <td>it is a pleasure to have this opportunity to a...</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td>1992-05</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>['long', 'time', 'fan', 'sanders', 'delighted'...</td>\n",
       "      <td>['long', 'time', 'fan', 'sander', 'delight', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>0.227350</td>\n",
       "      <td>as a long-time fan of don sanders, i am deligh...</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td>1992-08</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  ['would', 'doubt', 'argue', 'two', 'objectives...   \n",
       "1  ['today', 'wish', 'talk', 'real', 'interest', ...   \n",
       "2  ['welcome', 'opportunity', 'talk', 'prospects'...   \n",
       "3  ['pleasure', 'opportunity', 'address', 'influe...   \n",
       "4  ['long', 'time', 'fan', 'sanders', 'delighted'...   \n",
       "\n",
       "                                     text_lemmatised  ... weak  constraining  \\\n",
       "0  ['would', 'doubt', 'argue', 'two', 'objective'...  ...   15            13   \n",
       "1  ['today', 'wish', 'talk', 'real', 'interest', ...  ...   16            12   \n",
       "2  ['welcome', 'opportunity', 'talk', 'prospect',...  ...   16            13   \n",
       "3  ['pleasure', 'opportunity', 'address', 'influe...  ...   20             8   \n",
       "4  ['long', 'time', 'fan', 'sander', 'delight', '...  ...   27            13   \n",
       "\n",
       "   word_count_sentiment  sentiment_lexicon_simple  sentiment_lexicon_weighted  \\\n",
       "0                   217                 -0.119816                    0.112442   \n",
       "1                   149                 -0.167785                    0.014094   \n",
       "2                   191                  0.125654                    0.421466   \n",
       "3                   202                 -0.029703                    0.227228   \n",
       "4                   234                 -0.042735                    0.227350   \n",
       "\n",
       "                                           text_norm  date_format  year_month  \\\n",
       "0  they would no doubt argue that to have two obj...   1990-11-28     1990-11   \n",
       "1  today i wish to talk about real interest rates...   1991-10-03     1991-10   \n",
       "2  i welcome this opportunity to talk about prosp...   1992-03-14     1992-03   \n",
       "3  it is a pleasure to have this opportunity to a...   1992-05-29     1992-05   \n",
       "4  as a long-time fan of don sanders, i am deligh...   1992-08-17     1992-08   \n",
       "\n",
       "   year  year_month_dt  \n",
       "0  1990     1990-11-01  \n",
       "1  1991     1991-10-01  \n",
       "2  1992     1992-03-01  \n",
       "3  1992     1992-05-01  \n",
       "4  1992     1992-08-01  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the DataFrame.\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7b35431-fd38-4bfc-813b-82e775c06b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference                             object\n",
       "country                               object\n",
       "date                                  object\n",
       "title                                 object\n",
       "author                                object\n",
       "is_gov                                 int64\n",
       "text                                  object\n",
       "text_cleaned                          object\n",
       "text_tokenised                        object\n",
       "text_lemmatised                       object\n",
       "text_lemmatised_str                   object\n",
       "word_count_text                        int64\n",
       "word_count_text_cleaned                int64\n",
       "negative                               int64\n",
       "positive                               int64\n",
       "uncertainty                            int64\n",
       "litigious                              int64\n",
       "strong                                 int64\n",
       "weak                                   int64\n",
       "constraining                           int64\n",
       "word_count_sentiment                   int64\n",
       "sentiment_lexicon_simple             float64\n",
       "sentiment_lexicon_weighted           float64\n",
       "text_norm                             object\n",
       "date_format                   datetime64[ns]\n",
       "year_month                         period[M]\n",
       "year                                   int32\n",
       "year_month_dt                 datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column types.\n",
    "speeches.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2440d2-e663-4f89-a7f2-7d321e3a538a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4109a35-4bb7-43f0-9e11-4e91fe83d414",
   "metadata": {},
   "source": [
    "**Indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0139a9b2-6e61-4bc6-ae53-7d08427f1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for year and month.\n",
    "uk_economic_indicators['year_month'] = pd.to_datetime(uk_economic_indicators['year_month']).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ae3ce4b-1e12-4cdf-9cee-40e5d3e32dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "      <th>uk_inflation_rate_CPIH</th>\n",
       "      <th>uk_unemployment_rate</th>\n",
       "      <th>uk_gdp_growth</th>\n",
       "      <th>uk_interest_rate</th>\n",
       "      <th>uk_consumer_confidence</th>\n",
       "      <th>gbp_usd_fx</th>\n",
       "      <th>ftse_250</th>\n",
       "      <th>gilts_short</th>\n",
       "      <th>gilts_medium</th>\n",
       "      <th>gilts_long</th>\n",
       "      <th>uk_credit_growth_no_cc</th>\n",
       "      <th>uk_credit_growth_only_cc</th>\n",
       "      <th>avg_price_all_property_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>4</td>\n",
       "      <td>1998-04</td>\n",
       "      <td>1.815</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.673270</td>\n",
       "      <td>5554.720972</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.71</td>\n",
       "      <td>14.1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>64258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>5</td>\n",
       "      <td>1998-05</td>\n",
       "      <td>2.039</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.636589</td>\n",
       "      <td>5799.256322</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.55</td>\n",
       "      <td>14.4</td>\n",
       "      <td>24.5</td>\n",
       "      <td>64258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>6</td>\n",
       "      <td>1998-06</td>\n",
       "      <td>1.675</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.650718</td>\n",
       "      <td>5739.277233</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.43</td>\n",
       "      <td>13.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>64258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>7</td>\n",
       "      <td>1998-07</td>\n",
       "      <td>1.443</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>1.643657</td>\n",
       "      <td>5595.919582</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.38</td>\n",
       "      <td>14.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>67057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>8</td>\n",
       "      <td>1998-08</td>\n",
       "      <td>1.327</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>1.631950</td>\n",
       "      <td>5173.355054</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.11</td>\n",
       "      <td>14.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>67057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month year_month  uk_inflation_rate_CPIH  uk_unemployment_rate  \\\n",
       "0  1998      4    1998-04                   1.815                   6.3   \n",
       "1  1998      5    1998-05                   2.039                   6.3   \n",
       "2  1998      6    1998-06                   1.675                   6.3   \n",
       "3  1998      7    1998-07                   1.443                   6.3   \n",
       "4  1998      8    1998-08                   1.327                   6.2   \n",
       "\n",
       "   uk_gdp_growth  uk_interest_rate  uk_consumer_confidence  gbp_usd_fx  \\\n",
       "0            0.6              7.25                     1.1    1.673270   \n",
       "1            0.6              7.25                     1.2    1.636589   \n",
       "2            0.6              7.50                    -1.3    1.650718   \n",
       "3            0.3              7.50                    -4.3    1.643657   \n",
       "4            0.3              7.50                    -6.5    1.631950   \n",
       "\n",
       "      ftse_250  gilts_short   gilts_medium   gilts_long   \\\n",
       "0  5554.720972          5.91           5.70         5.71   \n",
       "1  5799.256322          5.82           5.57         5.55   \n",
       "2  5739.277233          6.17           5.64         5.43   \n",
       "3  5595.919582          6.06           5.57         5.38   \n",
       "4  5173.355054          5.52           5.19         5.11   \n",
       "\n",
       "   uk_credit_growth_no_cc  uk_credit_growth_only_cc  \\\n",
       "0                    14.1                      24.7   \n",
       "1                    14.4                      24.5   \n",
       "2                    13.9                      25.5   \n",
       "3                    14.6                      25.6   \n",
       "4                    14.6                      26.1   \n",
       "\n",
       "   avg_price_all_property_types  \n",
       "0                         64258  \n",
       "1                         64258  \n",
       "2                         64258  \n",
       "3                         67057  \n",
       "4                         67057  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the DataFrame.\n",
    "uk_economic_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6af3d9e2-730d-4708-8680-058fe5fb256c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                                int64\n",
       "month                               int64\n",
       "year_month                      period[M]\n",
       "uk_inflation_rate_CPIH            float64\n",
       "uk_unemployment_rate              float64\n",
       "uk_gdp_growth                     float64\n",
       "uk_interest_rate                  float64\n",
       "uk_consumer_confidence            float64\n",
       "gbp_usd_fx                        float64\n",
       "ftse_250                          float64\n",
       "gilts_short                       float64\n",
       "gilts_medium                      float64\n",
       "gilts_long                        float64\n",
       "uk_credit_growth_no_cc            float64\n",
       "uk_credit_growth_only_cc          float64\n",
       "avg_price_all_property_types        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column types.\n",
    "uk_economic_indicators.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa120d8d-b5b3-4aa4-a232-c25f717fb62d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27236c8e-629b-4e65-96d2-552ba16cabdb",
   "metadata": {},
   "source": [
    "### 2.5. Data Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3ca2069-3663-42ec-a2fb-170154fa0710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>weak</th>\n",
       "      <th>constraining</th>\n",
       "      <th>word_count_sentiment</th>\n",
       "      <th>sentiment_lexicon_simple</th>\n",
       "      <th>sentiment_lexicon_weighted</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>date_format</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>year_month_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>r980915a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>1998-09-15</td>\n",
       "      <td>Speech</td>\n",
       "      <td>george</td>\n",
       "      <td>1</td>\n",
       "      <td>Thank you, Chairman. I'm actually very pleased...</td>\n",
       "      <td>thank chairman actually pleased opportunity re...</td>\n",
       "      <td>['thank', 'chairman', 'actually', 'pleased', '...</td>\n",
       "      <td>['thank', 'chairman', 'actually', 'pleased', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>-0.143750</td>\n",
       "      <td>0.179375</td>\n",
       "      <td>thank you, chairman. i'm actually very pleased...</td>\n",
       "      <td>1998-09-15</td>\n",
       "      <td>1998-09</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>r981021b_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>1998-10-21</td>\n",
       "      <td>Britain in Europe</td>\n",
       "      <td>george</td>\n",
       "      <td>1</td>\n",
       "      <td>It's a great pleasure to be here in the beauti...</td>\n",
       "      <td>great pleasure beautiful city bruges honoured ...</td>\n",
       "      <td>['great', 'pleasure', 'beautiful', 'city', 'br...</td>\n",
       "      <td>['great', 'pleasure', 'beautiful', 'city', 'br...</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>280</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.291071</td>\n",
       "      <td>it's a great pleasure to be here in the beauti...</td>\n",
       "      <td>1998-10-21</td>\n",
       "      <td>1998-10</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>r981119a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>1998-11-19</td>\n",
       "      <td>Speech</td>\n",
       "      <td>george</td>\n",
       "      <td>1</td>\n",
       "      <td>Let me put some of the recent newspaper headli...</td>\n",
       "      <td>let put recent newspaper headlines alongside f...</td>\n",
       "      <td>['let', 'put', 'recent', 'newspaper', 'headlin...</td>\n",
       "      <td>['let', 'put', 'recent', 'newspaper', 'headlin...</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>162</td>\n",
       "      <td>-0.185185</td>\n",
       "      <td>0.069136</td>\n",
       "      <td>let me put some of the recent newspaper headli...</td>\n",
       "      <td>1998-11-19</td>\n",
       "      <td>1998-11</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>r990112a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>1999-01-12</td>\n",
       "      <td>Speech</td>\n",
       "      <td>george</td>\n",
       "      <td>1</td>\n",
       "      <td>I am only too well aware of the pressure curre...</td>\n",
       "      <td>well aware pressure currently facing large par...</td>\n",
       "      <td>['well', 'aware', 'pressure', 'currently', 'fa...</td>\n",
       "      <td>['well', 'aware', 'pressure', 'currently', 'fa...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.194872</td>\n",
       "      <td>0.022051</td>\n",
       "      <td>i am only too well aware of the pressure curre...</td>\n",
       "      <td>1999-01-12</td>\n",
       "      <td>1999-01</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>r990118a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>1999-01-18</td>\n",
       "      <td>Speech</td>\n",
       "      <td>george</td>\n",
       "      <td>1</td>\n",
       "      <td>It would be a masterly understatement to descr...</td>\n",
       "      <td>would masterly understatement describe past tw...</td>\n",
       "      <td>['would', 'masterly', 'understatement', 'descr...</td>\n",
       "      <td>['would', 'masterly', 'understatement', 'descr...</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>168</td>\n",
       "      <td>-0.059524</td>\n",
       "      <td>0.149405</td>\n",
       "      <td>it would be a masterly understatement to descr...</td>\n",
       "      <td>1999-01-18</td>\n",
       "      <td>1999-01</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reference         country       date              title  author  \\\n",
       "4961  r980915a_BOE  united kingdom 1998-09-15             Speech  george   \n",
       "4962  r981021b_BOE  united kingdom 1998-10-21  Britain in Europe  george   \n",
       "4966  r981119a_BOE  united kingdom 1998-11-19             Speech  george   \n",
       "4969  r990112a_BOE  united kingdom 1999-01-12             Speech  george   \n",
       "4970  r990118a_BOE  united kingdom 1999-01-18             Speech  george   \n",
       "\n",
       "      is_gov                                               text  \\\n",
       "4961       1  Thank you, Chairman. I'm actually very pleased...   \n",
       "4962       1  It's a great pleasure to be here in the beauti...   \n",
       "4966       1  Let me put some of the recent newspaper headli...   \n",
       "4969       1  I am only too well aware of the pressure curre...   \n",
       "4970       1  It would be a masterly understatement to descr...   \n",
       "\n",
       "                                           text_cleaned  \\\n",
       "4961  thank chairman actually pleased opportunity re...   \n",
       "4962  great pleasure beautiful city bruges honoured ...   \n",
       "4966  let put recent newspaper headlines alongside f...   \n",
       "4969  well aware pressure currently facing large par...   \n",
       "4970  would masterly understatement describe past tw...   \n",
       "\n",
       "                                         text_tokenised  \\\n",
       "4961  ['thank', 'chairman', 'actually', 'pleased', '...   \n",
       "4962  ['great', 'pleasure', 'beautiful', 'city', 'br...   \n",
       "4966  ['let', 'put', 'recent', 'newspaper', 'headlin...   \n",
       "4969  ['well', 'aware', 'pressure', 'currently', 'fa...   \n",
       "4970  ['would', 'masterly', 'understatement', 'descr...   \n",
       "\n",
       "                                        text_lemmatised  ... weak  \\\n",
       "4961  ['thank', 'chairman', 'actually', 'pleased', '...  ...   16   \n",
       "4962  ['great', 'pleasure', 'beautiful', 'city', 'br...  ...   28   \n",
       "4966  ['let', 'put', 'recent', 'newspaper', 'headlin...  ...   14   \n",
       "4969  ['well', 'aware', 'pressure', 'currently', 'fa...  ...   20   \n",
       "4970  ['would', 'masterly', 'understatement', 'descr...  ...   11   \n",
       "\n",
       "      constraining  word_count_sentiment  sentiment_lexicon_simple  \\\n",
       "4961             2                   160                 -0.143750   \n",
       "4962            17                   280                  0.028571   \n",
       "4966             3                   162                 -0.185185   \n",
       "4969             3                   195                 -0.194872   \n",
       "4970             9                   168                 -0.059524   \n",
       "\n",
       "      sentiment_lexicon_weighted  \\\n",
       "4961                    0.179375   \n",
       "4962                    0.291071   \n",
       "4966                    0.069136   \n",
       "4969                    0.022051   \n",
       "4970                    0.149405   \n",
       "\n",
       "                                              text_norm  date_format  \\\n",
       "4961  thank you, chairman. i'm actually very pleased...   1998-09-15   \n",
       "4962  it's a great pleasure to be here in the beauti...   1998-10-21   \n",
       "4966  let me put some of the recent newspaper headli...   1998-11-19   \n",
       "4969  i am only too well aware of the pressure curre...   1999-01-12   \n",
       "4970  it would be a masterly understatement to descr...   1999-01-18   \n",
       "\n",
       "      year_month  year  year_month_dt  \n",
       "4961     1998-09  1998     1998-09-01  \n",
       "4962     1998-10  1998     1998-10-01  \n",
       "4966     1998-11  1998     1998-11-01  \n",
       "4969     1999-01  1999     1999-01-01  \n",
       "4970     1999-01  1999     1999-01-01  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# speeches given by Edward George are wrongly not stated as is_gov\n",
    "def correct_is_gov_column(speeches_df: pd.DataFrame):\n",
    "    # Make sure date is datetime first\n",
    "    speeches['date'] = pd.to_datetime(speeches['date'], errors='coerce')\n",
    "    \n",
    "    # Apply correction\n",
    "    condition = (\n",
    "        (speeches['author'].str.lower() == 'george') &\n",
    "        (speeches['date'].dt.year > 1993) &\n",
    "        (speeches['date'].dt.year < 2004)\n",
    "    )\n",
    "    speeches.loc[condition, 'is_gov'] = 1  # 1 means Governor\n",
    "    \n",
    "    return speeches\n",
    "\n",
    "# Correct the is_gov column\n",
    "speeches = correct_is_gov_column(speeches)\n",
    "\n",
    "# View the DataFrame\n",
    "display(speeches[speeches['author'].str.lower() == 'george'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5292c3-7c63-4283-b83f-4d091a9b9992",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a99ab5-913d-430b-891e-b04bcd0fda17",
   "metadata": {},
   "source": [
    "## 3. Exploratory Sentiment Analysis & Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205b4a9-2fd5-4ad2-a2d1-06a0cc803fe3",
   "metadata": {},
   "source": [
    "### 3.1. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c4e8d-711e-4030-ba9a-3b5fad79df7b",
   "metadata": {},
   "source": [
    "**3.1.a. Filter for UK only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466bd93f-96d0-47d1-94b6-26229e64be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank OF England (UK) Speeches Only  \n",
    "boe_speeches = speeches[speeches['country'].str.lower() == 'united kingdom'].copy()\n",
    "\n",
    "# View the Dataframe\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a7cd0-c6dc-403f-96e4-f03bc8349f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View column types.\n",
    "boe_speeches.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96bb68-8363-45d4-9536-4c22beeed962",
   "metadata": {},
   "source": [
    "**3.1.b. Transformation to lowercase and removal of punctuation**\n",
    "- Remove elements such as hashtags and urls\n",
    "- Remove any special characters and punctuation\n",
    "- Convert text to lower case\n",
    "- Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0ba09-b86e-4bb0-977a-9ca9fbe33c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "boe_speeches['text_cleaned'] = boe_speeches['text'].apply(preprocess_text)\n",
    "\n",
    "# Review the result.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26fd17-e522-4b7d-8b8e-df4189cb5682",
   "metadata": {},
   "source": [
    "**3.1.c. Tokenisation of the data**<br>\n",
    "Split the cleaned text into individual words, so that text can be analysed at word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002884f3-500c-4e54-9d39-901581f01086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "boe_speeches['text_tokenised'] = boe_speeches['text_cleaned'].apply(word_tokenize)\n",
    "\n",
    "# Review the result.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9e8e5-c2db-410f-b7e1-53a7ce5849a0",
   "metadata": {},
   "source": [
    "**3.1.d. Lemmatisation of the data**<br>\n",
    "Reduce words to its base or dictionary form (the lemma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa2b67-e493-45bb-a6c4-e417958d9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "boe_speeches['text_lemmatised'] = boe_speeches['text_tokenised'].apply(lemmatize_tokens)\n",
    "\n",
    "# Review the result.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec5cc4-c18c-440e-8344-a08db874196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of words into a string\n",
    "boe_speeches['text_lemmatised_str'] = boe_speeches['text_lemmatised'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c5e20-7fa5-458b-905c-d93e4870a1c4",
   "metadata": {},
   "source": [
    "**3.1.e. Include wordcount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c549e5-6385-48a0-8e5d-940160d5c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is 'df' and the column is 'lemmatised_text'\n",
    "boe_speeches['word_count'] = boe_speeches['text_lemmatised_str'].str.split().apply(len)\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb553ea4-cc7b-45cb-87cb-ecb5f0e2a6a6",
   "metadata": {},
   "source": [
    "### 3.2. View data in a wordclouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45ef00-e710-43d4-85d6-7ef71cd2b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(counter):\n",
    "    # Generate and display the word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(counter)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_non_stopwords_wordcloud(text):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    \n",
    "    new = text.str.split()\n",
    "    new = new.values.tolist()\n",
    "    corpus = [word for i in new for word in i]\n",
    "\n",
    "    counter = Counter(corpus)\n",
    "    # Show the word cloud\n",
    "    show_wordcloud(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348b50e-3122-4e60-bbc4-b6d7592dfa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wordcloud of lemmatised text\n",
    "plot_top_non_stopwords_wordcloud(boe_speeches['text_lemmatised_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634cd78-1e11-4930-a985-88e6149e149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bar chart for top words\n",
    "def top_words_barchart(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    counter=Counter(corpus)\n",
    "    most=counter.most_common()\n",
    "    x, y=[], []\n",
    "    for word,count in most[:40]:\n",
    "        if (word not in stop):\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "            \n",
    "    # Set plot size\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot\n",
    "    sns.barplot(x=y, y=x)\n",
    "    \n",
    "    # Set label font sizes\n",
    "    plt.xlabel('Count', fontsize=14)\n",
    "    plt.ylabel('Words', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    plt.title('Top Non-Stopword Words', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96622108-63f4-4747-88bf-355584d58ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart to show top words\n",
    "top_words_barchart(boe_speeches['text_lemmatised_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f640aae-a1e7-47fa-a16d-af3791a91f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bar chart for top word groups\n",
    "def top_word_group_barchart(text, n=2):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:10]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:10]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172bf56b-d3c3-45de-b06e-99933289e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top phrases with 2 words\n",
    "top_word_group_barchart(boe_speeches['text_lemmatised_str'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85285d-ed48-47ce-8643-e461d54b40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top phrases with 3 words\n",
    "top_word_group_barchart(boe_speeches['text_lemmatised_str'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac62f0-600c-49bf-9391-45228cd698fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top phrases with 4 words\n",
    "top_word_group_barchart(boe_speeches['text_lemmatised_str'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f839a2-8287-4a4a-b77c-11ba59d8c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens into a single string.\n",
    "boe_speeches_text = ' '.join(boe_speeches['text_lemmatised_str'])\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', random_state=42).generate(boe_speeches_text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "# Hide the axis.\n",
    "plt.axis('off') \n",
    "\n",
    "# Dispaly the word cloud.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2e8c8-035e-448c-8c2e-ac3a4582d7c7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7e8ca-c08f-46c4-90ce-0a4359655b5a",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using VADER Sentiment Intensity Analyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d24a4-9cff-413a-a650-d138447b0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis to the columns using the lemmatised data converted into strings.\n",
    "boe_speeches['sentiment_score_vader'] = boe_speeches['text_lemmatised'].apply(analyse_sentiment)\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39cc06-9525-4397-82cf-c6344fce2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual sentiment scores for speeches.\n",
    "boe_speeches['text_neg'] = boe_speeches['sentiment_score_vader'].apply(lambda x: x['neg'])\n",
    "boe_speeches['text_neu'] = boe_speeches['sentiment_score_vader'].apply(lambda x: x['neu'])\n",
    "boe_speeches['text_pos'] = boe_speeches['sentiment_score_vader'].apply(lambda x: x['pos'])\n",
    "boe_speeches['text_compound'] = boe_speeches['sentiment_score_vader'].apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebaa4c7-ef10-455c-a352-8ca487416672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b49128-11a8-41c7-ba0a-a6987b53404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories VADER sentiment according to compound_score\n",
    "def vader_sentiment(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the sentiment labels to speeches\n",
    "boe_speeches['vader_sentiment_score'] = boe_speeches['text_compound'].apply(vader_sentiment)\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a810f-51c7-44e6-a725-6fd01e2b2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the vader sentiment score for summary\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the bars.\n",
    "n, bins, patches = plt.hist(boe_speeches['text_compound'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('BoE Wordlist Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of Vader Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e021337-82ba-4af8-b7c1-74501afc081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the sentiment score\n",
    "# Calculate mean and standard deviation\n",
    "mean_score_vader = boe_speeches['text_compound'].mean()\n",
    "std_score_vader = boe_speeches['text_compound'].std()\n",
    "\n",
    "# Create a new column for standardized scores\n",
    "boe_speeches['sentiment_score_vader_std'] = (boe_speeches['text_compound'] - mean_score_vader) / std_score_vader\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716bb8c0-b342-415b-9728-7a6213ed4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the vader sentiment score for summary\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the bars.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_vader_std'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('BoE Wordlist Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of standardised Vader Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aaa961-5a85-4cdf-b23f-b2a8cce20422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be563248-e2f0-42e5-b7d7-f084b2d762e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3fee21-94ac-41f9-b1f7-fe6b62deff16",
   "metadata": {},
   "source": [
    "### 3.2. Sentiment Analysis with BoE Sentiment Wordlist for BoE speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c479a-d0f5-4db8-b421-b8247c7306c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the lexicon\n",
    "sentiment_lexicon = sentiment_lexicon.copy()\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "     'Negative',\n",
    "     'Positive',\n",
    "     'Uncertainty',\n",
    "     'Litigious',\n",
    "     'Strong',\n",
    "     'Weak',\n",
    "     'Constraining',\n",
    " ]\n",
    "\n",
    "# Create dictionary of categories, containing words that belong to that category based on your sentiment lexicon.\n",
    "word_sets = {\n",
    "    cat: set(sentiment_lexicon.loc[sentiment_lexicon[cat] == 1, 'Word'].str.lower())\n",
    "    for cat in categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227b125-286b-464c-9e86-ee9942481965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to apply the lexicon to the text\n",
    "def lexicon_counts(tokens):\n",
    "    return pd.Series({\n",
    "        cat: sum(t in word_sets[cat] for t in tokens)\n",
    "        for cat in categories\n",
    "    })\n",
    "\n",
    "# Compute counts and add new columns for each category\n",
    "boe_speeches = pd.concat(\n",
    "    [boe_speeches, boe_speeches['text_lemmatised'].apply(lexicon_counts)], axis=1\n",
    " )\n",
    "\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e244fc-3cd0-4cd7-83a9-f78cc344d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a dictionary to store word counts per category\n",
    "word_counts_in_category = {cat: {} for cat in categories}\n",
    "\n",
    "# Loop through each tokenised text\n",
    "for tokens in boe_speeches['text_lemmatised']:\n",
    "    tokens_lower = [t.lower() for t in tokens]\n",
    "    for cat in categories:\n",
    "        category_words = word_sets[cat]\n",
    "        for t in tokens_lower:\n",
    "            if t in category_words:\n",
    "                # Count occurrences\n",
    "                word_counts_in_category[cat][t] = word_counts_in_category[cat].get(t, 0) + 1\n",
    "\n",
    "# Create a new DataFrame\n",
    "records = []\n",
    "\n",
    "for cat in categories:\n",
    "    for word, count in word_counts_in_category[cat].items():\n",
    "        records.append({'Word': word, 'Category': cat, 'Count': count})\n",
    "\n",
    "words_df = pd.DataFrame(records)\n",
    "\n",
    "# Sort alphabetically or by count\n",
    "words_df = words_df.sort_values(['Category', 'Word'])\n",
    "\n",
    "# Display the DataFrame\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca5d5d-5337-41e9-a61c-5c80832263e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the wordlist to Excel\n",
    "words_df.to_excel('found_words_counts.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame was exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88038d2-22df-490f-9a31-f3509fa28120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for governor speeches only\n",
    "boe_speeches_gov = boe_speeches[boe_speeches['is_gov'] == 1]\n",
    "\n",
    "# View the DataFrame\n",
    "boe_speeches_gov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be5687-ac2a-488e-9b2a-9f778f1d06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a dictionary to store word counts per category for governor speeches only\n",
    "word_counts_in_category = {cat: {} for cat in categories}\n",
    "\n",
    "# Loop through each tokenized text\n",
    "for tokens in boe_speeches_gov['text_lemmatised']:\n",
    "    tokens_lower = [t.lower() for t in tokens]\n",
    "    for cat in categories:\n",
    "        category_words = word_sets[cat]\n",
    "        for t in tokens_lower:\n",
    "            if t in category_words:\n",
    "                # Count occurrences\n",
    "                word_counts_in_category[cat][t] = word_counts_in_category[cat].get(t, 0) + 1\n",
    "\n",
    "# Create a DataFrame from this data\n",
    "records_gov = []\n",
    "\n",
    "for cat in categories:\n",
    "    for word, count in word_counts_in_category[cat].items():\n",
    "        records_gov.append({'Word': word, 'Category': cat, 'Count': count})\n",
    "\n",
    "words_df_gov = pd.DataFrame(records)\n",
    "\n",
    "# Optional: sort alphabetically or by count\n",
    "words_df_gov = words_df_gov.sort_values(['Category', 'Word'])\n",
    "\n",
    "# Display the DataFrame\n",
    "words_df_gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1e992-b731-4213-9ba8-beffcb47df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel\n",
    "words_df_gov.to_excel('found_words_counts_gov.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame was exported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70ff4f-4437-4a8e-bd79-922d297afe65",
   "metadata": {},
   "source": [
    "**Observations**: The percentages share of negative (32%) and positive words (25%) does not change between governor and non-governor speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f1fd5-29ca-444e-9947-ff837fde4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of words found in each category in all the speeches\n",
    "category_sums = boe_speeches[['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Strong', 'Weak']].sum()\n",
    "\n",
    "# Sort the sums in descending order\n",
    "category_sums_sorted = category_sums.sort_values(ascending=False)\n",
    "\n",
    "# View the results\n",
    "category_sums_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63c6d6-ce9d-4bc3-b77d-e2a8b7b19231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d65853-05f0-4c57-8569-dd76a4a9fe78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d44f90dc-d889-47e0-bdaa-997b18310b8f",
   "metadata": {},
   "source": [
    "**3.2.a. BoE Sentiment Score based on Positive & Negative Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57d884-931f-4fce-ad58-9802302cfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sentiment score by subtracting the negative score from the \n",
    "#positive score and dividing by the total number of words\n",
    "boe_speeches['sentiment_score_lexicon'] = (boe_speeches['Positive'] - boe_speeches['Negative'])/ boe_speeches['word_count']\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccfbf8-5749-4c95-9e4e-c2e46adaaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the vader sentiment score for summary\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the bars.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_lexicon'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('BoE Wordlist Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of BoE Wordlist Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f336a0-aa16-4ce4-a366-fea17564df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of sentiment scores\n",
    "boe_speeches['sentiment_score_lexicon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f159d7-2bb3-4b12-a108-17f9bdf7bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the sentiment score\n",
    "# Calculate mean and standard deviation\n",
    "mean_score = boe_speeches['sentiment_score_lexicon'].mean()\n",
    "std_score = boe_speeches['sentiment_score_lexicon'].std()\n",
    "\n",
    "# Create a new column for standardized scores\n",
    "boe_speeches['sentiment_score_lexicon_std'] = (boe_speeches['sentiment_score_lexicon'] - mean_score) / std_score\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca46aa-2010-4f7e-bf88-be874b789123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the vader sentiment score for summary\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the bars.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_lexicon_std'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('BoE Wordlist Standardised Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of BoE Wordlist Standardised Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d65b22-732f-4698-b874-f2beda7c09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of sentiment scores\n",
    "boe_speeches['sentiment_score_lexicon_std'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28e66f-0fe2-4cc4-a455-90faadfe7c7f",
   "metadata": {},
   "source": [
    "**3.2.b. BoE Sentiment Score based on all Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802084a9-5b5c-4070-95a1-3edff93da182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights to the categories\n",
    "category_weights = {\n",
    "    'Negative': -1,\n",
    "    'Positive': 1.5,\n",
    "    'Uncertainty': 0.2,\n",
    "    'Litigious': -0.2,\n",
    "    'Strong': 1.5,\n",
    "    'Weak': 0.5,\n",
    "    'Constraining': -0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d17b2-f70e-4e4b-aab3-a1f239bc4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to apply the lexicon to the text\n",
    "def lexicon_score_weighted(tokens):\n",
    "    score = 0\n",
    "    for cat in categories:\n",
    "        count = sum(t in word_sets[cat] for t in tokens)\n",
    "        score += count * category_weights[cat]\n",
    "    return score\n",
    "\n",
    "# Compute counts and store as a new column\n",
    "boe_speeches['sentiment_score_lexicon_weighted'] = boe_speeches['text_lemmatised'].apply(lexicon_score_weighted) \\\n",
    "                                                    / boe_speeches['word_count']\n",
    "\n",
    "# View the DataFrame\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68908b-6930-49a0-8762-1331c4349151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the vader sentiment score for summary\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the bars.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_lexicon_weighted'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('BoE Wordlist Weighted Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of BoE Wordlist Weighted Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82764570-170b-418e-9119-e8a418982ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of sentiment scores\n",
    "boe_speeches['sentiment_score_lexicon_weighted'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5aa3b3-27c4-4055-8588-a69b25994e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the sentiment score\n",
    "# Calculate mean and standard deviation\n",
    "mean_score_weighted = boe_speeches['sentiment_score_lexicon_weighted'].mean()\n",
    "std_score_weighted = boe_speeches['sentiment_score_lexicon_weighted'].std()\n",
    "\n",
    "# Create a new column for standardized scores\n",
    "boe_speeches['sentiment_score_lexicon_weighted_std'] = (boe_speeches['sentiment_score_lexicon_weighted'] - mean_score_weighted) / std_score_weighted\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41b6b8-a16d-4178-a43e-284a9e15b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of sentiment scores\n",
    "boe_speeches['sentiment_score_lexicon_weighted_std'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0134606-3ae1-41ec-a2c8-67ca4e9d0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the vader sentiment score for summary\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the bars.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_lexicon_weighted_std'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('BoE Wordlist Weighted Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of BoE Wordlist Weighted Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c1658-c14b-4bea-af78-2c2841b84c5b",
   "metadata": {},
   "source": [
    "**3.2.c. BoE Sentiment Score Labelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a9cae-f945-49cb-ad94-d19b040fbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories sentiment according to sentiment score\n",
    "def categorise_sentiment(sentiment_score, pos_threshold=1, neg_threshold=-1):\n",
    "    if sentiment_score >= pos_threshold:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score <= neg_threshold:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e2289-c1df-4a2e-ad56-12567588a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment labels to speeches\n",
    "boe_speeches['lexicon_label'] = boe_speeches['sentiment_score_lexicon_std'].apply(categorise_sentiment)\n",
    "boe_speeches['lexicon_label_2'] = boe_speeches['sentiment_score_lexicon_std'].apply(categorise_sentiment, pos_threshold=0.5, neg_threshold=-0.5)\n",
    "boe_speeches['lexicon_label_weighted'] = boe_speeches['sentiment_score_lexicon_weighted_std'].apply(categorise_sentiment)\n",
    "boe_speeches['lexicon_label_weighted_2'] = boe_speeches['sentiment_score_lexicon_weighted_std'].apply(categorise_sentiment, pos_threshold=0.5, neg_threshold=-0.5)\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5dcd2-e381-46d1-ae1b-fb048aa8b30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a110370-eef0-45ba-a982-8e636ab2d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories sentiment according to percentile thresholds\n",
    "lower_thresh = boe_speeches['sentiment_score_lexicon_std'].quantile(0.20)\n",
    "upper_thresh = boe_speeches['sentiment_score_lexicon_std'].quantile(0.80)\n",
    "\n",
    "def classify_score(z):\n",
    "    if z >= upper_thresh:\n",
    "        return 'Positive'\n",
    "    elif z <= lower_thresh:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b556a0-c17d-4df1-98cd-6678cbdfbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment labels to speeches\n",
    "boe_speeches['lexicon_label_percentile'] = boe_speeches['sentiment_score_lexicon_std'].apply(classify_score)\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e99f7-a792-4530-9135-b3163fc0d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for lexicon label\n",
    "sentiment_labels_lexicon = boe_speeches['lexicon_label']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_lexicon.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Lexicon Sentiment Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Reviews', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdd885-128b-4beb-bb46-4977a60dd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for lexicon label\n",
    "sentiment_labels_lexicon = boe_speeches['lexicon_label_2']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_lexicon.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Lexicon Sentiment Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Reviews', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b952b-b232-429b-b146-243637ba4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for lexicon label\n",
    "sentiment_labels_lexicon = boe_speeches['lexicon_label_weighted']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_lexicon.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Lexicon Sentiment Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Reviews', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ff6d4-761e-4bd0-aa13-ba625f58eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for lexicon label\n",
    "sentiment_labels_lexicon = boe_speeches['lexicon_label_weighted_2']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_lexicon.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Lexicon Sentiment Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Reviews', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525c135-84e1-435b-93ea-289e28ec6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for lexicon percentile\n",
    "sentiment_labels_lexicon_percentile = boe_speeches['lexicon_label_percentile']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_lexicon_percentile.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Lexicon Sentiment Label Percentile', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Reviews', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd350df-046e-4496-9417-f365adb9ebaa",
   "metadata": {},
   "source": [
    "### 3.3. Sentiment Analysis with GPT Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84f0c6-a31d-4254-9deb-971a9a64bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "gpt_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ea0a1-dd21-4135-9e27-6bb37cfd9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "sentiment_mapping = {\n",
    "    'Positive': 1,\n",
    "    'Neutral': 0,\n",
    "    'Negative': -1\n",
    "}\n",
    "\n",
    "# Apply the mapping to the sentiment column\n",
    "gpt_sentiment['gpt_sentiment_numeric'] = gpt_sentiment['gpt_sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# View the DataFrame\n",
    "gpt_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0f639-f562-4ab7-9e2a-f633f0d914be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for lexicon percentile\n",
    "sentiment_labels_gpt = gpt_sentiment['gpt_sentiment']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_gpt.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Lexicon Sentiment Label Percentile', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Reviews', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd1916-f044-4a26-a409-9c76ae6ec981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the sentiment score\n",
    "# Calculate mean and standard deviation\n",
    "mean_score_gpt = gpt_sentiment['gpt_sentiment_numeric'].mean()\n",
    "std_score = gpt_sentiment['gpt_sentiment_numeric'].std()\n",
    "\n",
    "# Create a new column for standardized scores\n",
    "gpt_sentiment['gpt_sentiment_std'] = (gpt_sentiment['gpt_sentiment_numeric'] - mean_score) / std_score\n",
    "\n",
    "# View the DataFrame.\n",
    "gpt_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e30559-992b-4fb7-b5e7-05ebb918b69d",
   "metadata": {},
   "source": [
    "### 3.4. Sentiment Analysis with FinBERT for BoE speeches using yiyanghkurts model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98887707-649f-41fc-a6a5-4fa9d16adc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to predict probabilities in batches\n",
    "def predict_batch(texts, tokenizer, model, max_length=128):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')  # Tokenize batch of texts\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}                 # Move inputs to the device (GPU or CPU)\n",
    "    with torch.no_grad():                                                 # Get model outputs without computing gradients\n",
    "        outputs = model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=1)                              # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a380b96-2039-4fc6-a884-3e9316f6cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the order of labels in the model\n",
    "model_yiyang.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c39c9-8827-48d9-b7d7-9952173fa926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column that the model should be applied to\n",
    "texts = boe_speeches['text_lemmatised'].astype(str).tolist()\n",
    "\n",
    "# Specify batch size for efficiency\n",
    "batch_size = 32\n",
    "all_probs = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    batch_probs = predict_batch(batch_texts, tokenizer_yiyang, model_yiyang)\n",
    "    all_probs.extend(batch_probs)\n",
    "\n",
    "# Store the predicted probabilities back into your DataFrame\n",
    "boe_speeches['yiyang_probs'] = all_probs\n",
    "\n",
    "# Extract top labels using the order established above\n",
    "labels = ['Neutral', 'Positive', 'Negative']\n",
    "\n",
    "def get_probs_yiyang_dict(probs):\n",
    "    # Assumes probs is an array/list like [neutral_score, positive_score, negative_score]\n",
    "    return {\n",
    "        'yiyang_neutral': probs[0],\n",
    "        'yiyang_positive': probs[1],\n",
    "        'yiyang_negative': probs[2]\n",
    "    }\n",
    "\n",
    "def get_top_label(probs):\n",
    "    idx = probs.argmax()\n",
    "    return labels[idx], probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f02ab-635d-44e2-9c16-683cc0e36378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all class probabilities\n",
    "probs_yiyang = boe_speeches['yiyang_probs'].apply(lambda x: get_probs_yiyang_dict(x)).apply(pd.Series)\n",
    "\n",
    "# Assign back to your main DataFrame\n",
    "boe_speeches = pd.concat([boe_speeches, probs_yiyang], axis=1)\n",
    "\n",
    "# Apply and extract label + confidence\n",
    "boe_speeches[['yiyang_label', 'yiyang_confidence']] = boe_speeches['yiyang_probs'].apply(lambda x: get_top_label(x)).apply(pd.Series)\n",
    "\n",
    "# Now, your DataFrame has the probabilities, top label, and confidence score\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb3187-ee73-467f-8359-02282afd88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights \n",
    "weights = {\n",
    "    'Positive': 1,\n",
    "    'Neutral': 0,\n",
    "    'Negative': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e2133-5020-4f34-895d-7b4867f5436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate one sentiment score\n",
    "def compute_tone_score(probs):\n",
    "    class_labels = ['Neutral', 'Positive', 'Negative']\n",
    "    prob_dict = dict(zip(class_labels, probs))\n",
    "    return (\n",
    "        prob_dict['Positive'] * weights['Positive'] +\n",
    "        prob_dict['Neutral'] * weights['Neutral'] +\n",
    "        prob_dict['Negative'] * weights['Negative']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bb8af-c396-4ade-bd63-9d0136a3e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all rows\n",
    "boe_speeches['sentiment_score_yiyang'] = boe_speeches['yiyang_probs'].apply(compute_tone_score)\n",
    "\n",
    "# View the dataframe\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb486b-e595-47b8-9d42-9550b88dbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the confidence score for BoE speeches\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the plot.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_yiyang'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('Yiyang Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of Yiyang Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543aae55-2ca8-4977-91e8-a6a9891fa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the sentiment score\n",
    "# Calculate mean and standard deviation\n",
    "mean_score_yiyang = boe_speeches['sentiment_score_yiyang'].mean()\n",
    "std_score_yiyang = boe_speeches['sentiment_score_yiyang'].std()\n",
    "\n",
    "# Create a new column for standardized scores\n",
    "boe_speeches['sentiment_score_yiyang_std'] = (boe_speeches['sentiment_score_yiyang'] - mean_score_yiyang) / std_score_yiyang\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f13ea6-1767-4cda-ac59-04fa9f6e8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the standardised sentiment score for BoE speeches\n",
    "# Set the number of bins.\n",
    "num_bins = 15\n",
    "\n",
    "# Set the plot area.\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Define the plot.\n",
    "n, bins, patches = plt.hist(boe_speeches['sentiment_score_yiyang_std'], num_bins, facecolor='#3bd5d7', alpha=0.6)\n",
    "\n",
    "# Set the labels.\n",
    "plt.xlabel('Standardised Yiyang Sentiment Score', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.title('Histogram of Standardised Yiyang Sentiment Score for BoE Speeches', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Display the chart.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6449545-4036-4c63-8961-dbd220cddc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments distribution for yiyang\n",
    "sentiment_labels_yiyang = boe_speeches['yiyang_label']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Calculate the counts and percentages\n",
    "sentiment_counts = pd.Series(sentiment_labels_yiyang.value_counts())\n",
    "sentiment_percentages = sentiment_counts / sentiment_counts.sum() * 100  # Calculate percentages\n",
    "\n",
    "# Plot the bar chart\n",
    "sentiment_counts.plot(kind='bar', color=['#339848', '#482173', '#557cbb'])\n",
    "\n",
    "# Add labels.\n",
    "plt.title('Sentiment Distribution for Yiyang Sentiment Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Sentiment Label', fontsize=10)\n",
    "plt.ylabel('Number of Speeches', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for index, value in enumerate(sentiment_counts):\n",
    "    plt.text(index, value + 0.5, f'{sentiment_percentages[index]:.0f}%', ha='center', fontsize=10)\n",
    "\n",
    "# Save the plot.\n",
    "# plt.savefig('Fig_Sentiment_Reviews.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55513d69-3c34-425c-8d43-3860a2014170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the weighted Sentiment scores.\n",
    "boe_speeches['sentiment_score_yiyang'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06dc010-a69c-4625-b40d-c081a75e941f",
   "metadata": {},
   "source": [
    "### 3.5. Compare sentiment scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc724d-7796-4d2d-85b0-c73ec7bdcdfa",
   "metadata": {},
   "source": [
    "Create a new dataframe with only relevant indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe118bf-3151-4009-abe5-56c1098c3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d54003-3500-4b59-a549-d1b9e10e63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge gpt_sentiment with boe_speeches\n",
    "boe_speeches_new = pd.merge(boe_speeches, gpt_sentiment[['reference', 'gpt_sentiment', 'gpt_sentiment_numeric', \\\n",
    "                                                         'gpt_sentiment_std']], on='reference', how='left')\n",
    "\n",
    "# View the DataFrame\n",
    "boe_speeches_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6855c98-961a-40cc-990f-cac931f8dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with all sentiment scores to include for comparison.\n",
    "boe_speeches_sentiment = boe_speeches_new[['reference', 'country', 'date', 'title', 'author', 'is_gov', 'text',\n",
    "                                           'date_format', 'year_month', 'year_month_dt', 'year',\n",
    "                                           'text_lemmatised', 'text_lemmatised_str', 'word_count',\n",
    "                                           'sentiment_score_lexicon', 'sentiment_score_lexicon_std', 'sentiment_score_lexicon_weighted_std',\n",
    "                                           'lexicon_label', 'lexicon_label_2', 'lexicon_label_weighted', 'lexicon_label_weighted_2', \n",
    "                                           'lexicon_label_percentile',\n",
    "                                           'sentiment_score_yiyang', 'sentiment_score_yiyang_std', 'yiyang_label', \n",
    "                                           'gpt_sentiment', 'gpt_sentiment_numeric', 'gpt_sentiment_std',\n",
    "                                          'text_neg', 'text_neu', 'text_pos', 'text_compound', 'vader_sentiment_score',\n",
    "                                           'sentiment_score_vader_std']]\n",
    "\n",
    "# View the DataFrame.\n",
    "boe_speeches_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe3868-90e0-47c5-97a9-8d8e30c6b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the data\n",
    "boe_speeches_sentiment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546ae23-251a-4ab5-85b1-bfe2358a01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between BoE Wordlist and Finbert sentiment scores\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['sentiment_score_lexicon_std'], boe_speeches_sentiment['sentiment_score_yiyang_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c2bd5-3019-46a3-9512-8c060fa4c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot for BoE dictionary and Finbert sentiment scores\n",
    "sns.scatterplot(x='sentiment_score_lexicon_std', y='sentiment_score_yiyang_std', data=boe_speeches_sentiment)\n",
    "plt.title('Comparison of Standardized Tone Indices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e89a3d-39a7-4b83-9262-9da748494f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between GPT sentiment and Finbert\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['gpt_sentiment_std'], boe_speeches_sentiment['sentiment_score_yiyang_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58008e-7b5e-43e3-943b-d279182be6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between GPT sentiment and BoE Wordlist\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['gpt_sentiment_std'], boe_speeches_sentiment['sentiment_score_lexicon_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64146ad4-2904-4f4a-a107-014450430589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between GPT sentiment and BoE Wordlist\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['gpt_sentiment_std'], boe_speeches_sentiment['sentiment_score_lexicon_weighted_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0ac77-beb4-4fd1-9755-f2f6f5d5e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between GPT sentiment and BoE Wordlist\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['gpt_sentiment_std'], boe_speeches_sentiment['sentiment_score_vader_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd67b6a-05a7-4f1e-88fa-8379b7e0dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between GPT sentiment and BoE Wordlist\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['sentiment_score_lexicon_std'], boe_speeches_sentiment['sentiment_score_vader_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ceac7f-5f81-4745-a72e-a100a2d0ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between GPT sentiment and BoE Wordlist\n",
    "from scipy.stats import pearsonr\n",
    "corr, p_value = pearsonr(boe_speeches_sentiment['sentiment_score_lexicon_weighted_std'], boe_speeches_sentiment['sentiment_score_vader_std'])\n",
    "print(f'Correlation: {corr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ff888-7545-48ba-b2b7-bfc27e5a61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to an Excel file\n",
    "# boe_speeches_sentiment.to_excel('boe_speeches_sentiment.xlsx', index=False)\n",
    "\n",
    "# print(\"DataFrame was exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa944c-4b81-4e61-b847-530baf163b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for agreement (1 for agree, 0 for disagree)\n",
    "boe_speeches_sentiment['agreement_lexicon_yiyang'] = (boe_speeches_sentiment['lexicon_label'] == boe_speeches_sentiment['yiyang_label']).astype(int)\n",
    "\n",
    "boe_speeches_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e29fd9-41d1-42d5-be8e-d1cbceb01476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the agreement vs disagreement\n",
    "agreement_count = boe_speeches_sentiment['agreement_lexicon_yiyang'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "agreement_count.plot(kind='bar', color=['red', 'green'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Agreement vs Disagreement between Lexicon and FinBERT', fontsize=16)\n",
    "plt.xlabel('Agreement (1: Agree, 0: Disagree)', fontsize=14)\n",
    "plt.ylabel('Number of Speeches', fontsize=14)\n",
    "plt.xticks([0, 1], ['Disagree (0)', 'Agree (1)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3ce8a-045c-4f45-80d2-47c7b088937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for agreement (1 for agree, 0 for disagree)\n",
    "boe_speeches_sentiment['agreement_gpt_yiyang'] = (boe_speeches_sentiment['gpt_sentiment'] == boe_speeches_sentiment['yiyang_label']).astype(int)\n",
    "\n",
    "boe_speeches_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47345cae-7fc3-457f-8eca-158d0a77bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the agreement vs disagreement\n",
    "agreement_count = boe_speeches_sentiment['agreement_gpt_yiyang'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "agreement_count.plot(kind='bar', color=['red', 'green'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Agreement vs Disagreement between GPT results and FinBERT', fontsize=16)\n",
    "plt.xlabel('Agreement (1: Agree, 0: Disagree)', fontsize=14)\n",
    "plt.ylabel('Number of Speeches', fontsize=14)\n",
    "plt.xticks([0, 1], ['Disagree (0)', 'Agree (1)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c685db-615d-484d-af97-96757226c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for agreement (1 for agree, 0 for disagree)\n",
    "boe_speeches_sentiment['agreement_gpt_lexicon'] = (boe_speeches_sentiment['gpt_sentiment'] == boe_speeches_sentiment['lexicon_label']).astype(int)\n",
    "\n",
    "boe_speeches_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8102e-8605-45b1-bf12-7d5b82b1e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agreement vs disagreement\n",
    "agreement_count = boe_speeches_sentiment['agreement_gpt_lexicon'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "agreement_count.plot(kind='bar', color=['red', 'green'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Agreement vs Disagreement between GPT results and Lexicon', fontsize=16)\n",
    "plt.xlabel('Agreement (1: Agree, 0: Disagree)', fontsize=14)\n",
    "plt.ylabel('Number of Speeches', fontsize=14)\n",
    "plt.xticks([0, 1], ['Disagree (0)', 'Agree (1)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbc7b4-81f4-4641-a8ff-7aaea13e69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for agreement (1 for agree, 0 for disagree)\n",
    "boe_speeches_sentiment['agreement_gpt_lexicon_2'] = (boe_speeches_sentiment['gpt_sentiment'] == boe_speeches_sentiment['lexicon_label_2']).astype(int)\n",
    "\n",
    "boe_speeches_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d9628-9c5c-4f9a-a763-e8843f116ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agreement vs disagreement\n",
    "agreement_count = boe_speeches_sentiment['agreement_gpt_lexicon_2'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "agreement_count.plot(kind='bar', color=['red', 'green'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Agreement vs Disagreement between GPT results and Lexicon', fontsize=16)\n",
    "plt.xlabel('Agreement (1: Agree, 0: Disagree)', fontsize=14)\n",
    "plt.ylabel('Number of Speeches', fontsize=14)\n",
    "plt.xticks([0, 1], ['Disagree (0)', 'Agree (1)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bfa5b9-8706-4ec1-bcf3-ef2f5d728eb0",
   "metadata": {},
   "source": [
    "**Accuracy Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde025e-6718-4c92-bd88-117cad11957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 5 reviews from the DataFrame.\n",
    "# accuracy_test = boe_speeches_sentiment.sample(n=5, random_state=101)\n",
    "\n",
    "# Extract only the original review and summary columns.\n",
    "# accuracy_test = accuracy_test[['year_month','text', 'lexicon_label', 'yiyang_label', 'gpt_sentiment']]\n",
    "\n",
    "# Add columns for manually labelling the sentiment.\n",
    "# accuracy_test['sentiment_labelled'] = ''\n",
    "\n",
    "# Display the sampled reviews.\n",
    "# accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df512ec-b3d8-441b-bef3-746f24b593df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a CSV file.\n",
    "#  accuracy_test.to_csv('sentiment_accuracy_test.csv', index = True)\n",
    "\n",
    "# print(\"DataFrame was exported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ca4fe-556f-45c3-8c92-95fa4983443c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90f288-74a7-4ca5-9cfd-0cca82b5f6ae",
   "metadata": {},
   "source": [
    "## 4. Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a236c58-91c3-4392-b80d-b5528b94f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_sentiment.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e7701-7a7a-4f50-bc08-938598d02326",
   "metadata": {},
   "source": [
    "**Filter for 2012 to 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020340d-35be-4757-a9f0-c34dec7210b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for 2012 to 2022\n",
    "start_date = '2012-01'\n",
    "end_date = '2022-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bdddb-8fd6-4a33-b2d5-5bf0fa8c140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "boe_speeches_sentiment_12_22 = boe_speeches_sentiment[(boe_speeches_sentiment['year_month'] >= start_date) & (boe_speeches_sentiment['year_month'] <= end_date)]\n",
    "\n",
    "# View the DataFrame\n",
    "boe_speeches_sentiment_12_22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff7e00-bb2f-4b2c-be81-708b65ba94bc",
   "metadata": {},
   "source": [
    "### Speech Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28a223-5e76-4965-8218-8911352b52b3",
   "metadata": {},
   "source": [
    "**Word Count per Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e3825-aef6-4e81-b8ea-b951c66db430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by month\n",
    "wordcount_monthly = boe_speeches_sentiment_12_22.groupby('year_month_dt')['word_count'].mean().reset_index()\n",
    "\n",
    "# View the DataFrame\n",
    "wordcount_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee79a77-59f1-4ce5-977d-b66470ac72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line chart of average word count per month\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(wordcount_monthly['year_month_dt'], wordcount_monthly['word_count'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Word Count')\n",
    "plt.title('Average Word Count per Month')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9dd5d0-8ad1-4a10-8f7b-c9417c124313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "wordcount_yearly = boe_speeches_sentiment_12_22.groupby('year')['word_count'].mean().reset_index()\n",
    "\n",
    "# View the DataFrame\n",
    "wordcount_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788530de-95de-49e7-bcab-c6694cec3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line chart of average word count per year\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(wordcount_yearly['year'], wordcount_yearly['word_count'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Word Count')\n",
    "plt.title('Average Word Count per Year')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cead08c-85d1-4edc-adf3-cc367820786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "wordcount_count_yearly = boe_speeches_sentiment_12_22.groupby('year').agg({'word_count': 'mean',\n",
    "                                                                           'reference': 'count'\n",
    "                                                                          }).reset_index().rename(columns={'reference': 'speech_count'})\n",
    "\n",
    "# View the DataFrame\n",
    "wordcount_count_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe448b-72c7-4c1a-8e9b-b6cc2173f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot 'word_count' on the primary y-axis\n",
    "ax1.plot(wordcount_count_yearly['year'], wordcount_count_yearly['word_count'], color='blue', label='Average Word Count')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Average Word Count')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Create a secondary y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot 'speech_count' on the secondary y-axis\n",
    "ax2.plot(wordcount_count_yearly['year'], wordcount_count_yearly['speech_count'], color='green', label='Number of Speeches')\n",
    "ax2.set_ylabel('Number of Speeches')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add titles and grid if needed\n",
    "plt.title('Avg Word Count and Number of Speeches per Year')\n",
    "\n",
    "# Optionally, add a legend\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26546e36-9b6c-4d7e-9b14-a55f541853d1",
   "metadata": {},
   "source": [
    "**Number of Speeches per Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e3127-26dd-4465-be6c-1f34d44194d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate number of speeches by governor by year\n",
    "governor_speeches_monthly = boe_speeches_sentiment_12_22.groupby(['year', 'is_gov']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "governor_speeches_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a14823-5d07-4464-aa90-b6580e4ac25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "governor_speeches_monthly_pivot = governor_speeches_monthly.pivot(index='year', columns='is_gov', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "governor_speeches_monthly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5b470-5820-49ba-bb43-a8704eb58c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = governor_speeches_monthly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of Speeches')\n",
    "ax.set_title('Count of Speeches by BoE Govenor and other Staff per Year')\n",
    "ax.legend(title='Staff Memmber')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa06d0-31ab-48c8-bf62-74cab388f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_sentiment_12_22.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683e73b-70f8-4f21-980f-59fa2cbc5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "gpt_sentiment_yearly= boe_speeches_sentiment_12_22.groupby(['year', 'gpt_sentiment']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "gpt_sentiment_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e3eec-5004-4715-b307-5147c182c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "gpt_sentiment_yearly_pivot = gpt_sentiment_yearly.pivot(index='year', columns='gpt_sentiment', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "gpt_sentiment_yearly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe2cca-0490-436b-8d02-4c4957d0d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = gpt_sentiment_yearly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of GPT Sentiments')\n",
    "ax.set_title('GPT Sentiment Distribution per Year')\n",
    "ax.legend(title='Sentiment')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2efed-6ffb-41d0-94c5-dd0d291644c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "lexicon_sentiment_yearly= boe_speeches_sentiment_12_22.groupby(['year', 'lexicon_label']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f035e3b-a080-4ae6-a145-f22c8ec565fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "lexicon_sentiment_yearly_pivot = lexicon_sentiment_yearly.pivot(index='year', columns='lexicon_label', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_yearly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629d4ea-43d3-474f-bac7-071b5a8b5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = lexicon_sentiment_yearly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of BoE Wordlist Sentiments')\n",
    "ax.set_title('BoE Wordlist Sentiment Distribution per Year')\n",
    "ax.legend(title='Sentiment')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955d99d-15ed-4dd0-a9b2-ac7b8d6a1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "lexicon_sentiment_2_yearly= boe_speeches_sentiment_12_22.groupby(['year', 'lexicon_label_2']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_2_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab1d3b-6084-491d-9735-52826acd6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "lexicon_sentiment_2_yearly_pivot = lexicon_sentiment_2_yearly.pivot(index='year', columns='lexicon_label_2', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_2_yearly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ee98f-bc52-423d-b328-467039c32ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = lexicon_sentiment_2_yearly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of BoE Wordlist Sentiments')\n",
    "ax.set_title('BoE Wordlist Sentiment Distribution per Year')\n",
    "ax.legend(title='Sentiment')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358f0ac-17fd-43b1-b3e9-83de6dc45ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "lexicon_sentiment_weighted_yearly= boe_speeches_sentiment_12_22.groupby(['year', 'lexicon_label_weighted']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_weighted_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e20b2-b25e-4073-a252-78180827047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "lexicon_sentiment_weighted_yearly_pivot = lexicon_sentiment_weighted_yearly.pivot(index='year', columns='lexicon_label_weighted', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_weighted_yearly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933dd2d3-b781-4c86-aff9-8067c7823f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = lexicon_sentiment_weighted_yearly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of BoE Wordlist Sentiments')\n",
    "ax.set_title('BoE Wordlist Sentiment Distribution per Year')\n",
    "ax.legend(title='Sentiment')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ff058-2b56-46d1-8a0e-b332393083e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "lexicon_sentiment_weighted_2_yearly= boe_speeches_sentiment_12_22.groupby(['year', 'lexicon_label_weighted_2']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_weighted_2_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b676e3-418a-4373-b944-d06679b5b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "lexicon_sentiment_weighted_2_yearly_pivot = lexicon_sentiment_weighted_2_yearly.pivot(index='year', columns='lexicon_label_weighted_2', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "lexicon_sentiment_weighted_2_yearly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94049a71-34ed-4ce6-b77e-612cbb47c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = lexicon_sentiment_weighted_2_yearly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of BoE Wordlist Sentiments')\n",
    "ax.set_title('BoE Wordlist Sentiment Distribution per Year')\n",
    "ax.legend(title='Sentiment')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82757c8-c1cd-4dde-96a1-7ad05d0d8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "yiyang_sentiment_yearly= boe_speeches_sentiment_12_22.groupby(['year', 'yiyang_label']).size().reset_index(name='count')\n",
    "\n",
    "# View the DataFrame\n",
    "yiyang_sentiment_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d4fa0-801e-40fc-9307-b05b0210f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data for plotting\n",
    "yiyang_sentiment_yearly_pivot = yiyang_sentiment_yearly.pivot(index='year', columns='yiyang_label', values='count').fillna(0)\n",
    "\n",
    "# View the DataFrame\n",
    "yiyang_sentiment_yearly_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2238ba-01a2-4140-b647-afc9e1d74f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart per month\n",
    "ax = yiyang_sentiment_yearly_pivot.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count of BoE Wordlist Sentiments')\n",
    "ax.set_title('Yiyang Sentiment Distribution per Year')\n",
    "ax.legend(title='Sentiment')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29b10b-c97c-4b74-99dc-7591a4f2adb7",
   "metadata": {},
   "source": [
    "### 4.1. Compare the sentiment scores over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf94c66-d3bd-492a-886f-472e95eb1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by month\n",
    "sentiment_monthly = boe_speeches_sentiment.groupby('year_month_dt')[['sentiment_score_yiyang_std','sentiment_score_lexicon_std', \\\n",
    "                                    'gpt_sentiment_std', 'sentiment_score_yiyang','sentiment_score_lexicon', \\\n",
    "                                    'gpt_sentiment_numeric', 'sentiment_score_lexicon_weighted_std']].mean().reset_index()\n",
    "# View the DataFrame\n",
    "sentiment_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42dd97-8d6d-47f0-a5a2-20c848f78849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the DataFrame\n",
    "sentiment_monthly.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329713e6-c6ff-4d44-8cd3-037ba62d7a5e",
   "metadata": {},
   "source": [
    "**4.1.a. Analysis by date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0ff53-5e7b-4063-998f-ae967228608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_monthly,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_yiyang_std','sentiment_score_lexicon_std', 'gpt_sentiment_numeric'],\n",
    "     title=\"Average monthly sentiment scores – Bank of England speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540c227-eb7d-4226-ade6-c62f217e9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_monthly,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_yiyang_std','sentiment_score_lexicon_std'],\n",
    "     title=\"Average monthly sentiment scores – Bank of England speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103d38b-0ea9-411f-80ac-dde53a4fa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_monthly,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_numeric'],\n",
    "     title=\"Average monthly BoE Wordlist and GPT sentiment scores – Bank of England speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4f2c1-d4e2-4bb2-acd8-ca67e07c278d",
   "metadata": {},
   "source": [
    "**4.1.b. Analysis by year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be9f30-20b8-40e9-a539-76d1641516d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_sentiment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99298e9-2d9f-4167-9c47-2382c370679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by year\n",
    "sentiment_yearly = boe_speeches_sentiment.groupby('year')[['sentiment_score_yiyang_std','sentiment_score_lexicon_std', \\\n",
    "                                    'gpt_sentiment_std', 'sentiment_score_yiyang','sentiment_score_lexicon', \\\n",
    "                                    'gpt_sentiment_numeric', 'sentiment_score_lexicon_weighted_std', \\\n",
    "                                                           'sentiment_score_vader_std']].mean().reset_index()\n",
    "# View the DataFrame\n",
    "sentiment_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54884323-7cc0-4c44-8489-1460a593e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_yearly,\n",
    "     x='year',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_std'],\n",
    "     title=\"Average yearly BoE Wordlist and GPT sentiment scores – BoE Speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b600225-e483-4574-ba40-7738cc2f737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_yearly,\n",
    "     x='year',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_std', 'sentiment_score_vader_std'],\n",
    "     title=\"Average yearly BoE Wordlist Weighted and GPT sentiment scores – BoE Speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2121fc-426a-46ed-a008-241acb7d9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_yearly,\n",
    "     x='year',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_std', 'sentiment_score_yiyang_std', 'sentiment_score_vader_std'],\n",
    "     title=\"Average yearly BoE Wordlist, GPT and FinBert sentiment scores – BoE Speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fa11d-1772-40d7-957f-3c219d5445fb",
   "metadata": {},
   "source": [
    "**4.1.c. Analysis by quarter/ 3 month averages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f7777-1288-4927-b85f-4adb077f5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by quarter\n",
    "sentiment_quarterly = boe_speeches_sentiment.groupby(pd.Grouper(key='year_month_dt', freq='Q'))[\n",
    "    ['sentiment_score_yiyang_std', 'sentiment_score_lexicon_std',\n",
    "     'gpt_sentiment_std', 'sentiment_score_yiyang', 'sentiment_score_lexicon',\n",
    "     'gpt_sentiment_numeric', 'sentiment_score_vader_std']\n",
    "].mean().reset_index()\n",
    "\n",
    "# View the DataFrane\n",
    "sentiment_quarterly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d80183-7d96-443f-9b22-4eb4c875be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrane\n",
    "sentiment_quarterly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ea345-220f-4fef-aef9-f419c08a800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_quarterly,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_std', 'sentiment_score_vader_std'],\n",
    "     title=\"Average quaterly BoE Wordlist and GPT sentiment scores – BoE Speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc76f3-f762-4ef8-b67f-beadaf1fdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_quarterly,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_std', 'sentiment_score_vader_std'],\n",
    "     title=\"Average quaterly BoE Wordlist and GPT sentiment scores – BoE Speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18fcbc-bb00-4a3a-b755-d50e5a28cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time\n",
    "\n",
    "# Define the plot\n",
    "fig = px.line(\n",
    "     sentiment_quarterly,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_lexicon_std','gpt_sentiment_std', 'sentiment_score_yiyang_std'],\n",
    "     title=\"Average quaterly BoE Wordlist, GPT and FinBert sentiment scores – BoE Speeches (1997–2022)\",\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dff991-d2b2-430f-9ad2-cd4258665b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cff708b-1338-46ee-bf96-64c82eba8983",
   "metadata": {},
   "source": [
    "### 4.2.Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66640b2c-05d8-44ef-aec4-d875dcd53c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame\n",
    "sentiment_monthly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db5f08-0dfb-447e-8aa8-5bc1f7dc752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data by date for Covid\n",
    "start_date = '2012-01'\n",
    "end_date = '2022-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def2862-2d96-4a40-8602-2af15cb34336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "seasonality = sentiment_monthly[(sentiment_monthly['year_month_dt'] >= start_date) & (sentiment_monthly['year_month_dt'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ec4b6-a991-42e0-80a3-7fa6e0bad4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the datetime as index\n",
    "seasonality.set_index('year_month_dt', inplace=True)\n",
    "\n",
    "# View the DataFrame\n",
    "seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61777f77-8cb8-4eea-a642-e8c5f6f0b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "decomposed_lexicon = seasonal_decompose(seasonality['sentiment_score_lexicon_std'], model='additive', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposed_lexicon.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa05ae-c1ba-463b-8568-bf2b503baaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "decomposed_gpt = seasonal_decompose(seasonality['gpt_sentiment_std'], model='additive', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposed_gpt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cecb8-b06a-4d5c-9b40-9d8133fa05a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6198d0d-e219-460b-91c5-f25829c2f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "decomposed_finbert = seasonal_decompose(seasonality['sentiment_score_yiyang_std'], model='additive', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposed_finbert.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d474c8-0000-4eea-86e7-cc24f73a36fd",
   "metadata": {},
   "source": [
    "**Observations Peaks**\n",
    "- August 2013: Peak with a speech announcing Jane Austen on 10 GBP note and a discussion of the evolution of monetary policy since 2008-2009 crisis\n",
    "- January 2022: speech about inflation with a sense of urgency about controlling inflation with reassurance that the Bank is actively monitoring and prepared to act responsibly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9c1bb-eb5e-4264-9cb6-c63caf08db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_quarterly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a32e12-6c18-4cd3-9e03-dc495f70e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data by date for Covid\n",
    "start_date = '2012-01'\n",
    "end_date = '2022-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e0906-b5bb-4d9d-8c5b-d50542b6bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "seasonality_quarterly = sentiment_quarterly[(sentiment_quarterly['year_month_dt'] >= start_date) & (sentiment_quarterly['year_month_dt'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b1d05-2433-4c42-b85d-0b78263970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the datetime as index\n",
    "seasonality_quarterly.set_index('year_month_dt', inplace=True)\n",
    "\n",
    "# View the DataFrame\n",
    "seasonality_quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ccc990-e0a9-4fa9-b49e-1d933fb27344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "decomposed_lexicon_quarterly = seasonal_decompose(seasonality_quarterly['sentiment_score_lexicon_std'], model='additive', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposed_lexicon_quarterly.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a65213-c4aa-4426-892e-24d7e126a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "decomposed_gpt_quarterly = seasonal_decompose(seasonality_quarterly['gpt_sentiment_std'], model='additive', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposed_gpt_quarterly.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f6bdf-6ffb-46a0-8fae-09bda6c56077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a226a-544c-426b-8daa-042ebf9d6437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cfa4b-13ac-4658-a141-a895eeffed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d9de9-a556-4a5c-a58d-5da6f4bc91f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "447f4a73-9c11-4852-84c5-20a69b600e9e",
   "metadata": {},
   "source": [
    "## Governor speeches only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e1d3c-c32d-4e7b-b32d-45402dc49367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter speeches for governors only\n",
    "boe_speeches_finbert_gov = boe_speeches_finbert[boe_speeches_finbert['is_gov'] == 1]\n",
    "\n",
    "# View the DataFrame\n",
    "boe_speeches_finbert_gov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51786ac-f1e7-4b9e-b216-664f3d6097a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the DataFrame\n",
    "boe_speeches_finbert_gov.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9689e-842f-441a-a5d2-28ff96d32c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate sentiment scores by month\n",
    "finbert_monthly_gov = boe_speeches_finbert_gov.groupby('year_month')[['yiyang_neutral', 'yiyang_positive', 'yiyang_negative', \\\n",
    "                                                              'yiyang_confidence', 'sentiment_score_yiyang', \\\n",
    "                                                                 'sentiment_score_yiyang_std']].mean().reset_index()\n",
    "finbert_monthly_gov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d89ac6-7f8a-431e-b388-e5bfb57741fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date format\n",
    "finbert_monthly_gov['year_month_dt'] = finbert_monthly_gov['year_month'].dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05cfed-dca9-4fd2-b15b-4634a03b9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for 10 years\n",
    "start_date = '2012-01'\n",
    "end_date = '2022-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d213504-6e00-4690-bf6f-c30a4e427d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "seasonality_finbert_gov_10 = finbert_monthly_gov[(finbert_monthly_gov['year_month'] >= start_date) & \\\n",
    "                          (finbert_monthly_gov['year_month'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb5a57-f605-4a4f-838d-ea9d43c80b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the datetime as index\n",
    "seasonality_finbert_gov_10.set_index('year_month_dt', inplace=True)\n",
    "\n",
    "# View the DataFrame\n",
    "seasonality_finbert_gov_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180f489-8851-4382-bbf7-8ac0f379a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "decomposed = seasonal_decompose(seasonality_finbert_gov_10['sentiment_score_yiyang_std'], model='additive', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposed.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0bb0d-ef8a-4ccd-ad43-e5fa538a7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51ccb2f2-2910-4502-a24d-4ac7673a23d1",
   "metadata": {},
   "source": [
    "### 4.1. Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf9dfb-22ce-4052-9417-22bd025c8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data by date for Covid\n",
    "start_date = '2020-01'\n",
    "end_date = '2022-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347df1b-b3fa-4c18-be2d-425413a73fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "finbert_covid = finbert_monthly[(finbert_monthly['year_month_dt'] >= start_date) & (finbert_monthly['year_month_dt'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2780e4d-e4f1-4c56-b2e4-8314640eba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "     finbert_covid,\n",
    "     x='year_month_dt',\n",
    "     y=['yiyang_neutral','yiyang_positive', 'yiyang_negative'],\n",
    "     title='Average monthly Finbert scores – Bank of England speeches during Covid (2020–2022)',\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'},\n",
    "    color_discrete_sequence=['blue', 'green', 'red']\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9460c0-ece4-4d8c-ba03-c8999e32e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "     finbert_covid,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_yiyang_std'],\n",
    "     title='Average monthly standardised Finbert scores – Bank of England speeches during Covid (2020–2022)',\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f6164-1d6c-43d0-92e2-cb10c2ee0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "finbert_gov_covid = finbert_monthly_gov[(finbert_monthly_gov['year_month_dt'] >= start_date) & (finbert_monthly_gov['year_month_dt'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1596cf7-0130-4621-b540-926555839d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "     finbert_gov_covid,\n",
    "     x='year_month_dt',\n",
    "     y=['yiyang_neutral','yiyang_positive', 'yiyang_negative'],\n",
    "     title='Average monthly Finbert scores – Bank of England speeches during Covid (2020–2022)',\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'},\n",
    "    color_discrete_sequence=['blue', 'green', 'red']\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbe556-e7ab-46c8-b6a6-e9ae5d970d6a",
   "metadata": {},
   "source": [
    "### 4.2. Brexit vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d01e0-d494-47d6-88af-91f5dc7c54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data by date for before and after Brexit\n",
    "start_date = '2016-01'\n",
    "end_date = '2017-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fcbba-9544-4e1b-bf36-2ba88ae07a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for specified period\n",
    "finbert_brexit = finbert_monthly[(finbert_monthly['year_month_dt'] >= start_date) & (finbert_monthly['year_month_dt'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3edbc0-118d-4b40-8ac3-4c85be55940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "     finbert_brexit,\n",
    "     x='year_month_dt',\n",
    "     y=['yiyang_neutral','yiyang_positive', 'yiyang_negative'],\n",
    "     title='Average monthly Finbert scores – Bank of England speeches during Brexit (2016–2017)',\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'},\n",
    "    color_discrete_sequence=['blue', 'green', 'red']\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe00734-f897-41e1-9486-178d7da7754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "     finbert_covid,\n",
    "     x='year_month_dt',\n",
    "     y=['sentiment_score_yiyang_std'],\n",
    "     title='Average monthly stamdardised Finbert scores – Bank of England speeches during Brexit (2016–2017)',\n",
    "     labels={'value': 'Average score', 'variable': 'Metric'}\n",
    ")\n",
    "\n",
    "# Adjust size\n",
    "fig.update_layout(width=1100, height=600)\n",
    "\n",
    "# Move the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.8,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d8bef-27c1-454f-9995-07ae68720424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce8854-5e07-4a5a-89c4-3f5f2cefb395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40047399-3b21-425b-a6d2-5ed78ab04ade",
   "metadata": {},
   "source": [
    "### Filter the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63035d-559f-495a-b663-69dfa222272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_words = {\n",
    "    'inflation': ['inflation'],           \n",
    "    'monetary policy': ['monetary policy'],               \n",
    "    'price stability': ['price stability'],\n",
    "    'exchange rate': ['exchange rate'],\n",
    "    'growth': ['growth'],\n",
    "    'financial market': ['finanical market']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5126d-befb-4dae-8a81-8827fc571871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word(text, word):\n",
    "    tokens = [w.lower() for w in word_tokenize(str(text))]\n",
    "    return tokens.count(word.lower())\n",
    "\n",
    "# Assuming your DataFrame is 'df' and text column is 'speech_text'\n",
    "\n",
    "for category, words in target_words.items():\n",
    "    # Since each category only has one word, no need to iterate over list, just take the first\n",
    "    word = words[0]\n",
    "    # Count occurrences of the word in each speech\n",
    "    boe_speeches_sentiment[category + '_count'] = boe_speeches_sentiment['text_lemmatised'].apply(lambda x: count_word(x, word))\n",
    "\n",
    "# Now, create separate dataframes per category\n",
    "inflation_df = boe_speeches_sentiment[['text_lemmatised', 'inflation_count']].copy()\n",
    "monetary_policy_df = boe_speeches_sentiment[['text_lemmatised', 'monetary policy_count']].copy()\n",
    "price_stability_df = boe_speeches_sentiment[['text_lemmatised', 'price stability_count']].copy()\n",
    "exchange_rate_df = boe_speeches_sentiment[['text_lemmatised', 'exchange rate_count']].copy()\n",
    "growth_df = boe_speeches_sentiment[['text_lemmatised', 'growth_count']].copy()\n",
    "financial_market_df = boe_speeches_sentiment[['text_lemmatised', 'financial market_count']].copy()\n",
    "\n",
    "# (Optional) filter for speeches where the target word appears at least once\n",
    "inflation_df = inflation_df[inflation_df['inflation_count'] > 3]\n",
    "monetary_policy_df = monetary_policy_df[monetary_policy_df['monetary policy_count'] > 3]\n",
    "price_stability_df = price_stability_df[price_stability_df['price stability_count'] > 3]\n",
    "exchange_rate_df = exchange_rate_df[exchange_rate_df['exchange rate_count'] > 3]\n",
    "growth_df = growth_df[growth_df['growth_count'] > 3]\n",
    "financial_market_df = financial_market_df[financial_market_df['financial market_count'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1526b-9b1e-4caa-b25c-c9b7e85ed3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word(text, word):\n",
    "    tokens = [w.lower() for w in word_tokenize(str(text))]\n",
    "    return tokens.count(word.lower())\n",
    "\n",
    "# Assuming your DataFrame is 'df' and text column is 'speech_text'\n",
    "\n",
    "for category, words in target_words.items():\n",
    "    # Since each category only has one word, no need to iterate over list, just take the first\n",
    "    word = words[0]\n",
    "    # Count occurrences of the word in each speech\n",
    "    boe_speeches_sentiment[category + '_count'] = boe_speeches_sentiment['text'].apply(lambda x: count_word(x, word))\n",
    "\n",
    "# Now, create separate dataframes per category\n",
    "inflation_df = boe_speeches_sentiment[['text', 'inflation_count']].copy()\n",
    "monetary_policy_df = boe_speeches_sentiment[['text', 'monetary policy_count']].copy()\n",
    "price_stability_df = boe_speeches_sentiment[['text', 'price stability_count']].copy()\n",
    "exchange_rate_df = boe_speeches_sentiment[['text', 'exchange rate_count']].copy()\n",
    "growth_df = boe_speeches_sentiment[['text', 'growth_count']].copy()\n",
    "financial_market_df = boe_speeches_sentiment[['text', 'financial market_count']].copy()\n",
    "\n",
    "# (Optional) filter for speeches where the target word appears at least once\n",
    "inflation_df = inflation_df[inflation_df['inflation_count'] > 3]\n",
    "monetary_policy_df = monetary_policy_df[monetary_policy_df['monetary policy_count'] > 3]\n",
    "price_stability_df = price_stability_df[price_stability_df['price stability_count'] > 3]\n",
    "exchange_rate_df = exchange_rate_df[exchange_rate_df['exchange rate_count'] > 3]\n",
    "growth_df = growth_df[growth_df['growth_count'] > 3]\n",
    "financial_market_df = financial_market_df[financial_market_df['financial market_count'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11de0c-890e-4707-a8c0-576fc13156d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167c803-91db-4924-8190-b4a63fb5ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary_policy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfbff9-de56-4d00-9186-0bacc8da9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_stability_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ad74b-a7f2-4a5f-8260-ec8a7e7b5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d828851-bc2d-492f-b257-86038a1adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd43b2-577b-4868-b5e7-39a877c2d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_market_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94f28c-b057-4a59-86a1-7d8226de4c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d6ac5-b740-43e6-a782-c3bef8c7d8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c8ff8-6037-4daa-b28d-8bc85a513f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f30b48-4879-4ead-8c30-be602f2ab83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc82d0-6772-4bde-b4f5-c2a155ccc4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060e0c3-eebd-4e9a-93fb-8927f9960f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_target_words(text, target_words):\n",
    "    tokens = [w.lower() for w in word_tokenize(str(text))]\n",
    "    count = sum(tokens.count(word) for word in target_words)\n",
    "    return count\n",
    "\n",
    "# Apply and add as a new column\n",
    "target_words = ['inflation', 'monetary policy', 'price stability', 'exchange rate', 'growth', 'financial market']\n",
    "boe_speeches_sentiment['target_word_freq'] = boe_speeches_sentiment['text_lemmatised_str'].apply(lambda x: count_target_words(x, target_words))\n",
    "\n",
    "# View the dataFrame\n",
    "boe_speeches_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150f248-85fb-4f37-a090-99c4381b684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, speeches where 'inflation' appears more than 3 times\n",
    "inflation_df = boe_speeches_sentiment[boe_speeches_sentiment['target_word_freq'] > 5]\n",
    "\n",
    "inflation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2b16b-9b34-4011-b704-39f566a02ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf2d28-cba4-42a3-9290-cb1feb0d94ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceba86-a7bd-471a-8367-4ff224ae5888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0d613-3ccf-4409-aa05-79fff85c1002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80e983-7246-4fe0-a0a8-0e4636844c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51ae1221-7ea0-4836-b8f9-9270a6c1c3fa",
   "metadata": {},
   "source": [
    "## 4. Exploratory Analysis for Correlation with Economic Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a9f80-00f1-4f22-9b7f-394f73b95790",
   "metadata": {},
   "source": [
    "### 4.1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41c52e-0d84-4b03-9579-73e23c61a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames to merge\n",
    "dataframes_to_merge = [uk_economic_indicators]\n",
    "\n",
    "# Use reduce to merge all DataFrames in the list\n",
    "boe_speeches_indicators = reduce(lambda left, right: left.merge(right, on='year_month', how='left'), dataframes_to_merge, boe_speeches_new)\n",
    "\n",
    "# View the merged DataFrame\n",
    "boe_speeches_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b27fc-c98c-4b92-bd2b-823d0b78bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values.\n",
    "boe_speeches_indicators.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777598b5-bdbe-4661-8761-4c3e4aa1e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the DataFrame.\n",
    "boe_speeches_indicators.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175255a-ecad-43f2-afd0-0fc208577d5f",
   "metadata": {},
   "source": [
    "### 4.2. Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab436fc-803d-49e0-8379-3dbcd1e936a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names.\n",
    "boe_speeches_indicators.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261bc3f-81e8-4991-a9b9-b9732c0bbe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_indicators['year_month'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79857a0b-7dc4-4a50-967d-914f789c18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'year_month' Period to datetime\n",
    "# boe_speeches_indicators['date'] = boe_speeches_indicators['year_month'].dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0280c-7c45-4c0c-b647-193747499056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boe_speeches_indicators['year_month'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd481a-611d-42ef-b4b8-575907ccaf99",
   "metadata": {},
   "source": [
    "**Confidence Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca5602-f7fc-4ac8-b6f9-6bb8a32f0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators['text_compound'], color='blue', label='VADER compound score')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('VADER compound score', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['confidence_index'], color='red', label='Confidence Index')\n",
    "ax2.set_ylabel('Confidence Index', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England VADER Sentiment Score vs UK Confidence Index')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a525ce-ede0-4513-90f4-f6f905e6ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators['sentiment_score_lm_weighted'], color='blue', label='sentiment_score_lm_weighted')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('sentiment_score_lm_weighted', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['confidence_index'], color='red', label='Confidence Index')\n",
    "ax2.set_ylabel('Confidence Index', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England Loughran-McDonald Weighted Sentiment Score vs UK Confidence Index')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4db4cd-c2e7-4c53-b580-de42d972e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators[['text_pos', 'text_neg', 'text_neu']], color='blue', label='VADER compound score')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('VADER Scores', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['confidence_index'], color='red', label='Confidence Index')\n",
    "ax2.set_ylabel('Confidence Index', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England VADER Sentiment Score vs UK Confidence Index')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c67387-f522-434c-9e16-e50464cb13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators[['Positive', 'Negative', 'Uncertainty']], color='blue', label='Lexicom Sentiment')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Lexicon Sentiment', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['confidence_index'], color='red', label='Confidence Index')\n",
    "ax2.set_ylabel('Confidence Index', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England VADER Sentiment Score vs UK Confidence Index')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14894b-c0bd-42cc-9b57-ea6106bfc93c",
   "metadata": {},
   "source": [
    "**Inflation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb493b-181e-41c8-bf02-0d2c33f4aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators[['negative_lm', 'positive_lm', 'uncertainty_lm']], color='blue', label='weighted_sentiment_LM')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('weighted_sentiment_LM', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['Inflation Rate'], color='red', label='Inflation Rate')\n",
    "ax2.set_ylabel('Inflation Rate', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England Loughran-McDonald Weighted Sentiment Score vs UK Inflation Rate')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19fb50-cdf5-4676-bc73-0efecd5bd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators['sentiment_score_lm_weighted'], color='blue', label='sentiment_score_lm_weighted')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('weighted_sentiment_LM', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['Unemployment rate'], color='red', label='Unemployment Rate')\n",
    "ax2.set_ylabel('Unemployment Rate', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England Loughran-McDonald Weighted Sentiment Score vs UK Unemployment Rate')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9914857-00e5-4966-9794-65fd1a2e249e",
   "metadata": {},
   "source": [
    "**Interest Rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4c74e-426a-433f-8abe-85b21aba3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators['sentiment_score_lm_weighted'], color='blue', label='sentiment_score_lm_weighted')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('weighted_sentiment_LM', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['Bank Rate'], color='red', label='Bank Rate')\n",
    "ax2.set_ylabel('Bank Rate', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England Loughran-McDonald Weighted Sentiment Score vs UK Bank Rate')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e2105-4848-44d9-9f70-831277f741b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators['sentiment_score_lm_weighted'], color='blue', label='sentiment_score_lm_weighted')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('weighted_sentiment_LM', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['Bank Rate'], color='red', label='Bank Rate')\n",
    "ax2.set_ylabel('Bank Rate', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England Loughran-McDonald Weighted Sentiment Score vs UK Bank Rate')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de6fda-79c0-4d18-9196-bc4353438277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot VADER text_compound on primary y-axis.\n",
    "ax1.plot(boe_speeches_indicators['date'], boe_speeches_indicators[['text_pos', 'text_neg', 'text_neu']], color='blue', label='VADER compound score')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('VADER Scores', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot  on secondary y-axis\n",
    "ax2.plot(boe_speeches_indicators['date'], boe_speeches_indicators['Bank Rate'], color='red', label='Bank Rate')\n",
    "ax2.set_ylabel('Bank Rate', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Bank of England VADER Sentiment Score vs UK Bank Rate')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462a260-40ab-4d9e-a0d2-7d5cf14ef6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec68517-0081-498b-953b-506911dcd1ec",
   "metadata": {},
   "source": [
    "### 4.3. Initial statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c92df-0f99-4a4c-8555-e22d15b57c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_indicators.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754d8b9-751b-4ddf-9366-5a35e7f4b182",
   "metadata": {},
   "source": [
    "**4.3.a. GPT Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42dc65-9124-43c0-9665-b7a88d1e3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for GPT sentiment score and all economic indicators.\n",
    "columns_sentiment_gpt = ['gpt_sentiment_std', 'uk_inflation_rate_CPIH', 'uk_unemployment_rate', 'uk_gdp_growth',\n",
    "                             'uk_interest_rate', 'uk_consumer_confidence', 'gbp_usd_fx', 'ftse_250', 'gilts_short ', \n",
    "                             'gilts_medium ', 'gilts_long ', 'uk_credit_growth_no_cc', 'uk_credit_growth_only_cc',\n",
    "                             'avg_price_all_property_types']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_gpt], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f8e0a-ba2c-4cae-b33e-6db6f7e11fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for GPT sentiment score with all economic indicators\n",
    "correlation_matrix_gpt = boe_speeches_indicators[columns_sentiment_gpt].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33fce3-fce5-4f7c-ad62-8811f4b79478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix for GPT sentiment score with all economic indicators\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_gpt, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of all Economic Indicators with GPT Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83392314-f946-4180-94b3-145f9393f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for GPT sentiment score and price/ inflation indicators\n",
    "columns_sentiment_gpt_price = ['gpt_sentiment_std', 'uk_inflation_rate_CPIH', 'uk_interest_rate',\n",
    "                             'avg_price_all_property_types']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_gpt_price], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bdfa2-056b-4e73-8d54-825b75d35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for GPT sentiment score with price/ inflation indicators\n",
    "correlation_matrix_gpt_price = boe_speeches_indicators[columns_sentiment_gpt_price].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_gpt_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c3fd3-4a3a-4543-8851-60077f29d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix with price/ inflation indicators\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_gpt_price, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Price/Inflation Indicators with GPT Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c18e41-8983-42bf-8bbf-bea4a221f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for GPT sentiment score and macroeconnomic indicators\n",
    "columns_sentiment_gpt_macro = ['gpt_sentiment_std', 'uk_gdp_growth', 'uk_unemployment_rate', \n",
    "                            'uk_credit_growth_no_cc', 'uk_consumer_confidence']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_gpt_macro], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63690c51-bb29-4ec7-9944-dde6d20dde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for GPT sentiment score with macroeconomic indicators\n",
    "correlation_matrix_gpt_macro = boe_speeches_indicators[columns_sentiment_gpt_macro].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_gpt_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210b8e0-6577-4d9d-b709-737b1be0a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix with macroeconomic indicators\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_gpt_macro, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Macroeconomic Indicators with GPT Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201993d-0c55-4120-8a34-cc64a770c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for GPT sentiment score and financial indicators\n",
    "columns_sentiment_gpt_finance = ['gpt_sentiment_std', 'gbp_usd_fx', 'ftse_250', 'gilts_short ', \n",
    "                             'gilts_medium ', 'gilts_long ']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_gpt_finance], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a64d2c-e570-4e6c-802f-f82481b5434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for GPT sentiment score with financial indicators\n",
    "correlation_matrix_gpt_finance = boe_speeches_indicators[columns_sentiment_gpt_finance].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_gpt_finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c50a4-e117-431a-bac4-8a59f0b82cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix with finance indicators\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_gpt_finance, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Financial Indicators with GPT Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24f178-94e2-4149-9861-c4e1a9120d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for GPT sentiment score and most impactful indicators\n",
    "columns_sentiment_gpt_top = ['gpt_sentiment_std', 'uk_inflation_rate_CPIH', 'uk_unemployment_rate', \n",
    "                            'uk_credit_growth_no_cc', 'uk_consumer_confidence', 'ftse_250']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_gpt_top], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eee2e-f767-4559-83ac-88afcecdd162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for GPT sentiment score with and most impactful indicators\n",
    "correlation_matrix_gpt_top = boe_speeches_indicators[columns_sentiment_gpt_top].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_gpt_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eca04-8378-42c0-867b-2ac9cc3bedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix with most impactful indicators\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_gpt_top, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Most Impactful Indicators with GPT Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54eb3cc-85fd-4465-a913-9d2e1936b1b1",
   "metadata": {},
   "source": [
    "**4.3.c. FinBert Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe15d4b-227d-43d5-9a78-be58e94d59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for sentiment score, unemployment, inflation and exchange rates.\n",
    "columns_sentiment_finbert = ['sentiment_score_yiyang_std', 'uk_inflation_rate_CPIH', 'uk_unemployment_rate', 'uk_gdp_growth',\n",
    "                             'uk_interest_rate', 'uk_consumer_confidence', 'gbp_usd_fx', 'ftse_250', 'gilts_short ', \n",
    "                             'gilts_medium ', 'gilts_long ', 'uk_credit_growth_no_cc', 'uk_credit_growth_only_cc',\n",
    "                             'avg_price_all_property_types']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_finbert], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe2a42-5f4e-4424-9a5c-3faaf14cc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix for the sentiment score with the indicators only.\n",
    "correlation_matrix_finbert = boe_speeches_indicators[columns_sentiment_finbert].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_finbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c47723-8ea8-4e01-b17a-7774050c0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_finbert, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Economic Indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d5cce-b77d-4fbb-b415-96617aaf333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for sentiment score, unemployment, inflation and exchange rates.\n",
    "columns_sentiment_finbert_inflation = ['sentiment_score_yiyang_std', 'uk_inflation_rate_CPIH', 'uk_interest_rate',\n",
    "                             'avg_price_all_property_types']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_finbert_inflation], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba45e66-daca-4a77-8c92-ef4e9f8113a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix for the sentiment score with the indicators only.\n",
    "correlation_matrix_finbert_inflation = boe_speeches_indicators[columns_sentiment_finbert_inflation].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_finbert_inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8e3fb-f7a8-4334-bc50-b74f527c4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_finbert_inflation, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Economic Indicators on Price & Inflation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c1a7d-903d-44db-b397-0ad9ea73e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for sentiment score, unemployment, inflation and exchange rates.\n",
    "columns_sentiment_finbert_macro = ['sentiment_score_yiyang_std', 'uk_gdp_growth', 'uk_unemployment_rate', \n",
    "                            'uk_credit_growth_no_cc', 'uk_consumer_confidence']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_finbert_macro], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b330037-634f-4710-92ac-5916f0828aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix for the sentiment score with the indicators only.\n",
    "correlation_matrix_finbert_macro = boe_speeches_indicators[columns_sentiment_finbert_macro].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_finbert_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac917c4-6a1e-4a9e-bc32-ce5ab6ca524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(8, 6)) \n",
    "sns.heatmap(correlation_matrix_finbert_macro, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "\n",
    "# Customize title and labels\n",
    "plt.title('Correlation Heatmap of Macroeconomic Indicators ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd874b09-563f-48d2-af2d-01a07e477f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for sentiment score, unemployment, inflation and exchange rates.\n",
    "columns_sentiment_finbert_finance = ['sentiment_score_yiyang_std', 'gbp_usd_fx', 'ftse_250', 'gilts_short ', \n",
    "                             'gilts_medium ', 'gilts_long ']\n",
    "\n",
    "# Create a pairplot using only the specified columns\n",
    "sns.pairplot(boe_speeches_indicators[columns_sentiment_finbert_finance], plot_kws={'alpha': 0.5, 'color': '#0e1b2c'})\n",
    "\n",
    "# Save figure.\n",
    "# plt.savefig('Fig_Pairplot_Indicators.png', dpi=500)\n",
    "\n",
    "# Display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e31bcf-0a5c-4063-be68-fe8c5e93c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix for the sentiment score with the indicators only.\n",
    "correlation_matrix_finbert_finance = boe_speeches_indicators[columns_sentiment_finbert_finance].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix_finbert_finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1db184-97e4-4b4d-93a6-3f006d324c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482af1e9-82e2-4e24-b65e-cf46a6177691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f3c4bb0-eda3-462d-babd-2831ee51115b",
   "metadata": {},
   "source": [
    "## 5. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590c355-c24f-4096-bae6-970e0cd62dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames to merge\n",
    "dataframes_to_merge = [uk_economic_indicators]\n",
    "\n",
    "# Use reduce to merge all DataFrames in the list\n",
    "boe_speeches_indicators = reduce(lambda left, right: left.merge(right, on='year_month', how='left'), dataframes_to_merge, boe_speeches_new)\n",
    "\n",
    "# View the merged DataFrame\n",
    "boe_speeches_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829aeed-c623-45e8-94f5-83302dbd599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_indicators.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297133e1-b629-4b33-95bd-632bc6d799f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "boe_speeches_indicators['date_format'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d19a3f-0ef7-49a9-af6c-5ad14b350af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the DataFranme for further manipulation\n",
    "boe_rf = boe_speeches_indicators.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a257bac-7e3f-48ac-af3b-66fa3b127141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert 'date' to datetime if it's not already\n",
    "boe_rf['date_time'] = pd.to_datetime(boe_rf['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2595cd-f07f-4bc2-9204-1e5f51a85ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' as index for resampling\n",
    "boe_rf.set_index('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf5cc0-632d-441f-b3b6-f68f1301c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02f62a-97f6-44d8-a2f3-ee2406038c0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.1. Monthly Analysis with BoE Wordlist Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cee6f-134e-44b8-af7a-be13777ebf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment scores and consumer confidence monthly\n",
    "boe_rf_monthly = boe_rf.resample('M').agg({\n",
    "            'sentiment_score_lexicon_std': 'mean',\n",
    "            'gpt_sentiment_std': 'mean',\n",
    "            'uk_consumer_confidence': 'mean',\n",
    "            'uk_inflation_rate_CPIH': 'mean',\n",
    "            'uk_unemployment_rate': 'mean',\n",
    "            'uk_gdp_growth': 'mean',\n",
    "            'uk_interest_rate': 'mean',\n",
    "            'uk_consumer_confidence': 'mean', \n",
    "            'gbp_usd_fx': 'mean',\n",
    "            'ftse_250': 'mean',\n",
    "            'gilts_short ': 'mean',\n",
    "            'gilts_medium ': 'mean', \n",
    "            'gilts_long ': 'mean', \n",
    "            'uk_credit_growth_no_cc': 'mean',\n",
    "            'uk_credit_growth_only_cc': 'mean',\n",
    "            'avg_price_all_property_types': 'mean'\n",
    "})\n",
    "\n",
    "# Reset index to turn 'date' back into a column\n",
    "boe_rf_monthly.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18917868-9d82-4425-a4d9-717f8f8ad330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819f503-5bc5-4910-ba5c-9325ddde617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date-related features\n",
    "boe_rf_monthly['month'] = boe_rf_monthly['date_time'].dt.month\n",
    "boe_rf_monthly['quarter'] = boe_rf_monthly['date_time'].dt.quarter\n",
    "boe_rf_monthly['year'] = boe_rf_monthly['date_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f71a6-8b96-40be-9449-0f4043009a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e0e00-c3ed-4f3e-8a7b-f049b1c190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged feature for sentiment score with 1 month lag\n",
    "boe_rf_monthly['sentiment_score_lexicon_std_lag_1m'] = boe_rf_monthly['sentiment_score_lexicon_std'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b26d66-3ef0-4dfe-975f-eda5bd227478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged feature for sentiment score with 1 month lag\n",
    "boe_rf_monthly['sentiment_score_lexicon_std_lag_3m'] = boe_rf_monthly['sentiment_score_lexicon_std'].shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ca749-f3ff-44a2-9cdc-f290c609e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f8da2-d74a-4f66-8f82-b105f2da2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first row(s) with NaN values due to lagging\n",
    "boe_rf_monthly.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74c1cb-71fa-42c7-a1a9-b39bb4450811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X)\n",
    "feature_cols = ['sentiment_score_lexicon_std', 'sentiment_score_lexicon_std_lag_1m', 'sentiment_score_lexicon_std_lag_3m', 'month', 'quarter', 'year']\n",
    "X = boe_rf_monthly[feature_cols]\n",
    "\n",
    "# For each indicator (target)\n",
    "for target in ['uk_consumer_confidence',\n",
    "            'uk_inflation_rate_CPIH',\n",
    "            'uk_unemployment_rate',\n",
    "            'uk_gdp_growth',\n",
    "            'uk_interest_rate',\n",
    "            'uk_consumer_confidence', \n",
    "            'gbp_usd_fx',\n",
    "            'ftse_250',\n",
    "            'gilts_short ',\n",
    "            'gilts_medium ', \n",
    "            'gilts_long ', \n",
    "            'uk_credit_growth_no_cc',\n",
    "            'uk_credit_growth_only_cc',\n",
    "            'avg_price_all_property_types']:\n",
    "            y = boe_rf_monthly[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f58453-96b6-45fd-a5fe-156ad284475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# List of targets\n",
    "targets = [\n",
    "    'uk_consumer_confidence',\n",
    "    'uk_inflation_rate_CPIH',\n",
    "    'uk_unemployment_rate',\n",
    "    'uk_gdp_growth',\n",
    "    'uk_interest_rate',\n",
    "    'uk_consumer_confidence', \n",
    "    'gbp_usd_fx',\n",
    "    'ftse_250',\n",
    "    'gilts_short ',\n",
    "    'gilts_medium ', \n",
    "    'gilts_long ', \n",
    "    'uk_credit_growth_no_cc',\n",
    "    'uk_credit_growth_only_cc',\n",
    "    'avg_price_all_property_types'\n",
    "]\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'sentiment_score_lexicon_std', \n",
    "    'sentiment_score_lexicon_std_lag_1m',\n",
    "    'sentiment_score_lexicon_std_lag_3m',\n",
    "    'month', 'quarter', 'year'\n",
    "]\n",
    "\n",
    "# Loop through each target\n",
    "for target in targets:\n",
    "    print(f\"\\nTraining model for: {target}\")\n",
    "    y = boe_rf_monthly[target]\n",
    "    X = boe_rf_monthly[feature_cols]\n",
    "\n",
    "    # Time-series aware split without shuffling\n",
    "    split_idx = int(len(boe_rf_monthly) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6be1e1-79c1-45d7-a5cd-c0ffecd9085e",
   "metadata": {},
   "source": [
    "### 5.2. Quarterly Analysis woth BoE Wordlist Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce2736-19a0-4f60-bfa2-417ec0dcfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment scores and consumer confidence monthly\n",
    "boe_rf_quarterly = boe_rf.resample('Q').agg({\n",
    "            'sentiment_score_lexicon_std': 'mean',\n",
    "            'gpt_sentiment_std': 'mean',\n",
    "            'uk_consumer_confidence': 'mean',\n",
    "            'uk_inflation_rate_CPIH': 'mean',\n",
    "            'uk_unemployment_rate': 'mean',\n",
    "            'uk_gdp_growth': 'mean',\n",
    "            'uk_interest_rate': 'mean',\n",
    "            'uk_consumer_confidence': 'mean', \n",
    "            'gbp_usd_fx': 'mean',\n",
    "            'ftse_250': 'mean',\n",
    "            'gilts_short ': 'mean',\n",
    "            'gilts_medium ': 'mean', \n",
    "            'gilts_long ': 'mean', \n",
    "            'uk_credit_growth_no_cc': 'mean',\n",
    "            'uk_credit_growth_only_cc': 'mean',\n",
    "            'avg_price_all_property_types': 'mean'\n",
    "})\n",
    "\n",
    "# Reset index to turn 'date' back into a column\n",
    "boe_rf_quarterly.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7a374-a48d-44bb-adec-e456ca4014ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date-related features\n",
    "boe_rf_quarterly['month'] = boe_rf_quarterly['date_time'].dt.month\n",
    "boe_rf_quarterly['quarter'] = boe_rf_quarterly['date_time'].dt.quarter\n",
    "boe_rf_quarterly['year'] = boe_rf_quarterly['date_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01012e-6bf1-40c7-98d3-d77610aafe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features (3 months lag is now 1 quarter lag)\n",
    "boe_rf_quarterly['sentiment_score_lexicon_std_lag_1q'] = boe_rf_quarterly['sentiment_score_lexicon_std'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7620b38-89f6-4734-8bae-e3923365a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_quarterly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649543a3-03ed-4684-9eaa-ab3e6418915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs due to lag\n",
    "boe_rf_quarterly.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b0d2b-722a-49fb-8b2c-3bdecc602ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X)\n",
    "feature_cols = ['sentiment_score_lexicon_std', 'sentiment_score_lexicon_std_lag_1q', 'month', 'quarter', 'year']\n",
    "X = boe_rf_quarterly[feature_cols]\n",
    "\n",
    "# For each indicator (target)\n",
    "for target in ['uk_consumer_confidence',\n",
    "            'uk_inflation_rate_CPIH',\n",
    "            'uk_unemployment_rate',\n",
    "            'uk_gdp_growth',\n",
    "            'uk_interest_rate',\n",
    "            'uk_consumer_confidence', \n",
    "            'gbp_usd_fx',\n",
    "            'ftse_250',\n",
    "            'gilts_short ',\n",
    "            'gilts_medium ', \n",
    "            'gilts_long ', \n",
    "            'uk_credit_growth_no_cc',\n",
    "            'uk_credit_growth_only_cc',\n",
    "            'avg_price_all_property_types']:\n",
    "            y = boe_rf_quarterly[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85891cf-d3ca-489f-9f82-5a8d9c33156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of targets\n",
    "targets = [\n",
    "    'uk_consumer_confidence',\n",
    "    'uk_inflation_rate_CPIH',\n",
    "    'uk_unemployment_rate',\n",
    "    'uk_gdp_growth',\n",
    "    'uk_interest_rate',\n",
    "    'uk_consumer_confidence', \n",
    "    'gbp_usd_fx',\n",
    "    'ftse_250',\n",
    "    'gilts_short ',\n",
    "    'gilts_medium ', \n",
    "    'gilts_long ', \n",
    "    'uk_credit_growth_no_cc',\n",
    "    'uk_credit_growth_only_cc',\n",
    "    'avg_price_all_property_types'\n",
    "]\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'sentiment_score_lexicon_std', \n",
    "    'sentiment_score_lexicon_std_lag_1q',\n",
    "    'month', 'quarter', 'year'\n",
    "]\n",
    "\n",
    "# Loop through each target\n",
    "for target in targets:\n",
    "    print(f\"\\nTraining model for: {target}\")\n",
    "    y = boe_rf_quarterly[target]\n",
    "    X = boe_rf_quarterly[feature_cols]\n",
    "\n",
    "    # Time-series aware split without shuffling\n",
    "    split_idx = int(len(boe_rf_quarterly) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80cd4e-1d28-4eb5-a779-c0a95130ef28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae055d2-0107-4282-84f5-529d4c258c1f",
   "metadata": {},
   "source": [
    "### 5.3. Monthly Analysis with GPT Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab933d9-7ea0-499d-8318-d768b07a7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment scores and consumer confidence monthly\n",
    "boe_rf_monthly_gpt = boe_rf.resample('M').agg({\n",
    "            'gpt_sentiment_std': 'mean',\n",
    "            'gpt_sentiment_std': 'mean',\n",
    "            'uk_consumer_confidence': 'mean',\n",
    "            'uk_inflation_rate_CPIH': 'mean',\n",
    "            'uk_unemployment_rate': 'mean',\n",
    "            'uk_gdp_growth': 'mean',\n",
    "            'uk_interest_rate': 'mean',\n",
    "            'uk_consumer_confidence': 'mean', \n",
    "            'gbp_usd_fx': 'mean',\n",
    "            'ftse_250': 'mean',\n",
    "            'gilts_short ': 'mean',\n",
    "            'gilts_medium ': 'mean', \n",
    "            'gilts_long ': 'mean', \n",
    "            'uk_credit_growth_no_cc': 'mean',\n",
    "            'uk_credit_growth_only_cc': 'mean',\n",
    "            'avg_price_all_property_types': 'mean'\n",
    "})\n",
    "\n",
    "# Reset index to turn 'date' back into a column\n",
    "boe_rf_monthly_gpt.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeae655-1177-4950-aa86-86b1acb119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_monthly_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8036d-065e-44e6-a0ee-c61bd42007a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date-related features\n",
    "boe_rf_monthly_gpt['month'] = boe_rf_monthly_gpt['date_time'].dt.month\n",
    "boe_rf_monthly_gpt['quarter'] = boe_rf_monthly_gpt['date_time'].dt.quarter\n",
    "boe_rf_monthly_gpt['year'] = boe_rf_monthly_gpt['date_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337d726-b094-4362-a5d4-fb8d882955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_monthly_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab886b8-c7d4-4b49-b2df-026b52895152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged feature for sentiment score with 1 month lag\n",
    "boe_rf_monthly_gpt['gpt_sentiment_std_lag_1m'] = boe_rf_monthly_gpt['gpt_sentiment_std'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a96563-9d18-440a-8ae2-d9682285d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged feature for sentiment score with 1 month lag\n",
    "boe_rf_monthly_gpt['gpt_sentiment_std_lag_3m'] = boe_rf_monthly_gpt['gpt_sentiment_std'].shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db40bc-803e-4c1c-a3e1-f229ec6004e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_monthly_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd1bb1-c7c3-4bdd-93d5-5a4958d2d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first row(s) with NaN values due to lagging\n",
    "boe_rf_monthly_gpt.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e640f7-cde2-451e-a7a3-dfbb02ac0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X)\n",
    "feature_cols = ['gpt_sentiment_std', 'gpt_sentiment_std_lag_1m', 'gpt_sentiment_std_lag_3m', 'month', 'quarter', 'year']\n",
    "X = boe_rf_monthly_gpt[feature_cols]\n",
    "\n",
    "# For each indicator (target)\n",
    "for target in ['uk_consumer_confidence',\n",
    "            'uk_inflation_rate_CPIH',\n",
    "            'uk_unemployment_rate',\n",
    "            'uk_gdp_growth',\n",
    "            'uk_interest_rate',\n",
    "            'uk_consumer_confidence', \n",
    "            'gbp_usd_fx',\n",
    "            'ftse_250',\n",
    "            'gilts_short ',\n",
    "            'gilts_medium ', \n",
    "            'gilts_long ', \n",
    "            'uk_credit_growth_no_cc',\n",
    "            'uk_credit_growth_only_cc',\n",
    "            'avg_price_all_property_types']:\n",
    "            y = boe_rf_monthly_gpt[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61120371-9bd2-4bda-b153-05d988f11d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of targets\n",
    "targets = [\n",
    "    'uk_consumer_confidence',\n",
    "    'uk_inflation_rate_CPIH',\n",
    "    'uk_unemployment_rate',\n",
    "    'uk_gdp_growth',\n",
    "    'uk_interest_rate',\n",
    "    'uk_consumer_confidence', \n",
    "    'gbp_usd_fx',\n",
    "    'ftse_250',\n",
    "    'gilts_short ',\n",
    "    'gilts_medium ', \n",
    "    'gilts_long ', \n",
    "    'uk_credit_growth_no_cc',\n",
    "    'uk_credit_growth_only_cc',\n",
    "    'avg_price_all_property_types'\n",
    "]\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'gpt_sentiment_std', \n",
    "    'gpt_sentiment_std_lag_1m',\n",
    "    'gpt_sentiment_std_lag_3m',\n",
    "    'month', 'quarter', 'year'\n",
    "]\n",
    "\n",
    "# Loop through each target\n",
    "for target in targets:\n",
    "    print(f\"\\nTraining model for: {target}\")\n",
    "    y = boe_rf_monthly_gpt[target]\n",
    "    X = boe_rf_monthly_gpt[feature_cols]\n",
    "\n",
    "    # Time-series aware split without shuffling\n",
    "    split_idx = int(len(boe_rf_monthly_gpt) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883e6ec-db89-4786-8017-aff228e404e3",
   "metadata": {},
   "source": [
    "### 5.2. Quarterly Analysis woth BoE Wordlist Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0959c-f749-4438-925c-738e3c3feed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment scores and consumer confidence monthly\n",
    "boe_rf_quarterly_gpt = boe_rf.resample('Q').agg({\n",
    "            'gpt_sentiment_std': 'mean',\n",
    "            'gpt_sentiment_std': 'mean',\n",
    "            'uk_consumer_confidence': 'mean',\n",
    "            'uk_inflation_rate_CPIH': 'mean',\n",
    "            'uk_unemployment_rate': 'mean',\n",
    "            'uk_gdp_growth': 'mean',\n",
    "            'uk_interest_rate': 'mean',\n",
    "            'uk_consumer_confidence': 'mean', \n",
    "            'gbp_usd_fx': 'mean',\n",
    "            'ftse_250': 'mean',\n",
    "            'gilts_short ': 'mean',\n",
    "            'gilts_medium ': 'mean', \n",
    "            'gilts_long ': 'mean', \n",
    "            'uk_credit_growth_no_cc': 'mean',\n",
    "            'uk_credit_growth_only_cc': 'mean',\n",
    "            'avg_price_all_property_types': 'mean'\n",
    "})\n",
    "\n",
    "# Reset index to turn 'date' back into a column\n",
    "boe_rf_quarterly_gpt.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3451ecb-4421-4ac7-879c-496d2a53072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date-related features\n",
    "boe_rf_quarterly_gpt['month'] = boe_rf_quarterly_gpt['date_time'].dt.month\n",
    "boe_rf_quarterly_gpt['quarter'] = boe_rf_quarterly_gpt['date_time'].dt.quarter\n",
    "boe_rf_quarterly_gpt['year'] = boe_rf_quarterly_gpt['date_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e0cae-780c-4f83-9ca6-f95149f1f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features (3 months lag is now 1 quarter lag)\n",
    "boe_rf_quarterly_gpt['gpt_sentiment_std_lag_1q'] = boe_rf_quarterly_gpt['gpt_sentiment_std'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f6984-1eae-4d9d-bbd0-e0fbb7b1e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "boe_rf_quarterly_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d798384-b5e8-4b6f-8176-41218c7c3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs due to lag\n",
    "boe_rf_quarterly_gpt.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81381932-d4c3-476c-95ea-01464a8cdb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X)\n",
    "feature_cols = ['gpt_sentiment_std', 'gpt_sentiment_std_lag_1q', 'month', 'quarter', 'year']\n",
    "X = boe_rf_quarterly_gpt[feature_cols]\n",
    "\n",
    "# For each indicator (target)\n",
    "for target in ['uk_consumer_confidence',\n",
    "            'uk_inflation_rate_CPIH',\n",
    "            'uk_unemployment_rate',\n",
    "            'uk_gdp_growth',\n",
    "            'uk_interest_rate',\n",
    "            'uk_consumer_confidence', \n",
    "            'gbp_usd_fx',\n",
    "            'ftse_250',\n",
    "            'gilts_short ',\n",
    "            'gilts_medium ', \n",
    "            'gilts_long ', \n",
    "            'uk_credit_growth_no_cc',\n",
    "            'uk_credit_growth_only_cc',\n",
    "            'avg_price_all_property_types']:\n",
    "            y = boe_rf_quarterly_gpt[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbd6a4-4c42-4936-8bee-4ca5398eaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of targets\n",
    "targets = [\n",
    "    'uk_consumer_confidence',\n",
    "    'uk_inflation_rate_CPIH',\n",
    "    'uk_unemployment_rate',\n",
    "    'uk_gdp_growth',\n",
    "    'uk_interest_rate',\n",
    "    'uk_consumer_confidence', \n",
    "    'gbp_usd_fx',\n",
    "    'ftse_250',\n",
    "    'gilts_short ',\n",
    "    'gilts_medium ', \n",
    "    'gilts_long ', \n",
    "    'uk_credit_growth_no_cc',\n",
    "    'uk_credit_growth_only_cc',\n",
    "    'avg_price_all_property_types'\n",
    "]\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'gpt_sentiment_std', \n",
    "    'gpt_sentiment_std_lag_1q',\n",
    "    'month', 'quarter', 'year'\n",
    "]\n",
    "\n",
    "# Loop through each target\n",
    "for target in targets:\n",
    "    print(f\"\\nTraining model for: {target}\")\n",
    "    y = boe_rf_quarterly_gpt[target]\n",
    "    X = boe_rf_quarterly_gpt[feature_cols]\n",
    "\n",
    "    # Time-series aware split without shuffling\n",
    "    split_idx = int(len(boe_rf_quarterly_) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf480ad-9400-4777-b223-4bc894eaa6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44220af9-ff22-40bb-a9cc-78fec54d6127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
