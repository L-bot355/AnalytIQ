{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f3516e-c928-4265-a9a5-2d9b48313c49",
   "metadata": {},
   "source": [
    "# Lexicon score code based on BoE Wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2a453-aab6-4f67-b551-bf4da5f2c4e7",
   "metadata": {},
   "source": [
    "**Import the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adbb8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \n",
       "0  fraser       0  They would no doubt argue that to have two obj...  \n",
       "1  fraser       0  Today I wish to talk about real interest rates...  \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...  \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...  \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Weak</th>\n",
       "      <th>Constraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDONING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABANDONMENTS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Negative  Positive  Uncertainty  Litigious  Strong  Weak  \\\n",
       "0       ABANDON         1         0            0          0       0     0   \n",
       "1     ABANDONED         1         0            0          0       0     0   \n",
       "2    ABANDONING         1         0            0          0       0     0   \n",
       "3   ABANDONMENT         1         0            0          0       0     0   \n",
       "4  ABANDONMENTS         1         0            0          0       0     0   \n",
       "\n",
       "   Constraining  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def load_data(speeches_path: str, sentiment_path: str):\n",
    "    \"\"\"\n",
    "    Load speeches and sentiment wordlist datasets.\n",
    "\n",
    "    Parameters:\n",
    "    speeches_path (str): Path to the speeches CSV file.\n",
    "    sentiment_path (str): Path to the sentiment-labelled wordlist Excel file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two pandas DataFrames (speeches_df, sentiment_df).\n",
    "    \"\"\"\n",
    "    speeches_df = pd.read_csv(speeches_path)\n",
    "    sentiment_df = pd.read_excel(sentiment_path)\n",
    "    \n",
    "    display(speeches_df.head())\n",
    "    display(sentiment_df.head())\n",
    "    \n",
    "    return speeches_df, sentiment_df\n",
    "\n",
    "# Paths to your files\n",
    "speeches_path = r\"/Users/kaferrante/Documents/Python/_Course4_Project/all_speeches.csv\"\n",
    "sentiment_path = r\"/Users/kaferrante/Documents/Python/_Course4_Project/LSE_DA_BoE_Employer_project_Sentiment-labelled_wordlist-2.xlsx\"\n",
    "\n",
    "# Load data\n",
    "speeches_df, sentiment_df = load_data(speeches_path, sentiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72c5c1f-3104-4d7e-ab7c-58ed7ac1793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional dataframe for the different sentiment score calcualtions\n",
    "speeches_df_2 = speeches_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ed9ec-0621-4699-9bbe-e01d737cb39f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058fb81-e6b7-49c7-9836-ad15b0833ec7",
   "metadata": {},
   "source": [
    "## Option 1: Focus on negative & positive wordcounts only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb717a-b2a5-49ed-8e9e-cd25022ac3d0",
   "metadata": {},
   "source": [
    "**Text cleaned** by \n",
    "- Removing unwanted characters\n",
    "- Converting text to lower case\n",
    "\n",
    "**Sentiment score** is calculated as follows:\n",
    "- positive and negative words in each speech are counted\n",
    "- sentiment score = positive word count - negative word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63517980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r1/lqqrzjf91n342xkgb_sbt6rh0000gn/T/ipykernel_24414/640994244.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'YES' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, 'is_gov'] = 'YES'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-10-03</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-03-14</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-05-29</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-08-17</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  author is_gov  sentiment_score\n",
       "0 1990-11-28  fraser      0              -38\n",
       "1 1991-10-03  fraser      0              -29\n",
       "2 1992-03-14  fraser      0               22\n",
       "3 1992-05-29  fraser      0              -11\n",
       "4 1992-08-17  fraser      0              -12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "# 2. Load your datasets\n",
    "# speeches_df = pd.read_csv('C:/Users/Srila/OneDrive/Documents/all_speeches.csv')\n",
    "# sentiment_df = pd.read_excel('C:/Users/Srila/OneDrive/Documents/LSE_DA_BoE_Employer_project_Sentiment-labelled_wordlist-2 (1).xlsx')\n",
    "\n",
    "# 3. Define the cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans input text by removing non-alphabetical characters and converting to lowercase.\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw text.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned text.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', str(text))  # Remove non-letters\n",
    "    text = text.lower()  # Lowercase\n",
    "    return text\n",
    "\n",
    "# 4. Define sentiment word preparation\n",
    "def prepare_sentiment_wordlists(sentiment_df):\n",
    "    \"\"\"\n",
    "    Prepare sets of positive and negative words from the sentiment dataframe.\n",
    "\n",
    "    Args:\n",
    "        sentiment_df (pd.DataFrame): Sentiment-labeled words.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Positive words set, negative words set.\n",
    "    \"\"\"\n",
    "    positive_words = set(sentiment_df[sentiment_df['Positive'] == 1]['Word'].str.lower())\n",
    "    negative_words = set(sentiment_df[sentiment_df['Negative'] == 1]['Word'].str.lower())\n",
    "    return positive_words, negative_words\n",
    "\n",
    "# 5. Define sentiment score calculation\n",
    "def calculate_sentiment_score(text, positive_words, negative_words):\n",
    "    \"\"\"\n",
    "    Calculates a sentiment score based on positive and negative words in the text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Cleaned text.\n",
    "        positive_words (set): Set of positive words.\n",
    "        negative_words (set): Set of negative words.\n",
    "\n",
    "    Returns:\n",
    "        int: Sentiment score (positive count - negative count).\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    pos_count = sum(word in positive_words for word in words)\n",
    "    neg_count = sum(word in negative_words for word in words)\n",
    "    return pos_count - neg_count\n",
    "\n",
    "# 6. Correct 'is_gov' column for Edward George\n",
    "def correct_is_gov_column(df):\n",
    "    \"\"\"\n",
    "    Corrects the is_gov flag for Edward George between 1993 and 2003.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Speech dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated dataframe.\n",
    "    \"\"\"\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Ensure dates are datetime\n",
    "    mask = (df['author'].str.lower().str.contains('george')) & (df['date'].dt.year >= 1993) & (df['date'].dt.year <= 2003)\n",
    "    df.loc[mask, 'is_gov'] = 'YES'\n",
    "    return df\n",
    "\n",
    "# 7. Start Cleaning and Calculating!\n",
    "\n",
    "# Set the correct speech text column\n",
    "speech_text_column = 'text'\n",
    "\n",
    "# Clean the speech text\n",
    "speeches_df['cleaned_text'] = speeches_df[speech_text_column].apply(clean_text)\n",
    "\n",
    "# Correct Edward George's governor status\n",
    "speeches_df = correct_is_gov_column(speeches_df)\n",
    "\n",
    "# Prepare sentiment wordlists\n",
    "positive_words, negative_words = prepare_sentiment_wordlists(sentiment_df)\n",
    "\n",
    "# Calculate sentiment scores\n",
    "speeches_df['sentiment_score'] = speeches_df['cleaned_text'].apply(\n",
    "    lambda text: calculate_sentiment_score(text, positive_words, negative_words)\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "display(speeches_df[['date', 'author', 'is_gov', 'sentiment_score']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15714ad-ec87-45e4-88f2-05296238128f",
   "metadata": {},
   "source": [
    "**Same calculation - only difference is that results also display the negative and positive scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb45ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-10-03</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-03-14</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-05-29</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-08-17</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>75</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  author is_gov  pos_count  neg_count  sentiment_score\n",
       "0 1990-11-28  fraser      0         55         93              -38\n",
       "1 1991-10-03  fraser      0         29         58              -29\n",
       "2 1992-03-14  fraser      0         67         45               22\n",
       "3 1992-05-29  fraser      0         52         63              -11\n",
       "4 1992-08-17  fraser      0         63         75              -12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define sentiment score calculation (modified to get positive & negative counts separately)\n",
    "def calculate_sentiment_scores(text, positive_words, negative_words):\n",
    "    \"\"\"\n",
    "    Calculates positive and negative word counts in the text.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    pos_count = sum(word in positive_words for word in words)\n",
    "    neg_count = sum(word in negative_words for word in words)\n",
    "    return pos_count, neg_count\n",
    "\n",
    "# Set the correct speech text column\n",
    "speech_text_column = 'text'\n",
    "\n",
    "# Clean the speech text\n",
    "speeches_df['cleaned_text'] = speeches_df[speech_text_column].apply(clean_text)\n",
    "\n",
    "# Correct Edward George's governor status\n",
    "speeches_df = correct_is_gov_column(speeches_df)\n",
    "\n",
    "# Prepare sentiment wordlists\n",
    "positive_words, negative_words = prepare_sentiment_wordlists(sentiment_df)\n",
    "\n",
    "# Calculate positive and negative sentiment scores and store in new columns\n",
    "sentiment_counts = speeches_df['cleaned_text'].apply(\n",
    "    lambda text: pd.Series(calculate_sentiment_scores(text, positive_words, negative_words))\n",
    ")\n",
    "\n",
    "# Assign positive and negative counts to separate columns\n",
    "speeches_df['pos_count'] = sentiment_counts[0]\n",
    "speeches_df['neg_count'] = sentiment_counts[1]\n",
    "\n",
    "# Optional: define overall sentiment score as difference\n",
    "speeches_df['sentiment_score'] = speeches_df['pos_count'] - speeches_df['neg_count']\n",
    "\n",
    "# Display the results, including positive and negative scores\n",
    "display(speeches_df[['date', 'author', 'is_gov', 'pos_count', 'neg_count', 'sentiment_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990a172-1b0b-41a7-b109-4218128bfc68",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512347d0-8c98-426f-93e7-b8dea0b06a11",
   "metadata": {},
   "source": [
    "## Option 2: Focus on negative & positive wordcounts & divide by the wordcount of the speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c986e4-9b77-47da-a847-e5dbeb952e92",
   "metadata": {},
   "source": [
    "**Text cleaned** by\n",
    "- Removing unwanted characters\n",
    "- Removing any special characters and punctuation\n",
    "- Converting text to lower case\n",
    "- Removing stopwords\n",
    "- tokenisation: Split the cleaned text into individual words, so that text can be analysed at word level.\n",
    "- Lemmatisation: Reduce words to its base or dictionary form (the lemma).\n",
    "\n",
    "**Sentiment score** is calculated as follows:\n",
    "- positive and negative words in each speech are counted\n",
    "- sentiment score = psotive word count - negative word count /  wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91fc66-bd31-4675-86f2-410695a730ae",
   "metadata": {},
   "source": [
    "**Text cleaning functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f8b3b7b-e2bd-4196-8d28-72599a7c8cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>r221010a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>Restoring Price Stability in an Uncertain Econ...</td>\n",
       "      <td>brainard</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to join this discussion today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>r221012b_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>Managing the Promise and Risk of Financial Inn...</td>\n",
       "      <td>barr</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you, Chris, and thank you for the invita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>r221012a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>Forward Guidance as a Monetary Policy Tool: Co...</td>\n",
       "      <td>bowman</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks to the Money Marketeers for inviting me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>r221014a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>The U.S. Dollar and Central Bank Digital Curre...</td>\n",
       "      <td>waller</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you, Professor Jackson, and thank you to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>r221020a_FOMC</td>\n",
       "      <td>united states</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>Welcoming Remarks</td>\n",
       "      <td>bowman</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome, and thank you for joining us to discu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7721 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference        country        date  \\\n",
       "0      r901128a_BOA      australia  1990-11-28   \n",
       "1      r911003a_BOA      australia  1991-10-03   \n",
       "2      r920314a_BOA      australia  1992-03-14   \n",
       "3      r920529a_BOA      australia  1992-05-29   \n",
       "4      r920817a_BOA      australia  1992-08-17   \n",
       "...             ...            ...         ...   \n",
       "7716  r221010a_FOMC  united states  2022-10-10   \n",
       "7717  r221012b_FOMC  united states  2022-10-12   \n",
       "7718  r221012a_FOMC  united states  2022-10-12   \n",
       "7719  r221014a_FOMC  united states  2022-10-14   \n",
       "7720  r221020a_FOMC  united states  2022-10-20   \n",
       "\n",
       "                                                  title    author  is_gov  \\\n",
       "0                     A Proper Role for Monetary Policy    fraser       0   \n",
       "1                                                          fraser       0   \n",
       "2                                                          fraser       0   \n",
       "3                                                          fraser       0   \n",
       "4                                                          fraser       0   \n",
       "...                                                 ...       ...     ...   \n",
       "7716  Restoring Price Stability in an Uncertain Econ...  brainard       0   \n",
       "7717  Managing the Promise and Risk of Financial Inn...      barr       0   \n",
       "7718  Forward Guidance as a Monetary Policy Tool: Co...    bowman       0   \n",
       "7719  The U.S. Dollar and Central Bank Digital Curre...    waller       0   \n",
       "7720                                  Welcoming Remarks    bowman       0   \n",
       "\n",
       "                                                   text  \n",
       "0     They would no doubt argue that to have two obj...  \n",
       "1     Today I wish to talk about real interest rates...  \n",
       "2     I welcome this opportunity to talk about prosp...  \n",
       "3     It is a pleasure to have this opportunity to a...  \n",
       "4     As a long-time fan of Don Sanders, I am deligh...  \n",
       "...                                                 ...  \n",
       "7716  It is a pleasure to join this discussion today...  \n",
       "7717  Thank you, Chris, and thank you for the invita...  \n",
       "7718  Thanks to the Money Marketeers for inviting me...  \n",
       "7719  Thank you, Professor Jackson, and thank you to...  \n",
       "7720  Welcome, and thank you for joining us to discu...  \n",
       "\n",
       "[7721 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43edf913-8332-4563-a319-55cd2bcbf43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict                     # Creating dictionaries that return default value for nonexistent keys.\n",
    "from nltk.corpus import wordnet as wn                   # Lexical database for retrieving word relationships & meanings.\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer  # Reducing words to base or root form.\n",
    "import contractions                                     # Expanding/contracting text contractions.\n",
    "from nltk.corpus import stopwords                       # Providing list of common words to exclude from analysis.\n",
    "from nltk import word_tokenize, pos_tag                 # Splitting text into words and tags with part of speech\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer  # Reducing words to base or root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cae3fcc5-dc54-4b3b-af10-288d73115130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = contractions.fix(text)  # Expand contractions i.e I'm not good goes to I am not good\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub('#', '', text)         # Remove hashtags\n",
    "    text = re.sub(r'\\W', ' ', text)      # Remove special characters\n",
    "    text = text.lower()                  # Convert to lowercase\n",
    "    #Below is to create a set of stop words from the NLTK library's predefined list but not is excluded.\n",
    "    stop_words = set(stopwords.words('english')) - {'not'} \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c66b7669-293d-496d-8728-b9ec44b4cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tag map for POS tagging.\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "# Lemmatise the tokens with correct POS tags.\n",
    "lemma_function = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatisation function.\n",
    "def lemmatize_tokens(tokens):\n",
    "    #For each word in the token list, it lemmatizes the word with the correct part-of-speech\n",
    "    lemmatized_tokens = [lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(tokens)]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f57f0-f79c-4192-9498-5fc11f5294f6",
   "metadata": {},
   "source": [
    "**Apply text cleaning functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f54f23a-0877-40ab-9321-c3b4be36a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "speeches_df_2['text_cleaned'] = speeches_df_2['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bd6d0fe-1df9-450c-8580-6dc0c8a1bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "speeches_df_2['text_tokenised'] = speeches_df_2['text_cleaned'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ccb2849-843f-4730-b5cd-7379110fe370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "speeches_df_2['text_lemmatised'] = speeches_df_2['text_tokenised'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f06e09-0b44-40ac-87b0-787e76a64461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of words into a string\n",
    "speeches_df_2['text_lemmatised_str'] = speeches_df_2['text_lemmatised'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ea391a-814d-46a1-80cd-ae3c26ba7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of words in lemmatised text\n",
    "speeches_df_2['word_count'] = speeches_df_2['text_lemmatised_str'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fa77a-a64e-4d84-9c75-d853b5ca2e23",
   "metadata": {},
   "source": [
    "**Observation**: do we need to count the words of the uncleaned text or the lemmatised text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5644902-6515-41b7-affc-310dc43ed604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>text_lemmatised_str</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>would doubt argue two objective like try cake ...</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>today wish talk real interest rate mainly hist...</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>welcome opportunity talk prospect bank austral...</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>long time fan sander delight participate tribu...</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...   \n",
       "1  [today, wish, talk, real, interest, rate, main...   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sander, delight, participate...   \n",
       "\n",
       "                                 text_lemmatised_str  word_count  \n",
       "0  would doubt argue two objective like try cake ...        1919  \n",
       "1  today wish talk real interest rate mainly hist...        1754  \n",
       "2  welcome opportunity talk prospect bank austral...        1867  \n",
       "3  pleasure opportunity address influential gathe...        2123  \n",
       "4  long time fan sander delight participate tribu...        2150  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the Dataframe\n",
    "speeches_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f4fb7-bef5-4f29-8ee0-3c4757f5b069",
   "metadata": {},
   "source": [
    "**Calculating sentiment score with BoE Wordlist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c69bde77-ce1f-4737-bb2f-acc0195551cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the lexicon\n",
    "sentiment_lexicon = sentiment_df.copy()\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "     'Negative',\n",
    "     'Positive',\n",
    "     'Uncertainty',\n",
    "     'Litigious',\n",
    "     'Strong',\n",
    "     'Weak',\n",
    "     'Constraining',\n",
    " ]\n",
    "\n",
    "# Create dictionary of categories, containing words that belong to that category based on your sentiment lexicon.\n",
    "word_sets = {\n",
    "    cat: set(sentiment_lexicon.loc[sentiment_lexicon[cat] == 1, 'Word'].str.lower())\n",
    "    for cat in categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d03201-c2ce-4e9d-97cc-39fd9a92714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to apply the lexicon to the text\n",
    "def lexicon_counts(tokens):\n",
    "    return pd.Series({\n",
    "        cat: sum(t in word_sets[cat] for t in tokens)\n",
    "        for cat in categories\n",
    "    })\n",
    "\n",
    "# Compute counts and add new columns for each category\n",
    "speeches_df_2 = pd.concat(\n",
    "    [speeches_df_2, speeches_df_2['text_lemmatised'].apply(lexicon_counts)], axis=1\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52fefa00-5c98-43bb-bbbb-b385ae23707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sentiment score by subtracting the negative score from the positive score\n",
    "# abd dividing by the total number of words in the lemmatised text\n",
    "speeches_df_2['sentiment_score_lexicon'] = (speeches_df_2['Positive'] - speeches_df_2['Negative'])/ speeches_df_2['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03151a76-b87b-401e-b294-16fd5cd9c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>text_lemmatised_str</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Weak</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>sentiment_score_lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>would doubt argue two objective like try cake ...</td>\n",
       "      <td>1919</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.013549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>today wish talk real interest rate mainly hist...</td>\n",
       "      <td>1754</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.014253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>welcome opportunity talk prospect bank austral...</td>\n",
       "      <td>1867</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0.012855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>2123</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>long time fan sander delight participate tribu...</td>\n",
       "      <td>2150</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...   \n",
       "1  [today, wish, talk, real, interest, rate, main...   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sander, delight, participate...   \n",
       "\n",
       "                                 text_lemmatised_str  word_count  Negative  \\\n",
       "0  would doubt argue two objective like try cake ...        1919        84   \n",
       "1  today wish talk real interest rate mainly hist...        1754        53   \n",
       "2  welcome opportunity talk prospect bank austral...        1867        43   \n",
       "3  pleasure opportunity address influential gathe...        2123        62   \n",
       "4  long time fan sander delight participate tribu...        2150        72   \n",
       "\n",
       "   Positive  Uncertainty  Litigious  Strong  Weak  Constraining  \\\n",
       "0        58           32          5      10    15            13   \n",
       "1        28           35          2       3    16            12   \n",
       "2        67           33          8      11    16            13   \n",
       "3        56           43          6       7    20             8   \n",
       "4        62           42          6      12    27            13   \n",
       "\n",
       "   sentiment_score_lexicon  \n",
       "0                -0.013549  \n",
       "1                -0.014253  \n",
       "2                 0.012855  \n",
       "3                -0.002826  \n",
       "4                -0.004651  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframe\n",
    "speeches_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce340f2-5450-4add-91ba-2ec90fbbc4a9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800ab5f-ff87-4eba-b454-6927b2a930ca",
   "metadata": {},
   "source": [
    "## Option 3: Calculate weighted sentiment score using all categories & divide by the wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686466b-ae7b-4d75-87b5-c8ca2cc459e1",
   "metadata": {},
   "source": [
    "**Text cleaned** as in option 2\n",
    "\n",
    "**Sentiment score** is calculated as follows:\n",
    "- words in all categories in each speech are counted (positive, negative, uncertainty, litigious, strong, weak, constraining)\n",
    "- weights are applied to each category to show how important the influence on the sentiment is\n",
    "- sentiment score = category counts * category weights / wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa34191e-336f-4c86-b030-75c47361520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative       527175\n",
       "Positive       426585\n",
       "Uncertainty    350161\n",
       "Weak           146413\n",
       "Litigious       85505\n",
       "Strong          41252\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of words found in each category in all the speeches\n",
    "category_sums = speeches_df_2[['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Strong', 'Weak']].sum()\n",
    "\n",
    "# Sort the sums in descending order\n",
    "category_sums_sorted = category_sums.sort_values(ascending=False)\n",
    "\n",
    "# View the results\n",
    "category_sums_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29f424cf-9b5e-4bfb-b928-bdf5254d7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank oF England (united kingdom) speeches only  \n",
    "boe_speeches = speeches_df_2[speeches_df_2['country'].str.lower() == 'united kingdom'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ad5f944-46e5-4d72-922a-9849352a0eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative       116182\n",
       "Uncertainty     89901\n",
       "Positive        76124\n",
       "Weak            38845\n",
       "Litigious       19064\n",
       "Strong           7764\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of words found in each category in all the speeches\n",
    "category_sums_boe = boe_speeches[['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Strong', 'Weak']].sum()\n",
    "\n",
    "# Sort the sums in descending order\n",
    "category_sums_boe_sorted = category_sums_boe.sort_values(ascending=False)\n",
    "\n",
    "# View the results\n",
    "category_sums_boe_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5ff48-c389-4f0d-a949-a8bdb9bca959",
   "metadata": {},
   "source": [
    "**Observations All Speeches**:\n",
    "- negative, positive & uncertainty have the biggest impact on the weighted score (33%, 27% and 22% respectively)\n",
    "- weak, litigious and strong have limited score (9%, 5% and 3% respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed8375-cc02-4ce5-84fd-14dce98d106d",
   "metadata": {},
   "source": [
    "**Observations BoE Speeches only**:\n",
    "- negative, uncertainty & positive have the biggest impact on the weighted score (33%, 26% and 22% respectively)<br>\n",
    "**Note**: Uncertainty has higher impact than positive\n",
    "- weak, litigious and strong have limited score (11%, 5% and 2% respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e6fa2-7d64-4c45-b425-80419979ca04",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2efd5-181a-4b29-aedb-8e0b4753f8d5",
   "metadata": {},
   "source": [
    "**Category weights** based on importance:<br>\n",
    "This is one weighting proposal - **of course different weights can be applied**\n",
    "- Negative -1       Standard negative words\n",
    "- Positive +1.5     Standard positive words - compensate for negatively skewed wordlist\n",
    "- Uncertainty 0.2   Words expressing doubt or ambiguity, less impactful than outright negative or positive words\n",
    "- Litigious -0.2    Words related to lawsuits or legal issues, potentially negative or impactful depending on context\n",
    "- Strong +1.5       Words with high intensity or impact, thus given more weight\n",
    "- Weak +0.5         Words with less impact, so given lesser weight than 'Strong' words\n",
    "- Constraining -0.5 Words implying restriction or limitations, generally negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b04c34a-7f87-42f0-b86f-fddfd393ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights to the categories\n",
    "category_weights = {\n",
    "    'Negative': -1,\n",
    "    'Positive': 1.5,\n",
    "    'Uncertainty': 0.2,\n",
    "    'Litigious': -0.2,\n",
    "    'Strong': 1.5,\n",
    "    'Weak': 0.5,\n",
    "    'Constraining': -0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fda6b52-e81a-4c96-9f56-fdefb35ff780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenised</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Weak</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>sentiment_score_lexicon</th>\n",
       "      <th>sentiment_score_lexicon_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r901128a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1990-11-28</td>\n",
       "      <td>A Proper Role for Monetary Policy</td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>They would no doubt argue that to have two obj...</td>\n",
       "      <td>would doubt argue two objectives like trying c...</td>\n",
       "      <td>[would, doubt, argue, two, objectives, like, t...</td>\n",
       "      <td>[would, doubt, argue, two, objective, like, tr...</td>\n",
       "      <td>...</td>\n",
       "      <td>1919</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.013549</td>\n",
       "      <td>0.012715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r911003a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1991-10-03</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>Today I wish to talk about real interest rates...</td>\n",
       "      <td>today wish talk real interest rates mainly his...</td>\n",
       "      <td>[today, wish, talk, real, interest, rates, mai...</td>\n",
       "      <td>[today, wish, talk, real, interest, rate, main...</td>\n",
       "      <td>...</td>\n",
       "      <td>1754</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.014253</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r920314a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-03-14</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>I welcome this opportunity to talk about prosp...</td>\n",
       "      <td>welcome opportunity talk prospects banks austr...</td>\n",
       "      <td>[welcome, opportunity, talk, prospects, banks,...</td>\n",
       "      <td>[welcome, opportunity, talk, prospect, bank, a...</td>\n",
       "      <td>...</td>\n",
       "      <td>1867</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.043117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r920529a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-05-29</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a pleasure to have this opportunity to a...</td>\n",
       "      <td>pleasure opportunity address influential gathe...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>[pleasure, opportunity, address, influential, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2123</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.021620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r920817a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1992-08-17</td>\n",
       "      <td></td>\n",
       "      <td>fraser</td>\n",
       "      <td>0</td>\n",
       "      <td>As a long-time fan of Don Sanders, I am deligh...</td>\n",
       "      <td>long time fan sanders delighted participating ...</td>\n",
       "      <td>[long, time, fan, sanders, delighted, particip...</td>\n",
       "      <td>[long, time, fan, sander, delight, participate...</td>\n",
       "      <td>...</td>\n",
       "      <td>2150</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004651</td>\n",
       "      <td>0.024744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference    country        date                               title  \\\n",
       "0  r901128a_BOA  australia  1990-11-28   A Proper Role for Monetary Policy   \n",
       "1  r911003a_BOA  australia  1991-10-03                                       \n",
       "2  r920314a_BOA  australia  1992-03-14                                       \n",
       "3  r920529a_BOA  australia  1992-05-29                                       \n",
       "4  r920817a_BOA  australia  1992-08-17                                       \n",
       "\n",
       "   author  is_gov                                               text  \\\n",
       "0  fraser       0  They would no doubt argue that to have two obj...   \n",
       "1  fraser       0  Today I wish to talk about real interest rates...   \n",
       "2  fraser       0  I welcome this opportunity to talk about prosp...   \n",
       "3  fraser       0  It is a pleasure to have this opportunity to a...   \n",
       "4  fraser       0  As a long-time fan of Don Sanders, I am deligh...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  would doubt argue two objectives like trying c...   \n",
       "1  today wish talk real interest rates mainly his...   \n",
       "2  welcome opportunity talk prospects banks austr...   \n",
       "3  pleasure opportunity address influential gathe...   \n",
       "4  long time fan sanders delighted participating ...   \n",
       "\n",
       "                                      text_tokenised  \\\n",
       "0  [would, doubt, argue, two, objectives, like, t...   \n",
       "1  [today, wish, talk, real, interest, rates, mai...   \n",
       "2  [welcome, opportunity, talk, prospects, banks,...   \n",
       "3  [pleasure, opportunity, address, influential, ...   \n",
       "4  [long, time, fan, sanders, delighted, particip...   \n",
       "\n",
       "                                     text_lemmatised  ... word_count  \\\n",
       "0  [would, doubt, argue, two, objective, like, tr...  ...       1919   \n",
       "1  [today, wish, talk, real, interest, rate, main...  ...       1754   \n",
       "2  [welcome, opportunity, talk, prospect, bank, a...  ...       1867   \n",
       "3  [pleasure, opportunity, address, influential, ...  ...       2123   \n",
       "4  [long, time, fan, sander, delight, participate...  ...       2150   \n",
       "\n",
       "   Negative  Positive  Uncertainty  Litigious  Strong  Weak  Constraining  \\\n",
       "0        84        58           32          5      10    15            13   \n",
       "1        53        28           35          2       3    16            12   \n",
       "2        43        67           33          8      11    16            13   \n",
       "3        62        56           43          6       7    20             8   \n",
       "4        72        62           42          6      12    27            13   \n",
       "\n",
       "   sentiment_score_lexicon  sentiment_score_lexicon_weighted  \n",
       "0                -0.013549                          0.012715  \n",
       "1                -0.014253                          0.001197  \n",
       "2                 0.012855                          0.043117  \n",
       "3                -0.002826                          0.021620  \n",
       "4                -0.004651                          0.024744  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to apply the lexicon to the text\n",
    "def lexicon_score_weighted(tokens):\n",
    "    score = 0\n",
    "    for cat in categories:\n",
    "        count = sum(t in word_sets[cat] for t in tokens)\n",
    "        score += count * category_weights[cat]\n",
    "    return score\n",
    "\n",
    "# Compute counts and store as a new column\n",
    "speeches_df_2['sentiment_score_lexicon_weighted'] = speeches_df_2['text_lemmatised'].apply(lexicon_score_weighted) \\\n",
    "                                                    / speeches_df_2['word_count']\n",
    "\n",
    "# View the DataFrame\n",
    "speeches_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ed3df-4038-4526-959c-ba12ffe04967",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad8a92-0cbc-481e-8f29-af7c9b9a99e6",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62172c39-9d8d-4de7-a8e3-bb150e6531bf",
   "metadata": {},
   "source": [
    "**1. Text Cleaning - which steps of text cleaning need to be taken to get the best results?**\n",
    "\n",
    "- Removing unwanted characters\n",
    "- Removing any special characters and punctuation\n",
    "- Converting text to lower case\n",
    "- Removing stopwords\n",
    "- tokenisation: Split the cleaned text into individual words, so that text can be analysed at word level.\n",
    "- Lemmatisation: Reduce words to its base or dictionary form (the lemma)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a40391-8fc6-4562-acca-80f6d004b983",
   "metadata": {},
   "source": [
    "**2. Sentiment Score - how do we want to calculate the sentiment score?**\n",
    "- Option 1: sentiment score = positive word count - negative word count\n",
    "- Option 2: sentiment score = (positive word count - negative word count) / speech word count\n",
    "- Option 3: sentiment score = (sum of (category word counts * category weights)) / speech word count  => weights to be defined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
